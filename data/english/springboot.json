[
  {
    "id": "spring-boot-mastery",
    "category": "Backend Development",
    "title": "Spring Boot Mastery Handbook",
    "subtitle": "A complete, end-to-end guide to Spring Boot covering fundamentals, web development, data access, configuration, security, observability, testing, and microservices architecture.",
    "icon": "spring-boot",
    "stats": {
      "sections": 6,
      "topics": 105
    },
    "sections": [
      {
        "id": "core-di",
        "title": "Core Spring Boot + Dependency Injection",
        "description": "Master Spring Boot fundamentals including auto-configuration, embedded servers, IoC container mechanics, dependency injection patterns, stereotype annotations, and advanced bean wiring strategies.",
        "topics": [
          {
            "id": "core-di-1",
            "title": "SpringApplication & @SpringBootApplication",
            "explanations": {
              "english": "The SpringApplication class provides the bootstrap entry point for Spring Boot applications. The @SpringBootApplication annotation is a convenience meta-annotation that combines @Configuration, @EnableAutoConfiguration, and @ComponentScan with their default attributes. When placed on the main class, it triggers component scanning from its package downward and enables auto-configuration based on classpath contents. This single annotation eliminates the need for XML configuration or multiple Java config annotations. It initializes the application context, registers all beans, and starts the embedded web server."
            },
            "code": {
              "title": "Standard Spring Boot Entry Point",
              "language": "java",
              "content": "@SpringBootApplication\npublic class Application {\n    public static void main(String[] args) {\n        SpringApplication.run(Application.class, args);\n    }\n}"
            },
            "codeExplanations": {
              "english": "The @SpringBootApplication marks this as the configuration class and enables auto-scanning. SpringApplication.run() bootstraps the application, creates the ApplicationContext, performs auto-configuration, and starts the embedded server on the default port 8080."
            },
            "keyPoints": [
              "Combines @Configuration, @EnableAutoConfiguration, and @ComponentScan into one annotation",
              "Must be placed on the class containing the public static void main method",
              "Component scan starts from the package where this annotation is placed",
              "Triggers automatic configuration based on classpath dependencies"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "core-di-2",
            "title": "Auto-Configuration Magic",
            "explanations": {
              "english": "Spring Boot's auto-configuration attempts to automatically configure your application based on the jar dependencies present in the classpath. It uses @Conditional annotations such as @ConditionalOnClass and @ConditionalOnMissingBean to determine whether specific configurations should apply. For example, if spring-webmvc is detected, it auto-configures DispatcherServlet. This convention-over-configuration approach eliminates boilerplate while remaining flexible through explicit bean overrides or property settings."
            },
            "code": {
              "title": "Conditional Auto-Configuration Example",
              "language": "java",
              "content": "@Configuration\n@ConditionalOnClass(DataSource.class)\npublic class DataSourceAutoConfiguration {\n    @Bean\n    @ConditionalOnMissingBean\n    public DataSource dataSource(DataSourceProperties properties) {\n        return DataSourceBuilder.create()\n            .url(properties.getUrl())\n            .build();\n    }\n}"
            },
            "codeExplanations": {
              "english": "This configuration only activates if DataSource.class is on the classpath. The @ConditionalOnMissingBean ensures this bean is only created if the user hasn't defined their own DataSource, allowing easy customization."
            },
            "keyPoints": [
              "Uses @Conditional annotations to make configuration decisions",
              "Triggered by the presence of specific classes in the classpath",
              "Can be disabled or excluded using @EnableAutoConfiguration(exclude={...})",
              "Auto-configuration classes are loaded from META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "core-di-3",
            "title": "Starter Dependencies",
            "explanations": {
              "english": "Starters are curated sets of dependency descriptors that simplify Maven and Gradle configuration. They provide transitive dependency management ensuring compatible versions of related libraries (Bill of Materials). Instead of manually adding 10+ dependencies for web development, adding spring-boot-starter-web brings in all required web components with verified compatibility. Starters follow the naming pattern spring-boot-starter-* and eliminate version conflict issues."
            },
            "code": {
              "title": "Maven Starter Dependencies",
              "language": "xml",
              "content": "<dependencies>\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-web</artifactId>\n    </dependency>\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-data-jpa</artifactId>\n    </dependency>\n</dependencies>"
            },
            "codeExplanations": {
              "english": "Each starter pulls in all necessary dependencies for its domain. Version numbers are inherited from the parent POM or BOM, ensuring compatibility across the Spring Boot ecosystem."
            },
            "keyPoints": [
              "Curated dependency sets that simplify build configuration",
              "Ensure version compatibility through transitive dependency management",
              "Follow naming convention spring-boot-starter-*",
              "Eliminate the need to hunt for compatible library versions"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [
                {
                  "headers": [
                    "Starter",
                    "Purpose",
                    "Key Dependencies Included"
                  ],
                  "rows": [
                    [
                      "spring-boot-starter-web",
                      "Web apps with MVC",
                      "Tomcat, Spring MVC, Jackson"
                    ],
                    [
                      "spring-boot-starter-data-jpa",
                      "Database access",
                      "Hibernate, Spring Data, Transaction API"
                    ],
                    [
                      "spring-boot-starter-test",
                      "Testing support",
                      "JUnit, Mockito, AssertJ"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "core-di-4",
            "title": "Embedded Servers - Tomcat",
            "explanations": {
              "english": "Spring Boot includes Apache Tomcat as the default embedded servlet container, eliminating the need to deploy WAR files to an external server. Tomcat starts programmatically within the application process when the application runs, typically listening on port 8080. This embedded approach enables building fully executable JAR files that follow the 'just run it' philosophy. Configuration is managed through properties like server.port and server.tomcat.max-threads."
            },
            "code": {
              "title": "Tomcat Configuration Properties",
              "language": "properties",
              "content": "server.port=8080\nserver.tomcat.max-threads=200\nserver.tomcat.connection-timeout=5s"
            },
            "codeExplanations": {
              "english": "These properties configure the embedded Tomcat instance. The server.port changes the listen port, max-threads controls the pool size for request processing, and connection-timeout sets socket timeout values."
            },
            "keyPoints": [
              "Default embedded servlet container for Spring Boot",
              "Supports executable JAR deployment model",
              "Configurable via application.properties using server.tomcat.* prefix",
              "Automatically started when spring-boot-starter-web is present"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "core-di-5",
            "title": "Embedded Servers - Netty",
            "explanations": {
              "english": "Netty serves as the default embedded server for reactive Spring Boot applications using WebFlux. Unlike Tomcat's thread-per-request model, Netty uses an event-driven architecture capable of handling high concurrency with fewer threads. It is auto-configured when spring-boot-starter-webflux is on the classpath instead of spring-boot-starter-web. Netty supports non-blocking I/O operations essential for reactive programming paradigms and streaming data."
            },
            "code": {
              "title": "WebFlux with Netty",
              "language": "java",
              "content": "@SpringBootApplication\npublic class ReactiveApplication {\n    public static void main(String[] args) {\n        SpringApplication.run(ReactiveApplication.class, args);\n    }\n}\n\n// Netty starts automatically on port 8080 when WebFlux starter is used"
            },
            "codeExplanations": {
              "english": "When spring-boot-starter-webflux is the only web starter present, Spring Boot auto-configures Netty instead of Tomcat. The same SpringApplication bootstrap starts the Netty server embedded within the application."
            },
            "keyPoints": [
              "Default server for Spring WebFlux reactive applications",
              "Event-driven architecture supporting high concurrency",
              "Uses non-blocking I/O instead of thread-per-request",
              "Auto-configured when spring-boot-starter-webflux is detected"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [
                {
                  "headers": [
                    "Feature",
                    "Tomcat",
                    "Netty"
                  ],
                  "rows": [
                    [
                      "Default with",
                      "spring-boot-starter-web",
                      "spring-boot-starter-webflux"
                    ],
                    [
                      "I/O Model",
                      "Blocking (Servlet)",
                      "Non-blocking (Reactive)"
                    ],
                    [
                      "Thread Model",
                      "Thread-per-request",
                      "Event loop with small thread pool"
                    ],
                    [
                      "Use Case",
                      "Traditional MVC",
                      "Reactive/Streaming APIs"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "core-di-6",
            "title": "Configuration Files - application.properties",
            "explanations": {
              "english": "The application.properties file uses traditional key-value pairs to configure Spring Boot applications. It employs dot notation to represent hierarchical configuration keys such as server.port=8080. Spring Boot automatically loads this file from the root of the classpath. While straightforward, deeply nested structures can become verbose compared to YAML, requiring repetition of prefixes for related configuration groups."
            },
            "code": {
              "title": "Properties Configuration Example",
              "language": "properties",
              "content": "server.port=8080\nserver.servlet.context-path=/api\nspring.datasource.url=jdbc:postgresql://localhost:5432/mydb\nspring.datasource.username=admin\nspring.datasource.password=secret\nlogging.level.org.springframework=INFO"
            },
            "codeExplanations": {
              "english": "Each line configures a specific property. The hierarchy is flattened using dots. Multiple related properties like datasource configuration require repeating the spring.datasource prefix for each line."
            },
            "keyPoints": [
              "Key-value format using equals sign separator",
              "Dot notation represents configuration hierarchy",
              "Loaded automatically from classpath root",
              "Verbose for nested configuration structures"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "core-di-7",
            "title": "Configuration Files - application.yml",
            "explanations": {
              "english": "YAML (application.yml) provides a hierarchical configuration format using indentation and colons to represent nested structures. It eliminates repetition by grouping related properties under common parent keys. More readable for complex configurations like database connection pools or profile-specific settings. Spring Boot supports both formats simultaneously, with properties defined in YAML potentially overriding those in properties files depending on loading order."
            },
            "code": {
              "title": "YAML Configuration Structure",
              "language": "yaml",
              "content": "server:\n  port: 8080\n  servlet:\n    context-path: /api\n\nspring:\n  datasource:\n    url: jdbc:postgresql://localhost:5432/mydb\n    username: admin\n    password: secret\n    hikari:\n      maximum-pool-size: 10\n      connection-timeout: 30000"
            },
            "codeExplanations": {
              "english": "YAML uses indentation to denote hierarchy, eliminating the need to repeat 'spring.datasource' for every sub-property. Lists and maps can be represented naturally. The hikari configuration is nested cleanly under datasource without prefix repetition."
            },
            "keyPoints": [
              "Hierarchical format using indentation and colons",
              "Eliminates repetition of common prefixes",
              "Supports lists and complex objects natively",
              "More readable for deeply nested configurations"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [
                {
                  "headers": [
                    "Aspect",
                    "Properties",
                    "YAML"
                  ],
                  "rows": [
                    [
                      "Syntax",
                      "Key=value pairs",
                      "Indented hierarchy with colons"
                    ],
                    [
                      "Verbosity",
                      "High for nested keys",
                      "Low, DRY principle"
                    ],
                    [
                      "Lists",
                      "Comma-separated or indexed",
                      "Natural hyphen notation"
                    ],
                    [
                      "Profiles",
                      "Separate files or suffixes",
                      "Document separators with ---"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "core-di-8",
            "title": "Inversion of Control (IoC)",
            "explanations": {
              "english": "Inversion of Control is a design principle where the control of object creation and lifecycle management is transferred from the application code to a container or framework. Instead of classes instantiating their dependencies using the 'new' keyword, the container injects required dependencies. This decouples components, enhances testability through mocking, and promotes the Single Responsibility Principle by removing object creation concerns from business logic."
            },
            "code": {
              "title": "IoC Concept Example",
              "language": "java",
              "content": "// Without IoC - tight coupling\npublic class OrderService {\n    private DatabaseRepository repo = new DatabaseRepository(); // tight coupling\n}\n\n// With IoC - container injects dependency\npublic class OrderService {\n    private final Repository repo;\n    public OrderService(Repository repo) { // injected by container\n        this.repo = repo;\n    }\n}"
            },
            "codeExplanations": {
              "english": "The first example creates tight coupling to a concrete implementation. The second example shows IoC where the dependency is provided externally by the container, allowing different implementations to be injected without code changes."
            },
            "keyPoints": [
              "Container manages object creation and wiring instead of application code",
              "Decouples components from their dependencies",
              "Enables easier unit testing through dependency substitution",
              "Foundation principle of the Spring Framework"
            ],
            "extras": {
              "flowDiagram": "Traditional: Application -> new Service() -> new Repository()\nIoC: Container -> creates Repository -> creates Service -> injects Repository -> Application uses Service",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "core-di-9",
            "title": "Bean Creation Lifecycle",
            "explanations": {
              "english": "Spring beans follow a defined lifecycle managed by the container: instantiation using constructors, population of properties and dependencies, BeanNameAware/BeanFactoryAware callbacks, pre-initialization BeanPostProcessor calls, initialization via @PostConstruct or InitializingBean, and finally destruction via @PreDestroy or DisposableBean. Understanding these phases is crucial for proper resource management, initialization logic, and cleanup operations."
            },
            "code": {
              "title": "Lifecycle Callbacks",
              "language": "java",
              "content": "@Component\npublic class MyBean implements InitializingBean, DisposableBean {\n    \n    @PostConstruct\n    public void init() {\n        // Called after properties set\n    }\n    \n    @Override\n    public void afterPropertiesSet() {\n        // Alternative initialization hook\n    }\n    \n    @PreDestroy\n    public void preDestroy() {\n        // Cleanup before container shutdown\n    }\n    \n    @Override\n    public void destroy() {\n        // Alternative destruction hook\n    }\n}"
            },
            "codeExplanations": {
              "english": "@PostConstruct is the modern annotation-based approach for initialization after dependencies are injected. @PreDestroy is called before the bean is destroyed. The interfaces InitializingBean and DisposableBean are older alternatives but serve the same purpose."
            },
            "keyPoints": [
              "Container manages bean instantiation through destruction",
              "@PostConstruct called after dependency injection completes",
              "@PreDestroy called during container shutdown for cleanup",
              "BeanPostProcessors can wrap beans for proxying during initialization"
            ],
            "extras": {
              "flowDiagram": "Instantiate -> Populate Properties -> Set Bean Name/Factory -> BeanPostProcessor.preInit -> @PostConstruct -> BeanPostProcessor.postInit -> Ready -> @PreDestroy -> Destroy",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "core-di-10",
            "title": "ApplicationContext vs BeanFactory",
            "explanations": {
              "english": "BeanFactory is the basic IoC container providing bean instantiation and dependency injection. ApplicationContext extends BeanFactory and adds enterprise application features: AOP integration, internationalization (i18n), event propagation, and web-application specific contexts. ApplicationContext loads singleton beans eagerly by default at startup, while BeanFactory uses lazy loading. In modern Spring Boot, ApplicationContext is always used as it provides the complete infrastructure required for enterprise applications."
            },
            "code": {
              "title": "Container Types",
              "language": "java",
              "content": "// BeanFactory - basic IoC\nBeanFactory factory = new XmlBeanFactory(new ClassPathResource(\"beans.xml\"));\n\n// ApplicationContext - full-featured\nApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class);\n// Or in Spring Boot:\nApplicationContext context = SpringApplication.run(Application.class, args);"
            },
            "codeExplanations": {
              "english": "BeanFactory is rarely used directly in modern applications. ApplicationContext provides the foundation for Spring Boot applications including annotation processing, event publishing, and resource loading."
            },
            "keyPoints": [
              "BeanFactory provides basic bean management and DI",
              "ApplicationContext extends BeanFactory with enterprise features",
              "ApplicationContext eager-loads singletons by default",
              "ApplicationContext supports AOP, events, and web-specific scopes"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [
                {
                  "headers": [
                    "Feature",
                    "BeanFactory",
                    "ApplicationContext"
                  ],
                  "rows": [
                    [
                      "Loading",
                      "Lazy (on-demand)",
                      "Eager (by default)"
                    ],
                    [
                      "AOP Integration",
                      "Requires manual setup",
                      "Built-in support"
                    ],
                    [
                      "MessageSource (i18n)",
                      "No",
                      "Yes"
                    ],
                    [
                      "Event Propagation",
                      "No",
                      "ApplicationEventPublisher"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "core-di-11",
            "title": "@Autowired",
            "explanations": {
              "english": "@Autowired enables automatic dependency injection by type. Spring resolves the dependency from the application context and injects it into fields, constructors, or setter methods. If no matching bean exists, it throws NoSuchBeanDefinitionException. If multiple beans match the type, it throws NoUniqueBeanDefinitionException unless resolved by @Primary or @Qualifier. It eliminates manual bean lookup through ApplicationContext.getBean() calls."
            },
            "code": {
              "title": "Autowired Usage Patterns",
              "language": "java",
              "content": "@Service\npublic class UserService {\n    \n    @Autowired // Field injection (not recommended)\n    private UserRepository fieldRepo;\n    \n    private final UserRepository constructorRepo;\n    \n    @Autowired // Constructor injection (recommended)\n    public UserService(UserRepository repo) {\n        this.constructorRepo = repo;\n    }\n    \n    @Autowired // Setter injection\n    public void setEmailService(EmailService service) {\n        this.emailService = service;\n    }\n}"
            },
            "codeExplanations": {
              "english": "Demonstrates the three injection modes: field (uses reflection), constructor (preferred for required dependencies), and setter (for optional dependencies). Starting with Spring 4.3, @Autowired on constructors is optional if only one constructor exists."
            },
            "keyPoints": [
              "Injects dependencies by type from the application context",
              "Can be applied to fields, constructors, and setter methods",
              "Required by default; use required=false for optional dependencies",
              "Requires disambiguation when multiple beans of same type exist"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "core-di-12",
            "title": "Constructor Injection vs Field Injection",
            "explanations": {
              "english": "Constructor injection declares dependencies as constructor parameters, making them required and allowing the class to be immutable (final fields). It ensures the object is in a valid state upon creation and makes dependencies explicit. Field injection uses reflection to set private fields directly, hiding dependencies from the public API and making unit testing difficult without the Spring container. Constructor injection is the recommended approach for mandatory dependencies."
            },
            "code": {
              "title": "Constructor vs Field Comparison",
              "language": "java",
              "content": "// Field Injection - Hidden dependencies\n@Service\npublic class OrderService {\n    @Autowired\n    private PaymentGateway gateway; // Hidden dependency\n}\n\n// Constructor Injection - Explicit contract\n@Service\npublic class OrderService {\n    private final PaymentGateway gateway;\n    \n    public OrderService(PaymentGateway gateway) {\n        this.gateway = gateway; // Null-safe assignment\n    }\n}"
            },
            "codeExplanations": {
              "english": "Field injection appears cleaner but hides the class requirements. Constructor injection makes the contract explicit through the constructor signature, supports final fields for immutability, and allows easy instantiation in unit tests without reflection."
            },
            "keyPoints": [
              "Constructor injection enforces required dependencies at object creation",
              "Field injection hides dependencies and complicates unit testing",
              "Constructor injection enables immutable dependencies (final fields)",
              "Constructor injection reveals circular dependencies at startup"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [
                {
                  "headers": [
                    "Characteristic",
                    "Constructor",
                    "Field"
                  ],
                  "rows": [
                    [
                      "Testability",
                      "Easy - pass mocks to constructor",
                      "Requires reflection or Spring context"
                    ],
                    [
                      "Immutability",
                      "Supports final fields",
                      "Cannot use final"
                    ],
                    [
                      "Null Safety",
                      "Guaranteed non-null after construction",
                      "Possible null if not injected"
                    ],
                    [
                      "Circular Dependencies",
                      "Detected at startup",
                      "May cause runtime issues"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "core-di-13",
            "title": "Dependency Injection Best Practices",
            "explanations": {
              "english": "Always use constructor injection for mandatory dependencies to ensure objects are valid upon instantiation. Avoid field injection in production code to maintain testability without Spring's test utilities. Declare injected fields as final to enforce immutability and prevent reassignment. Keep the number of constructor arguments manageable; if exceeding 4-5 dependencies, consider refactoring using the Facade pattern or splitting the class by responsibility."
            },
            "code": {
              "title": "Recommended Pattern",
              "language": "java",
              "content": "@Service\npublic class OrderProcessingService {\n    private final OrderRepository orderRepository;\n    private final PaymentService paymentService;\n    private final NotificationService notificationService;\n    \n    public OrderProcessingService(OrderRepository orderRepository,\n                                  PaymentService paymentService,\n                                  NotificationService notificationService) {\n        this.orderRepository = orderRepository;\n        this.paymentService = paymentService;\n        this.notificationService = notificationService;\n    }\n}"
            },
            "codeExplanations": {
              "english": "This example shows proper constructor injection with final fields. The dependencies are immutable, explicitly required, and easily mockable in unit tests. Lombok's @RequiredArgsConstructor can reduce boilerplate for such patterns."
            },
            "keyPoints": [
              "Use constructor injection for all mandatory dependencies",
              "Declare injected fields as final when possible",
              "Limit constructor parameters to avoid God classes",
              "Avoid field injection except in configuration classes"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "core-di-14",
            "title": "@Component",
            "explanations": {
              "english": "@Component is the generic stereotype annotation marking a class as a Spring-managed bean. During component scanning, Spring detects classes annotated with @Component and registers them as beans in the ApplicationContext. It is the parent meta-annotation for @Service, @Repository, and @Controller. Use @Component when the class doesn't fit into the specialized stereotypes but still requires Spring management."
            },
            "code": {
              "title": "Generic Component",
              "language": "java",
              "content": "@Component\npublic class CacheManager {\n    private final Map<String, Object> cache = new ConcurrentHashMap<>();\n    \n    public Object get(String key) {\n        return cache.get(key);\n    }\n    \n    public void put(String key, Object value) {\n        cache.put(key, value);\n    }\n}"
            },
            "codeExplanations": {
              "english": "CacheManager is a generic utility class that doesn't fit into service, repository, or controller categories but requires singleton lifecycle management by Spring. @Component enables automatic detection and registration."
            },
            "keyPoints": [
              "Generic stereotype for any Spring-managed component",
              "Enables detection during classpath scanning",
              "Parent annotation for @Service, @Repository, @Controller",
              "Use when no specialized stereotype applies"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "core-di-15",
            "title": "@Service",
            "explanations": {
              "english": "@Service is a specialization of @Component indicating that the class holds business logic in the service layer. It carries no additional technical behavior beyond @Component but serves as a semantic marker clarifying the class's architectural role. Service classes typically contain transactional boundaries, business rules, and coordination between repositories. This annotation aids in AOP pointcut targeting and improves code readability."
            },
            "code": {
              "title": "Service Layer Implementation",
              "language": "java",
              "content": "@Service\npublic class AccountService {\n    private final AccountRepository repository;\n    \n    public AccountService(AccountRepository repository) {\n        this.repository = repository;\n    }\n    \n    @Transactional\n    public void transfer(Long fromId, Long toId, BigDecimal amount) {\n        Account from = repository.findById(fromId).orElseThrow();\n        Account to = repository.findById(toId).orElseThrow();\n        from.debit(amount);\n        to.credit(amount);\n        repository.save(from);\n        repository.save(to);\n    }\n}"
            },
            "codeExplanations": {
              "english": "The @Service annotation marks this as a business logic holder. The transfer method represents a transactional business operation coordinating multiple repository calls. The annotation indicates this class belongs to the service layer in domain-driven design."
            },
            "keyPoints": [
              "Semantic marker for service layer business logic",
              "Specialization of @Component",
              "Typical location for @Transactional boundaries",
              "Improves architectural clarity and AOP targeting"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "core-di-16",
            "title": "@Repository",
            "explanations": {
              "english": "@Repository marks classes in the persistence layer dealing with data access and storage. It translates persistence-specific exceptions (like SQLException) into Spring's unified DataAccessException hierarchy. This enables exception translation across different data access technologies (JPA, JDBC, MongoDB). It also serves as a marker for automatic exception translation and can trigger proxy creation for transaction management in some configurations."
            },
            "code": {
              "title": "Data Repository",
              "language": "java",
              "content": "@Repository\npublic class JdbcProductRepository {\n    private final JdbcTemplate jdbcTemplate;\n    \n    public JdbcProductRepository(JdbcTemplate jdbcTemplate) {\n        this.jdbcTemplate = jdbcTemplate;\n    }\n    \n    public Product findById(Long id) {\n        try {\n            return jdbcTemplate.queryForObject(\n                \"SELECT * FROM products WHERE id = ?\", \n                new ProductRowMapper(), id);\n        } catch (DataAccessException e) {\n            throw new ProductNotFoundException(\"Product not found: \" + id, e);\n        }\n    }\n}"
            },
            "codeExplanations": {
              "english": "@Repository enables automatic translation of SQL exceptions into Spring's DataAccessException. It marks this class as a data access object in the persistence layer, distinct from services or controllers."
            },
            "keyPoints": [
              "Marks persistence layer components",
              "Enables exception translation to DataAccessException",
              "Indicates the class interacts with data storage",
              "Specialization of @Component for DAOs"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "core-di-17",
            "title": "@Controller",
            "explanations": {
              "english": "@Controller indicates a Spring MVC controller handling HTTP requests in traditional server-rendered web applications. Classes annotated with @Controller return view names resolved by ViewResolver implementations (like Thymeleaf or JSP resolvers). It combines @Component with web-specific functionality. Methods typically return String view names or ModelAndView objects containing both view name and model data."
            },
            "code": {
              "title": "MVC Controller",
              "language": "java",
              "content": "@Controller\n@RequestMapping(\"/products\")\npublic class ProductController {\n    private final ProductService productService;\n    \n    @GetMapping\n    public String listProducts(Model model) {\n        model.addAttribute(\"products\", productService.findAll());\n        return \"product/list\"; // View name resolved by Thymeleaf\n    }\n    \n    @GetMapping(\"/{id}\")\n    public ModelAndView productDetail(@PathVariable Long id) {\n        ModelAndView mav = new ModelAndView(\"product/detail\");\n        mav.addObject(\"product\", productService.findById(id));\n        return mav;\n    }\n}"
            },
            "codeExplanations": {
              "english": "This controller handles traditional web requests returning view names. The 'product/list' string is resolved by a ViewResolver to an actual HTML template. Model attributes are accessible in the view template."
            },
            "keyPoints": [
              "Used for traditional MVC with server-rendered views",
              "Methods return view names resolved by ViewResolver",
              "Combines @Component with web controller semantics",
              "Works with template engines like Thymeleaf, JSP, FreeMarker"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "core-di-18",
            "title": "@RestController",
            "explanations": {
              "english": "@RestController is a convenience annotation that combines @Controller and @ResponseBody. It indicates the class handles REST API requests returning data (JSON or XML) rather than views. The @ResponseBody annotation ensures return values are serialized directly to the HTTP response body using HttpMessageConverters. This eliminates the need to annotate every handler method with @ResponseBody when building RESTful services."
            },
            "code": {
              "title": "REST API Controller",
              "language": "java",
              "content": "@RestController\n@RequestMapping(\"/api/users\")\npublic class UserRestController {\n    private final UserService userService;\n    \n    @GetMapping\n    public List<User> getAllUsers() {\n        return userService.findAll();\n    }\n    \n    @PostMapping\n    public ResponseEntity<User> createUser(@RequestBody User user) {\n        User created = userService.save(user);\n        URI location = ServletUriComponentsBuilder\n            .fromCurrentRequest().path(\"/{id}\")\n            .buildAndExpand(created.getId()).toUri();\n        return ResponseEntity.created(location).body(created);\n    }\n}"
            },
            "codeExplanations": {
              "english": "@RestController ensures all methods return data directly to the client. User objects are automatically converted to JSON. ResponseEntity provides full control over HTTP status codes and headers."
            },
            "keyPoints": [
              "Combines @Controller and @ResponseBody",
              "Returns data objects serialized to HTTP body (JSON/XML)",
              "Eliminates repetitive @ResponseBody annotations",
              "Ideal for building RESTful APIs without view resolution"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [
                {
                  "headers": [
                    "Feature",
                    "@Controller",
                    "@RestController"
                  ],
                  "rows": [
                    [
                      "Return Type",
                      "View name (String)",
                      "Data object (JSON/XML)"
                    ],
                    [
                      "View Resolution",
                      "Yes, via ViewResolver",
                      "No, direct HTTP body"
                    ],
                    [
                      "Use Case",
                      "Server-rendered web apps",
                      "REST APIs"
                    ],
                    [
                      "Implicit Annotation",
                      "@Component",
                      "@Controller + @ResponseBody"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "core-di-19",
            "title": "@Configuration",
            "explanations": {
              "english": "@Configuration marks a class as a source of bean definitions using explicit Java code instead of XML. The class declares @Bean methods that the Spring container processes to generate bean definitions and service requests at runtime. It indicates that the class contains factory methods for creating beans. Configuration classes support inter-bean dependencies through method calls and can be imported into other configurations using @Import."
            },
            "code": {
              "title": "Java Configuration Class",
              "language": "java",
              "content": "@Configuration\npublic class AppConfig {\n    \n    @Bean\n    public RestTemplate restTemplate() {\n        return new RestTemplateBuilder()\n            .setConnectTimeout(Duration.ofSeconds(5))\n            .build();\n    }\n    \n    @Bean\n    public CacheManager cacheManager() {\n        return new ConcurrentMapCacheManager(\"users\", \"products\");\n    }\n}"
            },
            "codeExplanations": {
              "english": "Methods annotated with @Bean within @Configuration classes produce beans managed by Spring. When one @Bean method calls another, Spring intercepts the call to return the existing singleton bean rather than creating a new instance."
            },
            "keyPoints": [
              "Indicates the class contains bean factory methods",
              "Alternative to XML configuration",
              "Supports inter-bean dependencies via method calls",
              "Can be combined with @ComponentScan for mixed configuration"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "core-di-20",
            "title": "@Bean",
            "explanations": {
              "english": "@Bean declares a method produces a bean to be managed by the Spring container. Used within @Configuration classes, the method name typically becomes the bean name. It allows explicit control over bean instantiation, particularly useful for third-party classes that cannot be annotated with @Component or require complex initialization logic. Supports specifying initMethod, destroyMethod, and scope attributes."
            },
            "code": {
              "title": "Explicit Bean Definition",
              "language": "java",
              "content": "@Configuration\npublic class DatabaseConfig {\n    \n    @Bean(initMethod = \"start\", destroyMethod = \"stop\")\n    public DataSource dataSource(\n            @Value(\"${db.url}\") String url,\n            @Value(\"${db.username}\") String username) {\n        HikariConfig config = new HikariConfig();\n        config.setJdbcUrl(url);\n        config.setUsername(username);\n        return new HikariDataSource(config);\n    }\n    \n    @Bean(name = \"customObjectMapper\")\n    @Primary\n    public ObjectMapper objectMapper() {\n        ObjectMapper mapper = new ObjectMapper();\n        mapper.registerModule(new JavaTimeModule());\n        return mapper;\n    }\n}"
            },
            "codeExplanations": {
              "english": "The dataSource bean shows integration of third-party HikariCP with external property injection. The objectMapper bean demonstrates custom naming with @Bean(name) and @Primary for preference when multiple beans exist."
            },
            "keyPoints": [
              "Declares explicit bean creation in configuration classes",
              "Method name becomes bean name by default",
              "Used for third-party library integration",
              "Supports lifecycle callbacks and custom bean naming"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "core-di-21",
            "title": "Manual Bean Wiring",
            "explanations": {
              "english": "Manual bean wiring using @Bean methods provides complete control over object construction when auto-scanning is insufficient or impossible. It is required for integrating third-party libraries, creating beans conditionally based on profiles, or implementing complex initialization sequences. Unlike component scanning, manual wiring makes dependencies explicit in the configuration class and allows precise control over bean instantiation order and property setting."
            },
            "code": {
              "title": "Complex Bean Wiring",
              "language": "java",
              "content": "@Configuration\npublic class IntegrationConfig {\n    \n    private final ApiProperties properties;\n    \n    public IntegrationConfig(ApiProperties properties) {\n        this.properties = properties;\n    }\n    \n    @Bean\n    public ApiClient apiClient() {\n        // Complex construction logic not possible with simple @Component\n        ApiClient client = new ApiClient(properties.getEndpoint());\n        client.setRateLimiter(new RateLimiter(properties.getRateLimit()));\n        client.setRetryPolicy(new ExponentialBackoffRetry());\n        return client;\n    }\n}"
            },
            "codeExplanations": {
              "english": "This example shows wiring a third-party ApiClient requiring constructor arguments and setter configuration that cannot be achieved through simple component scanning. The configuration class itself uses constructor injection for its dependencies."
            },
            "keyPoints": [
              "Required for third-party classes without @Component",
              "Enables complex initialization logic",
              "Allows conditional bean creation based on environment",
              "Provides explicit control over dependency instantiation"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "core-di-22",
            "title": "@Qualifier",
            "explanations": {
              "english": "@Qualifier is used alongside @Autowired to disambiguate between multiple beans of the same type in the Spring container. It specifies which named bean should be injected when type-based resolution finds multiple candidates. The value attribute must match the bean identifier (either the method name for @Bean definitions or the component name). It resolves NoUniqueBeanDefinitionException by explicitly selecting among the available candidates."
            },
            "code": {
              "title": "Disambiguating Bean Selection",
              "language": "java",
              "content": "@Configuration\npublic class NotificationConfig {\n    @Bean\n    public NotificationService emailNotifier() {\n        return new EmailNotificationService();\n    }\n    \n    @Bean\n    public NotificationService smsNotifier() {\n        return new SmsNotificationService();\n    }\n}\n\n@Service\npublic class AlertService {\n    private final NotificationService notifier;\n    \n    public AlertService(@Qualifier(\"emailNotifier\") NotificationService notifier) {\n        this.notifier = notifier;\n    }\n}"
            },
            "codeExplanations": {
              "english": "Two NotificationService beans exist. Without @Qualifier, Spring would throw NoUniqueBeanDefinitionException. The @Qualifier annotation specifies that the bean named 'emailNotifier' should be injected into AlertService."
            },
            "keyPoints": [
              "Resolves ambiguity when multiple beans of same type exist",
              "Used with @Autowired to specify bean by name",
              "Value must match the target bean's identifier",
              "Prevents NoUniqueBeanDefinitionException"
            ],
            "extras": {
              "flowDiagram": "AlertService -> @Qualifier(\"emailNotifier\") -> emailNotifier bean\n               -> smsNotifier bean (ignored)",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "core-di-23",
            "title": "@Primary",
            "explanations": {
              "english": "@Primary marks a bean as the preferred candidate when multiple beans of the same type are candidates for autowiring. When a dependency of that type is requested and no specific @Qualifier is provided, the @Primary bean is chosen. This reduces the need for @Qualifier annotations in the common case while allowing specific injection of non-primary beans when needed. Only one @Primary bean is allowed per type in a given context."
            },
            "code": {
              "title": "Primary Bean Preference",
              "language": "java",
              "content": "@Configuration\npublic class StorageConfig {\n    @Primary\n    @Bean\n    public FileStorageService localStorage() {\n        return new LocalFileStorageService();\n    }\n    \n    @Bean\n    public FileStorageService cloudStorage() {\n        return new CloudFileStorageService();\n    }\n}\n\n@Service\npublic class DocumentService {\n    // Injects localStorage (the primary bean)\n    public DocumentService(FileStorageService storage) {}\n}\n\n@Service\npublic class BackupService {\n    // Explicitly injects cloudStorage\n    public BackupService(@Qualifier(\"cloudStorage\") FileStorageService storage) {}\n}"
            },
            "codeExplanations": {
              "english": "FileStorageService has two implementations. @Primary on localStorage makes it the default for all injection points. BackupService can still access cloudStorage using @Qualifier when specific behavior is required."
            },
            "keyPoints": [
              "Marks the default bean when multiple candidates exist",
              "Eliminates need for @Qualifier for the common case",
              "Only one bean per type can be @Primary",
              "Can be overridden by explicit @Qualifier usage"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [
                {
                  "headers": [
                    "Scenario",
                    "Behavior"
                  ],
                  "rows": [
                    [
                      "No @Primary, no @Qualifier",
                      "NoUniqueBeanDefinitionException thrown"
                    ],
                    [
                      "@Primary present, no @Qualifier",
                      "Primary bean injected"
                    ],
                    [
                      "@Qualifier present",
                      "Specified bean injected (ignores @Primary)"
                    ],
                    [
                      "Multiple @Primary",
                      "BeanDefinitionException at startup"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "core-di-24",
            "title": "Resolving Multiple Bean Conflicts",
            "explanations": {
              "english": "When Spring detects multiple eligible beans for a single injection point, it throws NoUniqueBeanDefinitionException. Resolution strategies include: using @Primary to mark a default candidate for that type, using @Qualifier to explicitly specify the desired bean name, or collecting all candidates into a List or Map of the dependency type. For collections, Spring injects all beans of the matching type. Understanding these resolution mechanisms prevents startup failures and provides flexibility in complex application architectures."
            },
            "code": {
              "title": "Conflict Resolution Strategies",
              "language": "java",
              "content": "@Service\npublic class NotificationDispatcher {\n    // Strategy 1: Inject all implementations into a List\n    private final List<NotificationService> allNotifiers;\n    \n    // Strategy 2: Inject all into a Map (key = bean name)\n    private final Map<String, NotificationService> notifierMap;\n    \n    // Strategy 3: Use @Primary for default\n    private final NotificationService primaryNotifier;\n    \n    // Strategy 4: Use @Qualifier for specific\n    public NotificationDispatcher(\n            List<NotificationService> allNotifiers,\n            Map<String, NotificationService> notifierMap,\n            NotificationService primaryNotifier,\n            @Qualifier(\"smsNotifier\") NotificationService specificNotifier) {\n        this.allNotifiers = allNotifiers;\n        this.notifierMap = notifierMap;\n        this.primaryNotifier = primaryNotifier;\n    }\n}"
            },
            "codeExplanations": {
              "english": "Demonstrates four resolution approaches: 1) List injection receives all beans, 2) Map injection receives all beans with their names as keys, 3) @Primary determines default, 4) @Qualifier specifies exact bean. These can be combined in the same application based on requirements."
            },
            "keyPoints": [
              "Use @Primary to designate the default bean",
              "Use @Qualifier to select specific beans by name",
              "Inject List<Type> or Map<String, Type> to receive all beans",
              "Plan bean naming strategy to support @Qualifier usage"
            ],
            "extras": {
              "flowDiagram": "Multiple Beans -> Decision: @Qualifier? -> Yes -> Specific Bean\n                        -> No -> @Primary? -> Yes -> Primary Bean\n                                    -> No -> Collection? -> Yes -> All Beans\n                                                -> No -> Exception",
              "comparisonTable": [],
              "examples": []
            }
          }
        ]
      },
      {
        "id": "web-rest-layer",
        "title": "Web / REST Layer",
        "description": "Master Spring MVC architecture, RESTful controller design, request/response handling, and global exception management for building robust web APIs and traditional web applications.",
        "topics": [
          {
            "id": "web-rest-1",
            "title": "DispatcherServlet (Front Controller)",
            "explanations": {
              "english": "The DispatcherServlet acts as the front controller in Spring MVC, receiving all incoming HTTP requests and delegating them to appropriate handler components. It serves as the central entry point that coordinates request processing by consulting HandlerMappings to determine the target controller, invoking HandlerAdapters to execute methods, and processing ViewResolvers for rendering. In Spring Boot, it is auto-configured and mapped to the root path by default. It manages the entire request lifecycle including exception handling, interceptor execution, and view rendering coordination."
            },
            "code": {
              "title": "Custom DispatcherServlet Configuration",
              "language": "java",
              "content": "@Configuration\npublic class WebConfig {\n    \n    @Bean\n    public ServletRegistrationBean<DispatcherServlet> dispatcherServletRegistration() {\n        ServletRegistrationBean<DispatcherServlet> registration = new ServletRegistrationBean<>(\n            new DispatcherServlet(), \"/api/*\"\n        );\n        registration.setLoadOnStartup(1);\n        registration.setName(\"api-dispatcher\");\n        return registration;\n    }\n}"
            },
            "codeExplanations": {
              "english": "While Spring Boot auto-configures DispatcherServlet, this shows how to customize its mapping. The servlet is mapped to /api/* instead of root, setting load order to startup priority 1. Normally customization is done via properties rather than explicit bean definition."
            },
            "keyPoints": [
              "Central entry point for all HTTP requests in Spring MVC",
              "Delegates to HandlerMappings, HandlerAdapters, and ViewResolvers",
              "Auto-configured by Spring Boot with default mapping to root path",
              "Manages the complete request processing workflow and exception translation"
            ],
            "extras": {
              "flowDiagram": "HTTP Request -> DispatcherServlet -> HandlerMapping -> Controller -> HandlerAdapter -> ViewResolver -> View -> HTTP Response",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "web-rest-2",
            "title": "Handler Mappings",
            "explanations": {
              "english": "Handler Mappings map incoming HTTP requests to appropriate controller handler methods based on criteria such as URL patterns, HTTP methods, request parameters, and headers. RequestMappingHandlerMapping is the default implementation that processes @RequestMapping annotations. It maintains a mapping registry of all controller methods and performs pattern matching against incoming requests. Advanced configurations can include path prefixes, custom matching strategies, and interceptor mappings."
            },
            "code": {
              "title": "Handler Mapping Configuration",
              "language": "java",
              "content": "@Configuration\npublic class WebMvcConfig implements WebMvcConfigurer {\n    \n    @Override\n    public void configurePathMatch(PathMatchConfigurer configurer) {\n        configurer.addPathPrefix(\"/api/v1\", HandlerTypePredicate.forAnnotation(RestController.class));\n    }\n    \n    @Bean\n    public HandlerMapping customHandlerMapping() {\n        RequestMappingHandlerMapping mapping = new RequestMappingHandlerMapping();\n        mapping.setUseSuffixPatternMatch(false);\n        mapping.setUseTrailingSlashMatch(true);\n        return mapping;\n    }\n}"
            },
            "codeExplanations": {
              "english": "configurePathMatch adds a global /api/v1 prefix to all @RestController classes. The custom HandlerMapping bean disables suffix pattern matching (avoiding .json/.xml extensions) while allowing trailing slashes in URLs for flexibility."
            },
            "keyPoints": [
              "Maps requests to controller methods based on URL patterns and HTTP methods",
              "RequestMappingHandlerMapping processes @RequestMapping annotations by default",
              "Supports path prefixes and custom matching strategies",
              "Integrates with interceptors for cross-cutting request processing"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "web-rest-3",
            "title": "View Resolvers",
            "explanations": {
              "english": "View Resolvers translate logical view names returned by controllers into actual view implementations for rendering responses. In traditional MVC applications, InternalResourceViewResolver resolves JSP views while ThymeleafViewResolver handles Thymeleaf templates. They determine the view technology, locate the template resource, and prepare the view instance with necessary configuration. In REST applications with @RestController, view resolution is bypassed in favor of message converters that serialize objects directly to the response body."
            },
            "code": {
              "title": "View Resolver Configuration",
              "language": "java",
              "content": "@Configuration\npublic class ViewConfig {\n    \n    @Bean\n    public ViewResolver thymeleafViewResolver(SpringTemplateEngine templateEngine) {\n        ThymeleafViewResolver resolver = new ThymeleafViewResolver();\n        resolver.setTemplateEngine(templateEngine);\n        resolver.setCharacterEncoding(\"UTF-8\");\n        resolver.setContentType(\"text/html\");\n        resolver.setViewNames(new String[]{\"*.html\"});\n        return resolver;\n    }\n    \n    @Bean\n    public ViewResolver internalResourceViewResolver() {\n        InternalResourceViewResolver resolver = new InternalResourceViewResolver();\n        resolver.setPrefix(\"/WEB-INF/views/\");\n        resolver.setSuffix(\".jsp\");\n        resolver.setViewClass(JstlView.class);\n        return resolver;\n    }\n}"
            },
            "codeExplanations": {
              "english": "Configures two view resolvers: Thymeleaf for HTML templates with UTF-8 encoding, and InternalResourceViewResolver for JSP files located in /WEB-INF/views/. The order of registration determines resolution priority."
            },
            "keyPoints": [
              "Resolves logical view names to physical view implementations",
              "Different resolvers handle different view technologies (JSP, Thymeleaf, FreeMarker)",
              "InternalResourceViewResolver is standard for JSP-based applications",
              "Chained resolvers attempt resolution in order until a match is found"
            ],
            "extras": {
              "flowDiagram": "Controller returns 'user/detail' -> ViewResolver -> /WEB-INF/views/user/detail.jsp -> Render",
              "comparisonTable": [
                {
                  "headers": [
                    "View Technology",
                    "Resolver Class",
                    "Template Location"
                  ],
                  "rows": [
                    [
                      "JSP",
                      "InternalResourceViewResolver",
                      "/WEB-INF/views/"
                    ],
                    [
                      "Thymeleaf",
                      "ThymeleafViewResolver",
                      "classpath:/templates/"
                    ],
                    [
                      "FreeMarker",
                      "FreeMarkerViewResolver",
                      "classpath:/templates/"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "web-rest-4",
            "title": "@Controller vs @RestController",
            "explanations": {
              "english": "In the web layer context, @Controller is used for traditional server-rendered applications where methods return view names resolved by ViewResolvers. @RestController is specifically designed for RESTful APIs, combining @Controller with @ResponseBody to serialize return values directly to the HTTP response body using HttpMessageConverters. When building microservices or API backends, @RestController is the standard choice, while @Controller remains relevant for MVC applications with HTML views."
            },
            "code": {
              "title": "Web Layer Usage Patterns",
              "language": "java",
              "content": "@Controller\npublic class PageController {\n    @GetMapping(\"/dashboard\")\n    public String dashboard(Model model) {\n        model.addAttribute(\"stats\", statsService.getStats());\n        return \"admin/dashboard\"; // Resolves to dashboard.html\n    }\n}\n\n@RestController\n@RequestMapping(\"/api/analytics\")\npublic class AnalyticsRestController {\n    @GetMapping(\"/stats\")\n    public ResponseEntity<Stats> getStats() {\n        return ResponseEntity.ok(statsService.getStats());\n    }\n}"
            },
            "codeExplanations": {
              "english": "PageController demonstrates traditional MVC returning view names for HTML rendering. AnalyticsRestController shows REST API development returning data objects that convert to JSON automatically via message converters."
            },
            "keyPoints": [
              "@Controller for server-rendered views and page navigation",
              "@RestController for API endpoints returning serialized data",
              "@RestController eliminates need for @ResponseBody on each method",
              "Both support the same request mapping annotations and injection capabilities"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [
                {
                  "headers": [
                    "Aspect",
                    "@Controller",
                    "@RestController"
                  ],
                  "rows": [
                    [
                      "Primary Use",
                      "Server-rendered web pages",
                      "REST APIs / JSON endpoints"
                    ],
                    [
                      "Return Value",
                      "View name string",
                      "Domain object / ResponseEntity"
                    ],
                    [
                      "View Resolution",
                      "Processed by ViewResolver",
                      "Skipped, uses HttpMessageConverter"
                    ],
                    [
                      "HTTP Response",
                      "Rendered HTML page",
                      "Raw data (JSON/XML)"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "web-rest-5",
            "title": "HTTP Method Mappings",
            "explanations": {
              "english": "Spring MVC provides specialized annotations for mapping HTTP methods to handler methods: @GetMapping for resource retrieval, @PostMapping for resource creation, @PutMapping for full resource updates, and @DeleteMapping for resource deletion. These are composed annotations that combine @RequestMapping with the specific HTTP method. They support URI templates, consumption of specific content types, and production of specific response formats. Proper use of these semantic mappings creates RESTful interfaces that follow HTTP protocol conventions."
            },
            "code": {
              "title": "CRUD Operation Mappings",
              "language": "java",
              "content": "@RestController\n@RequestMapping(\"/api/products\")\npublic class ProductController {\n    \n    @GetMapping\n    public List<Product> listAll() { return service.findAll(); }\n    \n    @GetMapping(\"/{id}\")\n    public Product getById(@PathVariable Long id) { return service.findById(id); }\n    \n    @PostMapping(consumes = MediaType.APPLICATION_JSON_VALUE)\n    public ResponseEntity<Product> create(@RequestBody @Valid Product product) {\n        Product saved = service.save(product);\n        URI location = ServletUriComponentsBuilder\n            .fromCurrentRequest().path(\"/{id}\").buildAndExpand(saved.getId()).toUri();\n        return ResponseEntity.created(location).body(saved);\n    }\n    \n    @PutMapping(\"/{id}\")\n    public Product update(@PathVariable Long id, @RequestBody Product product) {\n        return service.update(id, product);\n    }\n    \n    @DeleteMapping(\"/{id}\")\n    @ResponseStatus(HttpStatus.NO_CONTENT)\n    public void delete(@PathVariable Long id) {\n        service.delete(id);\n    }\n}"
            },
            "codeExplanations": {
              "english": "Demonstrates full CRUD mapping: GET for retrieval (collection and single), POST for creation with JSON consumption and 201 CREATED response with Location header, PUT for updates, DELETE with 204 NO_CONTENT. Each mapping uses appropriate HTTP semantics and status codes."
            },
            "keyPoints": [
              "@GetMapping retrieves resources without side effects",
              "@PostMapping creates new resources and returns 201 Created with Location header",
              "@PutMapping performs full resource updates (idempotent)",
              "@DeleteMapping removes resources and typically returns 204 No Content"
            ],
            "extras": {
              "flowDiagram": "Client -> GET /products -> List\n       -> GET /products/1 -> Single\n       -> POST /products -> Create -> 201\n       -> PUT /products/1 -> Update -> 200\n       -> DELETE /products/1 -> Remove -> 204",
              "comparisonTable": [
                {
                  "headers": [
                    "Annotation",
                    "HTTP Method",
                    "Idempotent",
                    "Safe"
                  ],
                  "rows": [
                    [
                      "@GetMapping",
                      "GET",
                      "Yes",
                      "Yes"
                    ],
                    [
                      "@PostMapping",
                      "POST",
                      "No",
                      "No"
                    ],
                    [
                      "@PutMapping",
                      "PUT",
                      "Yes",
                      "No"
                    ],
                    [
                      "@DeleteMapping",
                      "DELETE",
                      "Yes",
                      "No"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "web-rest-6",
            "title": "@PathVariable",
            "explanations": {
              "english": "@PathVariable extracts values from URI template variables defined in the request mapping path. It binds path segments to method parameters, automatically converting types using Spring's type conversion system. The variable name in the annotation must match the template variable name in the path, or explicitly specified using the value attribute. It supports optional parameters through required=false and custom regular expressions for validation within the path pattern itself."
            },
            "code": {
              "title": "Path Variable Extraction",
              "language": "java",
              "content": "@RestController\npublic class OrderController {\n    \n    @GetMapping(\"/orders/{orderId}\")\n    public Order getOrder(@PathVariable Long orderId) {\n        return orderService.findById(orderId);\n    }\n    \n    @GetMapping(\"/users/{userId}/orders/{orderId}\")\n    public Order getUserOrder(\n            @PathVariable(\"userId\") Long userId,\n            @PathVariable Long orderId) {\n        return orderService.findByUserAndId(userId, orderId);\n    }\n    \n    @GetMapping(\"/files/{filename:.+}\")  // Regex to capture dots in filename\n    public ResponseEntity<Resource> downloadFile(@PathVariable String filename) {\n        return ResponseEntity.ok(fileService.load(filename));\n    }\n}"
            },
            "codeExplanations": {
              "english": "First example shows simple extraction where parameter name matches path variable. Second shows explicit mapping when parameter name differs from path variable. Third demonstrates regex patterns to handle file extensions with dots that would otherwise be truncated."
            },
            "keyPoints": [
              "Extracts URI template variables into method parameters",
              "Supports type conversion from String to target parameter type",
              "Variable name must match path template or be explicitly specified",
              "Can include regular expressions for advanced path matching"
            ],
            "extras": {
              "flowDiagram": "URL /orders/123 -> @PathVariable Long orderId -> value 123L",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "web-rest-7",
            "title": "@RequestParam",
            "explanations": {
              "english": "@RequestParam binds HTTP query parameters and form data to method parameters in controller methods. It handles type conversion automatically and supports default values through the defaultValue attribute, making parameters effectively required=false. For optional parameters without defaults, required can be set to false allowing null values. It is commonly used for filtering, pagination, and search operations in GET requests where data is passed in the URL rather than the path."
            },
            "code": {
              "title": "Query Parameter Handling",
              "language": "java",
              "content": "@GetMapping(\"/products\")\npublic Page<Product> searchProducts(\n        @RequestParam(required = false) String category,\n        @RequestParam(defaultValue = \"0\") int page,\n        @RequestParam(defaultValue = \"20\") int size,\n        @RequestParam(name = \"sort_by\", defaultValue = \"name\") String sortBy,\n        @RequestParam(required = false) List<String> tags) {\n    \n    Pageable pageable = PageRequest.of(page, size, Sort.by(sortBy));\n    return productService.search(category, tags, pageable);\n}"
            },
            "codeExplanations": {
              "english": "Demonstrates various @RequestParam patterns: optional category filter, pagination with defaults (page 0, size 20), aliased parameter name (sort_by mapped to sortBy), and multi-value parameters for tags. All parameters are automatically converted from String to the target types."
            },
            "keyPoints": [
              "Binds query string parameters and form data to method arguments",
              "Supports default values for missing parameters",
              "Handles automatic type conversion from String",
              "Can map different query parameter names to method argument names"
            ],
            "extras": {
              "flowDiagram": "URL /products?category=electronics&page=0 -> @RequestParam category=\"electronics\", page=0",
              "comparisonTable": [
                {
                  "headers": [
                    "Aspect",
                    "@PathVariable",
                    "@RequestParam"
                  ],
                  "rows": [
                    [
                      "Source",
                      "URI path /users/{id}",
                      "Query string ?key=value"
                    ],
                    [
                      "Use Case",
                      "Resource identifiers",
                      "Filters, pagination, options"
                    ],
                    [
                      "Required",
                      "Typically yes",
                      "Often optional with defaults"
                    ],
                    [
                      "URL Example",
                      "/orders/123",
                      "/orders?status=pending"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "web-rest-8",
            "title": "@RequestBody",
            "explanations": {
              "english": "@RequestBody deserializes HTTP request body content (typically JSON or XML) into Java objects using HttpMessageConverters. It is essential for REST APIs processing POST and PUT requests with payload data. The annotation supports validation when combined with @Valid or @Validated, triggering JSR-303 Bean Validation. Spring uses content negotiation to determine the converter based on the Content-Type header. For JSON, MappingJackson2HttpMessageConverter is typically used by default in Spring Boot applications."
            },
            "code": {
              "title": "Request Body Deserialization",
              "language": "java",
              "content": "@PostMapping(\"/users\")\npublic ResponseEntity<User> createUser(\n        @RequestBody @Valid UserDto userDto,\n        @RequestHeader(\"X-Api-Key\") String apiKey) {\n    \n    User created = userService.create(userDto, apiKey);\n    return ResponseEntity.status(HttpStatus.CREATED).body(created);\n}\n\npublic record UserDto(\n    @NotBlank String username,\n    @Email String email,\n    @Size(min = 8) String password\n) {}"
            },
            "codeExplanations": {
              "english": "@RequestBody converts incoming JSON into UserDto object. @Valid triggers validation annotations on the DTO fields. If validation fails, MethodArgumentNotValidException is thrown before reaching the method body."
            },
            "keyPoints": [
              "Deserializes HTTP request body into Java objects using HttpMessageConverters",
              "Works with @Valid to enforce bean validation rules",
              "Requires Content-Type header matching supported media types",
              "Commonly used with JSON payloads in REST APIs"
            ],
            "extras": {
              "flowDiagram": "JSON Request Body -> HttpMessageConverter -> Java Object -> @Valid -> Method Parameter",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "web-rest-9",
            "title": "@ResponseBody",
            "explanations": {
              "english": "@ResponseBody indicates that a method return value should be bound to the HTTP response body rather than resolved as a view name. Spring converts the return object to the response format (JSON, XML, etc.) using registered HttpMessageConverters. When placed on individual methods within a @Controller class, it enables those specific methods to act as REST endpoints while others return views. It is implicitly included in @RestController, making explicit usage redundant in those classes."
            },
            "code": {
              "title": "Mixed Controller Usage",
              "language": "java",
              "content": "@Controller\n@RequestMapping(\"/items\")\npublic class ItemController {\n    \n    @GetMapping(\"/{id}/view\")\n    public String viewItem(@PathVariable Long id, Model model) {\n        model.addAttribute(\"item\", itemService.findById(id));\n        return \"item/detail\"; // View resolution\n    }\n    \n    @GetMapping(\"/{id}\")\n    @ResponseBody\n    public Item getItemJson(@PathVariable Long id) {\n        return itemService.findById(id); // Serialized to JSON\n    }\n    \n    @GetMapping(value = \"/{id}\", produces = MediaType.APPLICATION_XML_VALUE)\n    @ResponseBody\n    public ItemXmlWrapper getItemXml(@PathVariable Long id) {\n        return new ItemXmlWrapper(itemService.findById(id));\n    }\n}"
            },
            "codeExplanations": {
              "english": "The same controller mixes view-returning methods with @ResponseBody methods. The JSON endpoint uses default MappingJackson2HttpMessageConverter. The XML endpoint specifies produces to trigger XML converter selection based on Accept headers."
            },
            "keyPoints": [
              "Binds method return value directly to HTTP response body",
              "Triggers message conversion based on Accept header and produces attribute",
              "Allows selective REST endpoints within traditional @Controller classes",
              "Implicitly present on all methods when using @RestController"
            ],
            "extras": {
              "flowDiagram": "Java Object -> HttpMessageConverter -> HTTP Response Body (JSON/XML)",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "web-rest-10",
            "title": "ResponseEntity",
            "explanations": {
              "english": "ResponseEntity provides full programmatic control over the HTTP response including status codes, headers, and body content. It allows returning different status codes based on business logic (200 OK, 201 Created, 404 Not Found), setting custom headers like Location for newly created resources, and controlling cache directives. As a generic wrapper, it maintains type safety for the response body while offering a fluent builder API for constructing responses. It is preferred over @ResponseStatus annotations when dynamic response construction is needed."
            },
            "code": {
              "title": "Advanced Response Building",
              "language": "java",
              "content": "@GetMapping(\"/{id}\")\npublic ResponseEntity<Resource> downloadDocument(@PathVariable String id) {\n    Resource resource = documentService.loadAsResource(id);\n    \n    if (resource == null) {\n        return ResponseEntity.notFound().build();\n    }\n    \n    return ResponseEntity.ok()\n        .contentType(MediaType.APPLICATION_PDF)\n        .header(HttpHeaders.CONTENT_DISPOSITION, \n                \"attachment; filename=\\\"\" + resource.getFilename() + \"\\\"\")\n        .cacheControl(CacheControl.maxAge(24, TimeUnit.HOURS))\n        .eTag(resource.getMd5())\n        .body(resource);\n}\n\n@PostMapping\npublic ResponseEntity<Void> createResource(@RequestBody ResourceRequest request) {\n    String id = service.create(request);\n    URI location = ServletUriComponentsBuilder\n        .fromCurrentRequest().path(\"/{id}\").buildAndExpand(id).toUri();\n    \n    return ResponseEntity.created(location).build();\n}"
            },
            "codeExplanations": {
              "english": "First example shows comprehensive response building with conditional 404, content type setting, download headers, caching directives, and ETag for HTTP caching. Second demonstrates 201 Created with Location header for REST compliance using the builder pattern."
            },
            "keyPoints": [
              "Provides complete control over HTTP response status, headers, and body",
              "Supports fluent API for building responses (ok(), created(), notFound())",
              "Enables dynamic status code selection based on business logic",
              "Type-safe wrapper for response body content"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [
                {
                  "headers": [
                    "Approach",
                    "Flexibility",
                    "Use Case"
                  ],
                  "rows": [
                    [
                      "@ResponseStatus",
                      "Static per method/class",
                      "Fixed success codes"
                    ],
                    [
                      "ResponseEntity",
                      "Dynamic per execution",
                      "Conditional responses, custom headers"
                    ],
                    [
                      "ResponseStatusException",
                      "Exception-based",
                      "Error handling in catch blocks"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "web-rest-11",
            "title": "Global Exception Handling (@ControllerAdvice)",
            "explanations": {
              "english": "@ControllerAdvice provides global exception handling across multiple controllers by consolidating @ExceptionHandler, @InitBinder, and @ModelAttribute methods in a single class. It intercepts exceptions thrown by any controller and transforms them into standardized HTTP responses, preventing stack traces from leaking to clients. Common use cases include handling validation errors, resource not found scenarios, and business logic exceptions. It can be restricted to specific controller packages or annotations using basePackages or basePackageClasses attributes."
            },
            "code": {
              "title": "Global Exception Handler",
              "language": "java",
              "content": "@ControllerAdvice\npublic class GlobalExceptionHandler {\n    \n    private static final Logger log = LoggerFactory.getLogger(GlobalExceptionHandler.class);\n    \n    @ExceptionHandler(ResourceNotFoundException.class)\n    public ResponseEntity<ErrorResponse> handleNotFound(ResourceNotFoundException ex, WebRequest request) {\n        ErrorResponse error = new ErrorResponse(\n            HttpStatus.NOT_FOUND.value(),\n            ex.getMessage(),\n            request.getDescription(false)\n        );\n        return new ResponseEntity<>(error, HttpStatus.NOT_FOUND);\n    }\n    \n    @ExceptionHandler(MethodArgumentNotValidException.class)\n    public ResponseEntity<Map<String, Object>> handleValidationErrors(MethodArgumentNotValidException ex) {\n        Map<String, String> errors = ex.getBindingResult().getFieldErrors().stream()\n            .collect(Collectors.toMap(FieldError::getField, FieldError::getDefaultMessage));\n        \n        return ResponseEntity.badRequest().body(Map.of(\"errors\", errors));\n    }\n    \n    @ExceptionHandler(Exception.class)\n    public ResponseEntity<ErrorResponse> handleGeneric(Exception ex, WebRequest request) {\n        log.error(\"Unhandled exception\", ex);\n        ErrorResponse error = new ErrorResponse(\n            HttpStatus.INTERNAL_SERVER_ERROR.value(),\n            \"An unexpected error occurred\",\n            request.getDescription(false)\n        );\n        return new ResponseEntity<>(error, HttpStatus.INTERNAL_SERVER_ERROR);\n    }\n    \n    public record ErrorResponse(int status, String message, String path) {}\n}"
            },
            "codeExplanations": {
              "english": "This advice class handles three exception types: custom ResourceNotFoundException returns 404 with details, validation errors return 400 with field-specific error maps, and generic exceptions return 500 while logging the stack trace internally for security."
            },
            "keyPoints": [
              "Centralizes exception handling logic for multiple controllers",
              "Eliminates duplicate try-catch blocks across controllers",
              "Supports fine-grained mapping via exception class hierarchy",
              "Can include @ModelAttribute and @InitBinder for shared controller preparation"
            ],
            "extras": {
              "flowDiagram": "Controller throws Exception -> @ControllerAdvice intercepts -> @ExceptionHandler method -> Standardized Error Response",
              "comparisonTable": [],
              "examples": []
            }
          }
        ]
      },
      {
        "id": "data-database-layer",
        "title": "Data / Database Layer",
        "description": "Master data persistence with Spring Data JPA, Hibernate integration, query optimization strategies, transaction management, and handling common ORM pitfalls in enterprise applications.",
        "topics": [
          {
            "id": "data-1",
            "title": "CrudRepository Interface",
            "explanations": {
              "english": "CrudRepository is the foundational interface in Spring Data providing generic CRUD (Create, Read, Update, Delete) operations for entity management. It extends Repository and offers methods like save(), findById(), findAll(), deleteById() without requiring implementation code. When extended by a domain-specific interface, Spring Data generates the implementation dynamically at runtime using proxy objects. It is suitable for simple data access needs where basic persistence operations are sufficient."
            },
            "code": {
              "title": "Basic CrudRepository Usage",
              "language": "java",
              "content": "public interface CustomerRepository extends CrudRepository<Customer, Long> {\n    // Basic CRUD methods inherited: save, findById, findAll, delete, etc.\n}\n\n@Service\npublic class CustomerService {\n    private final CustomerRepository repository;\n    \n    public Customer createCustomer(Customer customer) {\n        return repository.save(customer);\n    }\n    \n    public Optional<Customer> findCustomer(Long id) {\n        return repository.findById(id);\n    }\n    \n    public void deleteCustomer(Long id) {\n        repository.deleteById(id);\n    }\n}"
            },
            "codeExplanations": {
              "english": "The CustomerRepository interface extends CrudRepository with Customer as the entity type and Long as the identifier type. No implementation is required; Spring Data provides the actual implementation at runtime. The service layer uses these methods for basic persistence operations."
            },
            "keyPoints": [
              "Provides basic CRUD operations out of the box",
              "No implementation code required - Spring generates proxy at runtime",
              "Generic types: <Entity, ID>",
              "Suitable for simple data access without pagination or sorting needs"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "data-2",
            "title": "JpaRepository Interface",
            "explanations": {
              "english": "JpaRepository extends CrudRepository and PagingAndSortingRepository to provide JPA-specific operations. It adds batch operations like saveAll(), flushing capabilities with saveAndFlush(), and retrieval methods that return List instead of Iterable for easier processing. It also provides CRUD methods that operate directly with JPA EntityManager. This is the preferred interface for JPA-based applications requiring pagination, sorting, or advanced persistence features."
            },
            "code": {
              "title": "JpaRepository with Pagination",
              "language": "java",
              "content": "public interface ProductRepository extends JpaRepository<Product, Long> {\n    // Inherits: findAll(Pageable), findAll(Sort), saveAndFlush, etc.\n}\n\n@Service\npublic class ProductService {\n    private final ProductRepository repository;\n    \n    public Page<Product> getProducts(int page, int size, String sortBy) {\n        Pageable pageable = PageRequest.of(page, size, Sort.by(sortBy).ascending());\n        return repository.findAll(pageable);\n    }\n    \n    public List<Product> saveAllProducts(List<Product> products) {\n        return repository.saveAll(products);\n    }\n    \n    public void flushChanges() {\n        repository.flush();\n    }\n}"
            },
            "codeExplanations": {
              "english": "JpaRepository provides pageable queries through findAll(Pageable) returning a Page object containing results plus metadata (total elements, total pages). saveAll() performs batch inserts efficiently. flush() synchronizes persistence context state with the database."
            },
            "keyPoints": [
              "Extends CrudRepository with JPA-specific methods",
              "Supports pagination and sorting through Pageable and Sort parameters",
              "Returns List<T> instead of Iterable<T> for convenience",
              "Includes flush() and saveAndFlush() for immediate persistence"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [
                {
                  "headers": [
                    "Feature",
                    "CrudRepository",
                    "JpaRepository"
                  ],
                  "rows": [
                    [
                      "Pagination",
                      "No",
                      "Yes (via PagingAndSorting)"
                    ],
                    [
                      "Sorting",
                      "No",
                      "Yes"
                    ],
                    [
                      "Return Type",
                      "Iterable",
                      "List"
                    ],
                    [
                      "Flush Operations",
                      "No",
                      "Yes"
                    ],
                    [
                      "Batch Save",
                      "No",
                      "saveAll()"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "data-3",
            "title": "@Entity",
            "explanations": {
              "english": "The @Entity annotation marks a Java class as a JPA entity, meaning it is mapped to a database table. The class must have a no-argument constructor (can be protected or public) and should not be final. By default, the entity name matches the class name, and the table name matches the entity name unless overridden with @Table. Entity classes represent the domain model in JPA and their instances are managed by the persistence context, enabling dirty checking and automatic state synchronization with the database."
            },
            "code": {
              "title": "JPA Entity Definition",
              "language": "java",
              "content": "@Entity\n@Table(name = \"users\", schema = \"public\")\npublic class User {\n    \n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n    \n    @Column(name = \"username\", nullable = false, unique = true, length = 50)\n    private String username;\n    \n    @Column(name = \"email\", nullable = false)\n    private String email;\n    \n    @Column(name = \"created_at\", updatable = false)\n    private LocalDateTime createdAt;\n    \n    protected User() {\n        // JPA requires no-arg constructor\n    }\n    \n    public User(String username, String email) {\n        this.username = username;\n        this.email = email;\n        this.createdAt = LocalDateTime.now();\n    }\n}"
            },
            "codeExplanations": {
              "english": "User is marked as an entity mapped to the 'users' table. @Column customizes database column attributes like nullability and length. A protected no-arg constructor satisfies JPA requirements while the public constructor enforces required fields."
            },
            "keyPoints": [
              "Marks the class as mappable to a database table",
              "Must have a no-argument constructor (protected or public)",
              "Class should not be final (proxying limitations)",
              "Fields are mapped to columns by default unless annotated otherwise"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "data-4",
            "title": "@Id and @GeneratedValue",
            "explanations": {
              "english": "@Id designates the primary key field of an entity. Every entity must have exactly one @Id field. @GeneratedValue configures automatic primary key generation strategies: IDENTITY (database auto-increment), SEQUENCE (database sequence), TABLE (sequence table), or AUTO (provider chooses). IDENTITY is common for MySQL and PostgreSQL, while SEQUENCE is preferred for Oracle and PostgreSQL to optimize batch inserts. The strategy choice affects performance and batch operation capabilities."
            },
            "code": {
              "title": "Primary Key Generation Strategies",
              "language": "java",
              "content": "@Entity\npublic class Order {\n    \n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n    \n    // Alternative: Sequence generation (better for batch)\n    @Id\n    @GeneratedValue(strategy = GenerationType.SEQUENCE, generator = \"order_seq\")\n    @SequenceGenerator(name = \"order_seq\", sequenceName = \"order_sequence\", allocationSize = 50)\n    private Long id;\n    \n    // Alternative: UUID generation\n    @Id\n    @GeneratedValue(generator = \"UUID\")\n    @GenericGenerator(name = \"UUID\", strategy = \"org.hibernate.id.UUIDGenerator\")\n    @Column(name = \"id\", updatable = false, nullable = false)\n    private UUID id;\n}"
            },
            "codeExplanations": {
              "english": "Shows three strategies: IDENTITY relies on database auto-increment. SEQUENCE uses database sequences with allocationSize for batch optimization (fetches 50 IDs at once). UUID uses Hibernate's UUID generator for distributed systems without centralized ID generation."
            },
            "keyPoints": [
              "@Id marks the primary key field",
              "GenerationType.IDENTITY: Database auto-increment, immediate insert on persist",
              "GenerationType.SEQUENCE: Database sequence, allows batching with allocationSize",
              "Never manually assign IDs when using generated values"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [
                {
                  "headers": [
                    "Strategy",
                    "Database Support",
                    "Batch Insert",
                    "Use Case"
                  ],
                  "rows": [
                    [
                      "IDENTITY",
                      "MySQL, PostgreSQL, SQL Server",
                      "No",
                      "Standard auto-increment"
                    ],
                    [
                      "SEQUENCE",
                      "PostgreSQL, Oracle, H2",
                      "Yes",
                      "High-performance batch operations"
                    ],
                    [
                      "UUID",
                      "All",
                      "Yes",
                      "Distributed systems, security"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "data-5",
            "title": "Entity Associations",
            "explanations": {
              "english": "JPA associations map relationships between entities: @OneToOne (single reference both ways), @OneToMany / @ManyToOne (parent-child hierarchies), and @ManyToMany (complex relationships via join tables). The mappedBy attribute indicates the inverse side of bidirectional relationships, while the default is unidirectional. FetchType determines loading strategy: LAZY (loaded on demand) or EAGER (loaded immediately). Bidirectional relationships require maintaining consistency in both sides in Java code."
            },
            "code": {
              "title": "Relationship Mapping",
              "language": "java",
              "content": "@Entity\npublic class Department {\n    @Id\n    @GeneratedValue\n    private Long id;\n    \n    @OneToMany(mappedBy = \"department\", cascade = CascadeType.ALL, orphanRemoval = true)\n    private List<Employee> employees = new ArrayList<>();\n    \n    public void addEmployee(Employee emp) {\n        employees.add(emp);\n        emp.setDepartment(this);\n    }\n}\n\n@Entity\npublic class Employee {\n    @Id\n    @GeneratedValue\n    private Long id;\n    \n    @ManyToOne(fetch = FetchType.LAZY)\n    @JoinColumn(name = \"dept_id\")\n    private Department department;\n    \n    @ManyToMany\n    @JoinTable(name = \"employee_project\",\n               joinColumns = @JoinColumn(name = \"emp_id\"),\n               inverseJoinColumns = @JoinColumn(name = \"proj_id\"))\n    private Set<Project> projects = new HashSet<>();\n}"
            },
            "codeExplanations": {
              "english": "Department has bidirectional OneToMany with Employee (mappedBy indicates Employee owns the foreign key). CascadeType.ALL propagates operations, orphanRemoval deletes employees removed from the list. Employee has ManyToOne (LAZY to avoid loading department unnecessarily) and ManyToMany with join table for projects."
            },
            "keyPoints": [
              "mappedBy indicates the inverse side of bidirectional relationships",
              "Always default to FetchType.LAZY to avoid unintended data loading",
              "CascadeType determines operation propagation to related entities",
              "Bidirectional relationships require helper methods to maintain consistency"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [
                {
                  "headers": [
                    "Association",
                    "Cardinality",
                    "Ownership"
                  ],
                  "rows": [
                    [
                      "@OneToOne",
                      "1:1",
                      "either side with join column"
                    ],
                    [
                      "@ManyToOne",
                      "N:1",
                      "always the many side (child)"
                    ],
                    [
                      "@OneToMany",
                      "1:N",
                      "inverse side (mappedBy)"
                    ],
                    [
                      "@ManyToMany",
                      "N:M",
                      "either side with @JoinTable"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "data-6",
            "title": "Derived Query Methods",
            "explanations": {
              "english": "Spring Data JPA derives queries from method names following specific naming conventions. Methods starting with findBy, readBy, or getBy followed by property names and operations (And, Or, LessThan, Like, etc.) are automatically implemented. The parser splits the method name into property expressions and operators, generating the appropriate JPQL query. While convenient for simple queries, complex queries with many conditions become unwieldy and should use @Query instead."
            },
            "code": {
              "title": "Method Name Queries",
              "language": "java",
              "content": "public interface OrderRepository extends JpaRepository<Order, Long> {\n    \n    List<Order> findByStatus(OrderStatus status);\n    \n    List<Order> findByStatusAndCreatedDateGreaterThan(OrderStatus status, LocalDateTime date);\n    \n    List<Order> findByCustomerEmailContainingIgnoreCase(String email);\n    \n    Optional<Order> findFirstByStatusOrderByCreatedDateDesc(OrderStatus status);\n    \n    boolean existsByOrderNumber(String orderNumber);\n    \n    long countByStatus(OrderStatus status);\n    \n    void deleteByStatusAndCreatedDateBefore(OrderStatus status, LocalDateTime date);\n}"
            },
            "codeExplanations": {
              "english": "Spring Data parses these method names to generate queries: findByStatus creates WHERE status = ?. And combines conditions. GreaterThan translates to > comparator. FirstBy with OrderBy adds LIMIT 1 and ORDER BY clauses. existsBy returns boolean instead of entity."
            },
            "keyPoints": [
              "Query derived from method name at startup",
              "Supports operations: And, Or, Like, GreaterThan, LessThan, Between, etc.",
              "First/Top keywords limit results (e.g., findFirstBy...)",
              "OrderBy adds sorting (ASC/DESC)",
              "Exists and Count prefixes return boolean and long respectively"
            ],
            "extras": {
              "flowDiagram": "Method Name: findByLastNameAndFirstNameIgnoreCase\nParsing: Property 'lastName' + Operator 'And' + Property 'firstName' + Modifier 'IgnoreCase'\nGenerated JPQL: SELECT o FROM Order o WHERE o.lastName = ?1 AND UPPER(o.firstName) = UPPER(?2)",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "data-7",
            "title": "@Query Annotation",
            "explanations": {
              "english": "@Query allows defining custom JPQL (Java Persistence Query Language) or native SQL queries directly on repository methods. It overrides the query derivation mechanism for complex operations unsupported by method naming conventions. Named parameters (e.g., :name) or positional parameters (?1) can bind method arguments. Setting nativeQuery=true switches to SQL instead of JPQL. @Query is also used for defining UPDATE or DELETE operations when combined with @Modifying."
            },
            "code": {
              "title": "Custom Query Definitions",
              "language": "java",
              "content": "public interface UserRepository extends JpaRepository<User, Long> {\n    \n    @Query(\"SELECT u FROM User u WHERE u.department.name = :deptName AND u.active = true\")\n    List<User> findActiveByDepartmentName(@Param(\"deptName\") String departmentName);\n    \n    @Query(value = \"SELECT * FROM users WHERE created_date > ?1\", nativeQuery = true)\n    List<User> findRecentUsersNative(LocalDateTime since);\n    \n    @Modifying\n    @Query(\"UPDATE User u SET u.lastLogin = CURRENT_TIMESTAMP WHERE u.id = :userId\")\n    int updateLastLogin(@Param(\"userId\") Long userId);\n    \n    @Query(\"SELECT new com.example.UserDto(u.id, u.email) FROM User u\")\n    List<UserDto> findAllForExport();\n}"
            },
            "codeExplanations": {
              "english": "First query uses named parameters with JPQL navigation to department.name. Second shows native SQL with positional parameter (?1). @Modifying indicates an update operation returning affected rows. Fourth uses constructor expression (new) to return DTO projections instead of entities."
            },
            "keyPoints": [
              "Defines explicit JPQL or SQL queries when derivation is insufficient",
              "Use @Param to bind named parameters in queries",
              "Set nativeQuery=true for database-specific SQL",
              "@Modifying required for UPDATE/DELETE operations",
              "Constructor expressions (new) enable DTO projections"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [
                {
                  "headers": [
                    "Aspect",
                    "Derived Methods",
                    "@Query"
                  ],
                  "rows": [
                    [
                      "Complexity",
                      "Simple conditions",
                      "Complex joins, aggregations, subqueries"
                    ],
                    [
                      "Optimization",
                      "Generic",
                      "Custom SQL hints, specific columns"
                    ],
                    [
                      "Flexibility",
                      "Limited to naming convention",
                      "Full JPQL/SQL support"
                    ],
                    [
                      "Maintainability",
                      "Can be verbose",
                      "Explicit and documented"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "data-8",
            "title": "JPQL vs Native SQL",
            "explanations": {
              "english": "JPQL (Java Persistence Query Language) operates on entity objects and their relationships rather than database tables, providing database independence and type safety. It supports polymorphic queries and entity inheritance naturally. Native SQL queries directly target database tables and columns, enabling use of vendor-specific features, complex optimizations, and database functions not supported by JPQL. While JPQL is preferred for portability, native SQL is necessary for performance tuning and leveraging specific database capabilities."
            },
            "code": {
              "title": "Query Language Comparison",
              "language": "java",
              "content": "// JPQL - Object-oriented, database agnostic\n@Query(\"SELECT o FROM Order o JOIN FETCH o.customer c WHERE c.region = :region\")\nList<Order> findOrdersWithCustomersByRegion(@Param(\"region\") String region);\n\n// Native SQL - Database specific, table-centric\n@Query(value = \"SELECT o.*, c.name as customer_name FROM orders o \" +\n               \"JOIN customers c ON o.customer_id = c.id \" +\n               \"WHERE c.region = :region \" +\n               \"AND o.created_date > CURRENT_DATE - INTERVAL '30 days'\", \n       nativeQuery = true)\nList<Order> findRecentOrdersNative(@Param(\"region\") String region);\n\n// Native with Entity mapping\n@Query(value = \"SELECT * FROM orders WHERE status = ?1\", nativeQuery = true)\n@Modifying\nList<Order> findByStatusNative(String status);"
            },
            "codeExplanations": {
              "english": "JPQL example uses entity names (Order, Customer) and association navigation (o.customer). JOIN FETCH eagerly loads related entities to prevent N+1. Native SQL uses actual table names and SQL syntax, allowing database-specific functions like INTERVAL operations."
            },
            "keyPoints": [
              "JPQL queries entities and relationships; SQL queries tables and columns",
              "JPQL provides database portability and polymorphic queries",
              "Native SQL enables vendor-specific optimizations and functions",
              "Use JPQL by default; fallback to native SQL for performance or complexity"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [
                {
                  "headers": [
                    "Characteristic",
                    "JPQL",
                    "Native SQL"
                  ],
                  "rows": [
                    [
                      "Syntax Target",
                      "Entity classes",
                      "Database tables"
                    ],
                    [
                      "Portability",
                      "Database independent",
                      "Vendor specific"
                    ],
                    [
                      "Caching",
                      "Supports 2nd level cache",
                      "May bypass cache"
                    ],
                    [
                      "Features",
                      "Standard JPA operations",
                      "Full SQL dialect features"
                    ],
                    [
                      "Return Type",
                      "Managed entities",
                      "May require @SqlResultSetMapping"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "data-9",
            "title": "Pagination Support",
            "explanations": {
              "english": "Pagination splits large result sets into manageable chunks using Pageable parameters. Spring Data JPA automatically appends LIMIT/OFFSET (or equivalent) clauses to queries when Pageable is passed. The Page<T> return type includes both the current page content and metadata (total elements, total pages, current page number). Slice<T> is a lighter alternative that only indicates whether more pages exist without counting total rows, improving performance for large datasets where exact counts are expensive."
            },
            "code": {
              "title": "Paginated Queries",
              "language": "java",
              "content": "public interface DocumentRepository extends JpaRepository<Document, Long> {\n    \n    // Automatic pagination for derived query\n    Page<Document> findByStatus(DocumentStatus status, Pageable pageable);\n    \n    // Custom query with pageable\n    @Query(\"SELECT d FROM Document d WHERE d.owner = :user\")\n    Page<Document> findByOwner(@Param(\"user\") User user, Pageable pageable);\n    \n    // Slice for performance (no total count)\n    Slice<Document> findByCategory(String category, Pageable pageable);\n}\n\n@Service\npublic class DocumentService {\n    public Page<Document> getDocuments(int page, int size, String sort) {\n        PageRequest pageable = PageRequest.of(\n            page, size, \n            Sort.by(\"createdDate\").descending()\n        );\n        return repository.findByStatus(DocumentStatus.ACTIVE, pageable);\n    }\n}"
            },
            "codeExplanations": {
              "english": "Pageable parameter triggers pagination logic. PageRequest.of creates the request with page number (0-indexed), size, and optional sorting. Page contains getContent(), getTotalPages(), getTotalElements(). Slice is similar but uses hasNext() instead of total counts, avoiding expensive COUNT(*) queries."
            },
            "keyPoints": [
              "Pass Pageable parameter to enable pagination",
              "Page<T> includes total count metadata; Slice<T> does not (better performance)",
              "PageRequest.of(page, size, Sort) creates pagination requests",
              "Sorting can be dynamic via Sort.by() or Sort.Direction"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [
                {
                  "headers": [
                    "Aspect",
                    "Page<T>",
                    "Slice<T>"
                  ],
                  "rows": [
                    [
                      "Total Count",
                      "Available (expensive query)",
                      "Not available"
                    ],
                    [
                      "Total Pages",
                      "Calculated",
                      "Unknown"
                    ],
                    [
                      "Performance",
                      "Slower (COUNT required)",
                      "Faster"
                    ],
                    [
                      "Navigation",
                      "Full page numbers",
                      "Previous/Next only"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "data-10",
            "title": "Projections",
            "explanations": {
              "english": "Projections retrieve only specific columns from entities rather than full objects, reducing memory usage and improving query performance. Interface-based projections define getter methods for required properties; Spring Data creates proxy implementations. Class-based projections (DTOs) use constructor expressions in @Query to instantiate specific classes with selected fields. Projections are essential for reporting queries and API responses requiring only subsets of entity data, avoiding loading unnecessary large fields like BLOBs or extensive relationships."
            },
            "code": {
              "title": "Projection Strategies",
              "language": "java",
              "content": "// Interface projection - closed projection (specific fields)\npublic interface UserSummary {\n    String getUsername();\n    String getEmail();\n    DepartmentInfo getDepartment();\n    \n    interface DepartmentInfo {\n        String getName();\n    }\n}\n\n// Repository using projection\npublic interface UserRepository extends JpaRepository<User, Long> {\n    List<UserSummary> findByActiveTrue();\n    \n    @Query(\"SELECT new com.example.UserDto(u.id, u.username, d.name) \" +\n           \"FROM User u JOIN u.department d WHERE u.active = true\")\n    List<UserDto> findActiveUsersWithDept();\n}\n\n// DTO Class for constructor projection\n@Data\n@AllArgsConstructor\npublic class UserDto {\n    private Long id;\n    private String username;\n    private String departmentName;\n}"
            },
            "codeExplanations": {
              "english": "UserSummary is an interface projection where Spring Data generates a proxy implementing only the specified getters. This is a closed projection optimizing the SQL SELECT clause. The @Query with 'new' uses a constructor expression to instantiate UserDto directly from the query results."
            },
            "keyPoints": [
              "Interface projections create proxies with only required fields",
              "Class projections (DTOs) use constructor expressions in JPQL",
              "Reduces data transfer when only specific fields are needed",
              "Closed projections (interface) allow SQL optimization (select specific columns)"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [
                {
                  "headers": [
                    "Type",
                    "Implementation",
                    "Use Case"
                  ],
                  "rows": [
                    [
                      "Interface (Closed)",
                      "Spring proxy",
                      "Simple read-only views"
                    ],
                    [
                      "Interface (Open)",
                      "Entity proxy",
                      "Full entity with restricted view"
                    ],
                    [
                      "Class (DTO)",
                      "Constructor instantiation",
                      "Complex aggregations, reporting"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "data-11",
            "title": "@Transactional",
            "explanations": {
              "english": "@Transactional declares that a method (or class) should be executed within a transactional context. Spring manages transaction boundaries, beginning a transaction before method entry and committing upon successful completion or rolling back on runtime exceptions. At the class level, it applies to all public methods. It works via Spring AOP proxies, so only external method calls trigger transaction interception. The annotation supports customization of propagation, isolation, timeout, and rollback rules."
            },
            "code": {
              "title": "Transactional Usage",
              "language": "java",
              "content": "@Service\n@Transactional(readOnly = true)  // Default for all methods in class\npublic class AccountService {\n    \n    @Transactional  // Overrides class-level, readOnly = false\n    public void transfer(Long fromId, Long toId, BigDecimal amount) {\n        Account from = accountRepo.findById(fromId).orElseThrow();\n        Account to = accountRepo.findById(toId).orElseThrow();\n        \n        from.debit(amount);\n        to.credit(amount);\n        \n        // Both saves happen in same transaction\n        accountRepo.save(from);\n        accountRepo.save(to);\n    }\n    \n    public Account getAccount(Long id) {  // Inherits readOnly = true\n        return accountRepo.findById(id).orElseThrow();\n    }\n    \n    @Transactional(rollbackFor = InsufficientFundsException.class)\n    public void strictTransfer(Long fromId, Long toId, BigDecimal amount) \n            throws InsufficientFundsException {\n        // Rolls back for checked exception too\n    }\n}"
            },
            "codeExplanations": {
              "english": "Class-level @Transactional(readOnly=true) optimizes read operations (no dirty checking, no snapshot). Method-level @Transactional without attributes enables write operations. The strictTransfer example shows rollbackFor to include checked exceptions in rollback rules."
            },
            "keyPoints": [
              "Declares transactional boundaries semantically",
              "readOnly=true optimizes performance for query methods",
              "Rollback occurs automatically for unchecked exceptions",
              "Use rollbackFor to include checked exceptions",
              "Propagation defaults to REQUIRED (join existing or create new)"
            ],
            "extras": {
              "flowDiagram": "Method Entry -> Proxy intercepts -> Begin TX -> Execute Method -> Success? -> Commit : Rollback -> Return",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "data-12",
            "title": "Transaction Propagation",
            "explanations": {
              "english": "Propagation defines transactional behavior when a method is invoked within an existing transaction context. REQUIRED (default) joins the existing transaction or creates new if none exists. REQUIRES_NEW suspends the current transaction and creates a new independent one, committing or rolling back separately. NESTED creates a savepoint within the current transaction, allowing partial rollback. MANDATORY requires an existing transaction and throws an exception if none exists. NEVER throws an exception if called within a transaction. SUPPORTS joins existing or executes non-transactionally if none exists."
            },
            "code": {
              "title": "Propagation Behaviors",
              "language": "java",
              "content": "@Service\npublic class OrderProcessingService {\n    \n    @Transactional\n    public void processOrder(Order order) {\n        orderRepo.save(order);\n        // Joins outer transaction (default REQUIRED)\n        inventoryService.reserveInventory(order.getItems());\n        \n        // Independent transaction - commits even if outer rolls back\n        auditService.logAuditEvent(\"Order processed: \" + order.getId());\n    }\n}\n\n@Service\npublic class AuditService {\n    \n    @Transactional(propagation = Propagation.REQUIRES_NEW)\n    public void logAuditEvent(String message) {\n        auditRepo.save(new AuditLog(message));\n    }\n    \n    @Transactional(propagation = Propagation.MANDATORY)\n    public void mandatoryOperation() {\n        // Must be called within existing transaction\n    }\n}"
            },
            "codeExplanations": {
              "english": "processOrder runs in a transaction. inventoryService call joins the same transaction (REQUIRED). auditService.logAuditEvent suspends the order transaction, creates a new one for the audit, commits it immediately, then resumes the order transaction. This ensures audit records persist even if the main order fails."
            },
            "keyPoints": [
              "REQUIRED: Default, joins existing or creates new",
              "REQUIRES_NEW: Suspends current, creates independent transaction",
              "NESTED: Creates savepoint for partial rollback",
              "MANDATORY: Requires existing transaction, throws if none",
              "NEVER: Throws if called within a transaction"
            ],
            "extras": {
              "flowDiagram": "Outer TX[REQUIRED] -> calls Inner1[REQUIRED] -> Joins Outer\n                     -> calls Inner2[REQUIRES_NEW] -> Suspends Outer, creates Inner2 TX\n                     -> Inner2 Commits -> Resumes Outer",
              "comparisonTable": [
                {
                  "headers": [
                    "Propagation",
                    "Current TX Present",
                    "No Current TX"
                  ],
                  "rows": [
                    [
                      "REQUIRED",
                      "Join",
                      "Create new"
                    ],
                    [
                      "REQUIRES_NEW",
                      "Suspend, create new",
                      "Create new"
                    ],
                    [
                      "NESTED",
                      "Create savepoint",
                      "Create new"
                    ],
                    [
                      "MANDATORY",
                      "Join",
                      "Throw exception"
                    ],
                    [
                      "NEVER",
                      "Throw exception",
                      "Execute without TX"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "data-13",
            "title": "Transaction Isolation Levels",
            "explanations": {
              "english": "Isolation levels determine how transaction integrity is visible to other transactions, balancing consistency against concurrency. READ_UNCOMMITTED allows dirty reads (reading uncommitted changes). READ_COMMITTED prevents dirty reads but allows non-repeatable reads (default in most databases). REPEATABLE_READ prevents non-repeatable reads but allows phantom reads. SERIALIZABLE provides complete isolation preventing all anomalies but severely limits concurrency. Spring defaults to the underlying database's default level but allows explicit configuration per transaction."
            },
            "code": {
              "title": "Isolation Configuration",
              "language": "java",
              "content": "@Service\npublic class FinancialService {\n    \n    // Strict isolation for critical operations\n    @Transactional(isolation = Isolation.SERIALIZABLE)\n    public void transferFunds(Account from, Account to, BigDecimal amount) {\n        // Prevents phantom reads and non-repeatable reads\n    }\n    \n    // Read committed for standard operations\n    @Transactional(isolation = Isolation.READ_COMMITTED)\n    public Account getAccountSummary(Long accountId) {\n        return accountRepository.findById(accountId).orElseThrow();\n    }\n    \n    // Optimistic locking alternative\n    @Transactional\n    public Account updateBalance(Long id, BigDecimal delta) {\n        Account account = accountRepository.findById(id).orElseThrow();\n        account.setBalance(account.getBalance().add(delta));\n        return accountRepository.save(account); // Version check prevents lost updates\n    }\n}"
            },
            "codeExplanations": {
              "english": "SERIALIZable is used for transferFunds to ensure absolute consistency. READ_COMMITTED is standard for queries. Alternatively, optimistic locking via @Version fields can replace strict isolation for better performance while preventing lost updates."
            },
            "keyPoints": [
              "DEFAULT: Database default (usually READ_COMMITTED)",
              "READ_UNCOMMITTED: Lowest isolation, allows dirty reads",
              "READ_COMMITTED: Prevents dirty reads, allows non-repeatable reads",
              "REPEATABLE_READ: Prevents non-repeatable reads, allows phantom reads",
              "SERIALIZABLE: Highest isolation, prevents all anomalies, lowest concurrency"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [
                {
                  "headers": [
                    "Isolation Level",
                    "Dirty Read",
                    "Non-Repeatable",
                    "Phantom Read"
                  ],
                  "rows": [
                    [
                      "READ_UNCOMMITTED",
                      "Possible",
                      "Possible",
                      "Possible"
                    ],
                    [
                      "READ_COMMITTED",
                      "Prevented",
                      "Possible",
                      "Possible"
                    ],
                    [
                      "REPEATABLE_READ",
                      "Prevented",
                      "Prevented",
                      "Possible"
                    ],
                    [
                      "SERIALIZABLE",
                      "Prevented",
                      "Prevented",
                      "Prevented"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "data-14",
            "title": "N+1 Problem",
            "explanations": {
              "english": "The N+1 problem occurs when an ORM executes one query to fetch a parent entity, then executes additional queries for each of the N parent entities to fetch related children (lazy loading). This results in N+1 total queries instead of a single joined query, causing severe performance degradation. Solutions include using JOIN FETCH in JPQL to eagerly load associations in one query, using EntityGraph to define fetch plans, or enabling batch fetching to load multiple children in fewer queries."
            },
            "code": {
              "title": "Solving N+1",
              "language": "java",
              "content": "// Problem: N+1 queries\n@Entity\npublic class Order {\n    @OneToMany(mappedBy = \"order\", fetch = FetchType.LAZY)\n    private List<OrderItem> items;\n}\n\n// Bad: 101 queries for 100 orders\nList<Order> orders = orderRepository.findAll();  // 1 query\nfor (Order o : orders) {\n    o.getItems().size();  // 100 additional queries\n}\n\n// Solution 1: JOIN FETCH\n@Query(\"SELECT DISTINCT o FROM Order o JOIN FETCH o.items\")\nList<Order> findAllWithItems();\n\n// Solution 2: Entity Graph\n@EntityGraph(attributePaths = {\"items\", \"items.product\"})\n@Query(\"SELECT o FROM Order o\")\nList<Order> findAllWithGraph();\n\n// Solution 3: Batch Size\n@Entity\npublic class OrderItem {\n    @ManyToOne(fetch = FetchType.LAZY)\n    @BatchSize(size = 25)\n    private Order order;\n}"
            },
            "codeExplanations": {
              "english": "The N+1 example shows 101 queries issued. Solution 1 uses JOIN FETCH to load orders and items in one SQL with JOIN. Solution 2 uses @EntityGraph to specify fetch plan at query time. Solution 3 uses @BatchSize to load items in batches of 25 instead of one by one."
            },
            "keyPoints": [
              "Occurs when accessing lazy-loaded collections in loops",
              "JOIN FETCH loads data in single query with SQL JOIN",
              "EntityGraph provides declarative fetch plans",
              "Batch fetching reduces queries by loading collections in batches",
              "Use lazy loading carefully; fetch eagerly when needed"
            ],
            "extras": {
              "flowDiagram": "N+1 Problem: Select Orders (1) -> Loop -> Select Items for Order 1 -> Select Items for Order 2 ... (N queries)\nJOIN FETCH: Select Orders JOIN Items (1 query total)",
              "comparisonTable": [
                {
                  "headers": [
                    "Solution",
                    "Approach",
                    "Best For"
                  ],
                  "rows": [
                    [
                      "JOIN FETCH",
                      "Eager join in query",
                      "Always need the data"
                    ],
                    [
                      "Entity Graph",
                      "Dynamic fetch plan",
                      "Sometimes need the data"
                    ],
                    [
                      "Batch Size",
                      "Multiple lazy loads batched",
                      "Deep object graphs"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "data-15",
            "title": "LazyInitializationException",
            "explanations": {
              "english": "LazyInitializationException occurs when code attempts to access a lazy-loaded association after the Hibernate Session (Persistence Context) has been closed, typically when accessing collection properties outside a transactional boundary. Since lazy loading requires an active session to proxy database access, the exception prevents accessing uninitialized proxies. Solutions include keeping transactions open long enough (Open Session in View pattern), eagerly fetching required data within the transaction using JOIN FETCH, or using DTO projections to fetch only necessary data upfront."
            },
            "code": {
              "title": "Handling Lazy Loading",
              "language": "java",
              "content": "// Problem: Session closed\n@Service\npublic class OrderService {\n    @Transactional\n    public Order getOrder(Long id) {\n        return orderRepository.findById(id).orElseThrow(); // Session closes here\n    }\n}\n\n// Controller - outside transaction\n@GetMapping(\"/{id}/items\")\npublic List<ItemDto> getItems(@PathVariable Long id) {\n    Order order = orderService.getOrder(id);\n    return order.getItems().stream()  // LazyInitializationException!\n        .map(this::toDto)\n        .collect(Collectors.toList());\n}\n\n// Solutions:\n\n// 1. Transactional at higher level or OSIV (Open Session in View)\n@GetMapping(\"/{id}/items\")\n@Transactional(readOnly = true)  // Keeps session open\npublic List<ItemDto> getItemsFixed(@PathVariable Long id) { ... }\n\n// 2. Fetch within transaction\n@Transactional\npublic Order getOrderWithItems(Long id) {\n    Order order = orderRepository.findById(id).orElseThrow();\n    order.getItems().size();  // Force initialization within TX\n    return order;\n}\n\n// 3. Use projections to avoid entity loading\n@Query(\"SELECT new com.example.OrderDto(o.id, o.total, i.name) \" +\n       \"FROM Order o JOIN o.items i WHERE o.id = :id\")\nList<OrderDto> findOrderDetails(@Param(\"id\") Long id);"
            },
            "codeExplanations": {
              "english": "The problem shows accessing lazy collection after @Transactional service method ends and session closes. Solutions show: keeping transaction open in controller (OSIV anti-pattern caution), forcing initialization within transaction by touching the collection, or avoiding entities entirely with DTO projection queries."
            },
            "keyPoints": [
              "Thrown when accessing uninitialized lazy association outside Session",
              "Occurs after transaction commits and session closes",
              "Solutions: eager fetching, Open Session in View (anti-pattern), DTOs",
              "Avoid returning entities to web layer; use DTOs instead",
              "Hibernate.initialize() or touching the collection forces initialization"
            ],
            "extras": {
              "flowDiagram": "Service Method [TX Open] -> Load Entity (proxy) -> TX Commit [Session Closed] -> Controller accesses proxy -> No Session -> LazyInitializationException",
              "comparisonTable": [],
              "examples": []
            }
          }
        ]
      },
      {
        "id": "config-security",
        "title": "Configuration, Profiles & Security",
        "description": "Master externalized configuration management, environment-specific profiles, and comprehensive application security including authentication, authorization, JWT, and OAuth2 integration.",
        "topics": [
          {
            "id": "config-1",
            "title": "Configuration Management",
            "explanations": {
              "english": "Spring Boot externalizes configuration through property files or YAML, allowing behavior changes without code modification. @Value injects individual properties using SpEL expressions, while @ConfigurationProperties binds structured hierarchical settings to type-safe POJOs with validation support. Configuration properties support relaxed binding (kebab-case, camelCase, snake_case) and type conversion. @Validated enables JSR-303 bean validation on configuration classes, ensuring constraints like @NotNull or @Min are checked at startup."
            },
            "code": {
              "title": "Configuration Strategies",
              "language": "java",
              "content": "@Configuration\npublic class AppConfig {\n    \n    @Value(\"${app.name:DefaultApp}\")\n    private String appName;\n    \n    @Value(\"${app.features}\")\n    private List<String> features;\n    \n    @Bean\n    public RestTemplate restTemplate(@Value(\"${api.timeout:5000}\") int timeout) {\n        return new RestTemplateBuilder()\n            .setConnectTimeout(Duration.ofMillis(timeout))\n            .build();\n    }\n}\n\n@Configuration\n@ConfigurationProperties(prefix = \"app.mail\")\n@Validated\n@Data\npublic class MailProperties {\n    @NotNull\n    private String host;\n    \n    @Min(1024)\n    @Max(65535)\n    private int port = 587;\n    \n    @NotEmpty\n    private String username;\n    \n    @NotEmpty\n    private String password;\n    \n    private Map<String, String> headers = new HashMap<>();\n}\n\n// application.yml:\n// app:\n//   mail:\n//     host: smtp.gmail.com\n//     port: 587\n//     username: user@gmail.com\n//     password: ${MAIL_PASSWORD}"
            },
            "codeExplanations": {
              "english": "@Value demonstrates individual property injection with default values and SpEL for lists. MailProperties shows type-safe structured configuration with validation constraints. The prefix 'app.mail' maps to nested YAML structures. @Validated triggers constraint validation during context initialization, failing fast on invalid configuration."
            },
            "keyPoints": [
              "@Value for simple property injection with SpEL support and defaults",
              "@ConfigurationProperties for type-safe hierarchical configuration",
              "Relaxed binding allows app.mail.camelCase, app.mail.kebab-case, or APP_MAIL_SNAKE_CASE",
              "@Validated enables bean validation on configuration classes",
              "Use @ConstructorBinding on record classes for immutable configuration"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [
                {
                  "headers": [
                    "Feature",
                    "@Value",
                    "@ConfigurationProperties"
                  ],
                  "rows": [
                    [
                      "Type Safety",
                      "String conversion required",
                      "Automatic type binding"
                    ],
                    [
                      "Validation",
                      "Manual",
                      "@Validated support"
                    ],
                    [
                      "Complex Objects",
                      "Not supported",
                      "Nested objects and lists"
                    ],
                    [
                      "IDE Support",
                      "Limited",
                      "Metadata for auto-completion"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "profiles-1",
            "title": "Spring Profiles",
            "explanations": {
              "english": "Profiles provide environment-specific configuration separation, allowing different settings for development, testing, and production. Profile-specific files follow the application-{profile}.properties naming convention and override default properties. The @Profile annotation conditionally activates beans or @Configuration classes only when specified profiles are active. Profiles are activated via spring.profiles.active property through command-line arguments, environment variables, or programmatic configuration in SpringApplicationBuilder."
            },
            "code": {
              "title": "Profile Configuration",
              "language": "java",
              "content": "@Configuration\n@Profile(\"dev\")\npublic class DevConfig {\n    @Bean\n    public DataSource h2DataSource() {\n        return new EmbeddedDatabaseBuilder()\n            .setType(EmbeddedDatabaseType.H2)\n            .build();\n    }\n}\n\n@Configuration\n@Profile(\"prod\")\npublic class ProdConfig {\n    @Bean\n    public DataSource postgresDataSource(\n            @Value(\"${DB_URL}\") String url,\n            @Value(\"${DB_USER}\") String user) {\n        HikariConfig config = new HikariConfig();\n        config.setJdbcUrl(url);\n        config.setUsername(user);\n        return new HikariDataSource(config);\n    }\n}\n\n@Service\n@Profile({\"dev\", \"test\"})\npublic class MockEmailService implements EmailService {\n    // Only active in dev or test\n}\n\n// application-dev.yml (loaded only when 'dev' profile active)\n// server:\n//   port: 8081\n// logging:\n//   level:\n//     root: DEBUG"
            },
            "codeExplanations": {
              "english": "DevConfig provides H2 embedded database only when 'dev' profile is active. ProdConfig activates for 'prod' profile with externalized database credentials. The MockEmailService uses multiple profile names. Profile-specific YAML files override shared configuration only when their profile is active."
            },
            "keyPoints": [
              "application-{profile}.properties/yaml for profile-specific settings",
              "@Profile on @Component, @Service, @Configuration to conditionally enable beans",
              "Multiple profiles can be active simultaneously: spring.profiles.active=dev,local",
              "Profiles can be activated via command line: --spring.profiles.active=prod",
              "Use ! prefix for negative profiles: @Profile(\"!test\") excludes test profile"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [
                {
                  "headers": [
                    "Activation Method",
                    "Command",
                    "Scope"
                  ],
                  "rows": [
                    [
                      "Command Line",
                      "--spring.profiles.active=dev",
                      "Single execution"
                    ],
                    [
                      "Environment Variable",
                      "SPRING_PROFILES_ACTIVE=dev",
                      "System-wide"
                    ],
                    [
                      "application.properties",
                      "spring.profiles.active=dev",
                      "Default for app"
                    ],
                    [
                      "Programmatic",
                      "setAdditionalProfiles()",
                      "Specific to application instance"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "sec-auth-1",
            "title": "Authentication vs Authorization",
            "explanations": {
              "english": "Authentication verifies identity (proving who you are) through credentials like passwords, tokens, or certificates, resulting in an Authentication object stored in the SecurityContext. Authorization determines permitted actions (what you can do) by evaluating GrantedAuthority roles against access rules. Spring Security filters intercept requests to perform authentication before authorization. The process separates identity verification from permission checking, allowing flexible security models where authenticated users may have different privilege levels."
            },
            "code": {
              "title": "Security Context",
              "language": "java",
              "content": "@Service\npublic class SecurityAuditService {\n    \n    public void logAccessAttempt() {\n        Authentication auth = SecurityContextHolder.getContext().getAuthentication();\n        \n        if (auth != null && auth.isAuthenticated()) {\n            String username = auth.getName();\n            Collection<? extends GrantedAuthority> authorities = auth.getAuthorities();\n            \n            boolean isAdmin = authorities.stream()\n                .anyMatch(a -> a.getAuthority().equals(\"ROLE_ADMIN\"));\n            \n            // Authentication: Who (username)\n            // Authorization: What they can do (isAdmin)\n        }\n    }\n}\n\n@Configuration\n@EnableWebSecurity\npublic class SecurityConfig {\n    @Bean\n    public SecurityFilterChain filterChain(HttpSecurity http) throws Exception {\n        http\n            .authorizeHttpRequests(auth -> auth\n                .requestMatchers(\"/public/**\").permitAll()\n                .requestMatchers(\"/admin/**\").hasRole(\"ADMIN\")  // Authorization\n                .anyRequest().authenticated()  // Requires Authentication\n            )\n            .formLogin(withDefaults());  // Authentication mechanism\n        return http.build();\n    }\n}"
            },
            "codeExplanations": {
              "english": "SecurityContextHolder provides access to the current Authentication object containing principal (identity) and authorities (permissions). Authentication filters populate this context. The SecurityFilterChain demonstrates the separation: formLogin handles authentication, while authorizeHttpRules handles authorization decisions based on roles (hasRole) or requiring any authentication."
            },
            "keyPoints": [
              "Authentication: Establishing identity (username/password verification)",
              "Authorization: Checking permissions (role-based access control)",
              "SecurityContext holds Authentication object for current thread",
              "Authentication results in GrantedAuthority collection for authorization decisions",
              "Spring Security filters perform authentication before authorization checks"
            ],
            "extras": {
              "flowDiagram": "Request -> AuthenticationFilter (verify credentials) -> SecurityContext (store Authentication) -> AuthorizationFilter (check roles) -> Resource",
              "comparisonTable": [
                {
                  "headers": [
                    "Aspect",
                    "Authentication",
                    "Authorization"
                  ],
                  "rows": [
                    [
                      "Question",
                      "Who are you?",
                      "What can you do?"
                    ],
                    [
                      "Process",
                      "Credential verification",
                      "Permission evaluation"
                    ],
                    [
                      "Result",
                      "Authentication object",
                      "Access granted/denied"
                    ],
                    [
                      "Mechanisms",
                      "Form, JWT, OAuth2",
                      "Roles, ACLs, SpEL expressions"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "sec-form-1",
            "title": "Form Login",
            "explanations": {
              "english": "Form-based authentication uses HTTP sessions to maintain state between requests. Spring Security provides a default login page or allows custom login endpoints. Upon successful authentication, a session is created (default in-memory or JDBC-backed for clustering) and a cookie (JSESSIONID) tracks the user. CSRF protection is automatically enabled for state-changing operations. Session fixation protection regenerates session IDs upon login to prevent session hijacking. This approach is suitable for traditional server-rendered web applications."
            },
            "code": {
              "title": "Form Login Configuration",
              "language": "java",
              "content": "@Bean\npublic SecurityFilterChain filterChain(HttpSecurity http) throws Exception {\n    http\n        .authorizeHttpRequests(auth -> auth\n            .requestMatchers(\"/login\", \"/css/**\", \"/js/**\").permitAll()\n            .requestMatchers(\"/dashboard\").hasAnyRole(\"USER\", \"ADMIN\")\n            .requestMatchers(\"/admin/**\").hasRole(\"ADMIN\")\n        )\n        .formLogin(form -> form\n            .loginPage(\"/login\")\n            .loginProcessingUrl(\"/perform-login\")\n            .defaultSuccessUrl(\"/dashboard\", false)\n            .failureUrl(\"/login?error=true\")\n            .usernameParameter(\"email\")\n            .passwordParameter(\"pass\")\n        )\n        .logout(logout -> logout\n            .logoutUrl(\"/logout\")\n            .logoutSuccessUrl(\"/login?logout=true\")\n            .invalidateHttpSession(true)\n            .deleteCookies(\"JSESSIONID\")\n        )\n        .sessionManagement(session -> session\n            .sessionCreationPolicy(SessionCreationPolicy.IF_REQUIRED)\n            .maximumSessions(1)\n            .maxSessionsPreventsLogin(false)\n        );\n    return http.build();\n}\n\n@Bean\npublic UserDetailsService userDetailsService() {\n    UserDetails user = User.builder()\n        .username(\"user@example.com\")\n        .password(passwordEncoder().encode(\"password\"))\n        .roles(\"USER\")\n        .build();\n    return new InMemoryUserDetailsManager(user);\n}"
            },
            "codeExplanations": {
              "english": "Configures custom login page at /login while permitting static resources. loginProcessingUrl specifies where the form POSTs credentials. defaultSuccessUrl sets post-login destination with false allowing redirect to originally requested page. Session management restricts to single concurrent session per user. In-memory user store is suitable for demos; production uses database-backed UserDetailsService."
            },
            "keyPoints": [
              "Session-based authentication with JSESSIONID cookie",
              "CSRF protection automatically enabled for non-GET requests",
              "Session fixation protection regenerates ID after login",
              "Customizable login pages, success handlers, and failure URLs",
              "Concurrent session control prevents account sharing"
            ],
            "extras": {
              "flowDiagram": "Browser -> GET /login -> Render Form\n       -> POST /perform-login -> Validate -> Create Session -> Set Cookie -> Redirect /dashboard\n       -> Subsequent Requests -> Auto-authenticate via Session Cookie",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "sec-jwt-1",
            "title": "JWT (Stateless Authentication)",
            "explanations": {
              "english": "JSON Web Tokens enable stateless authentication where the server validates signed tokens containing claims rather than maintaining session state. A JWT consists of three parts: header (algorithm), payload (claims like username, roles, expiration), and signature (verification). Upon login, the server issues a token; subsequent requests include it in the Authorization header (Bearer scheme). Spring Security validates the signature and extracts authorities without database lookups. This scales horizontally without session clustering but requires token expiration handling and secure storage on the client."
            },
            "code": {
              "title": "JWT Security Configuration",
              "language": "java",
              "content": "@Component\npublic class JwtAuthenticationFilter extends OncePerRequestFilter {\n    \n    @Override\n    protected void doFilterInternal(HttpServletRequest request, \n                                    HttpServletResponse response, \n                                    FilterChain chain) throws ServletException, IOException {\n        String header = request.getHeader(\"Authorization\");\n        \n        if (header != null && header.startsWith(\"Bearer \")) {\n            String token = header.substring(7);\n            if (JwtUtil.validateToken(token)) {\n                String username = JwtUtil.getUsernameFromToken(token);\n                List<GrantedAuthority> authorities = JwtUtil.getAuthorities(token);\n                \n                UsernamePasswordAuthenticationToken auth = \n                    new UsernamePasswordAuthenticationToken(username, null, authorities);\n                auth.setDetails(new WebAuthenticationDetailsSource().buildDetails(request));\n                SecurityContextHolder.getContext().setAuthentication(auth);\n            }\n        }\n        chain.doFilter(request, response);\n    }\n}\n\n@Bean\npublic SecurityFilterChain filterChain(HttpSecurity http) throws Exception {\n    http\n        .csrf(csrf -> csrf.disable())  // Stateless doesn't need CSRF\n        .sessionManagement(session -> \n            session.sessionCreationPolicy(SessionCreationPolicy.STATELESS))\n        .authorizeHttpRequests(auth -> auth\n            .requestMatchers(\"/api/auth/**\").permitAll()\n            .anyRequest().authenticated()\n        )\n        .addFilterBefore(jwtFilter, UsernamePasswordAuthenticationFilter.class);\n    return http.build();\n}\n\n// Token generation utility\npublic class JwtUtil {\n    private static final String SECRET = \"mySecretKey\";\n    private static final long EXPIRATION = 86400000; // 24 hours\n    \n    public static String generateToken(UserDetails userDetails) {\n        return Jwts.builder()\n            .setSubject(userDetails.getUsername())\n            .claim(\"roles\", userDetails.getAuthorities())\n            .setIssuedAt(new Date())\n            .setExpiration(new Date(System.currentTimeMillis() + EXPIRATION))\n            .signWith(SignatureAlgorithm.HS256, SECRET)\n            .compact();\n    }\n}"
            },
            "codeExplanations": {
              "english": "JwtAuthenticationFilter intercepts requests to extract and validate Bearer tokens from the Authorization header. Valid tokens create Authentication objects without session creation. The SecurityFilterChain disables CSRF and sessions (STATELESS), adding the JWT filter before standard authentication filters. The utility generates signed tokens with claims including roles and expiration."
            },
            "keyPoints": [
              "JWT contains claims (identity, roles) signed with secret key",
              "No server-side session storage required - truly stateless",
              "Sent in Authorization: Bearer <token> header",
              "Signature verification ensures token integrity",
              "Token expiration requires refresh strategy or re-login",
              "Scales horizontally without session clustering"
            ],
            "extras": {
              "flowDiagram": "Login -> Validate Credentials -> Generate JWT -> Return to Client\nRequest -> Extract JWT from Header -> Validate Signature -> Parse Claims -> Authenticate -> Access Resource",
              "comparisonTable": [
                {
                  "headers": [
                    "Aspect",
                    "Session",
                    "JWT"
                  ],
                  "rows": [
                    [
                      "Storage",
                      "Server memory/database\", \"Client-side (browser storage)"
                    ],
                    [
                      "Scalability",
                      "Requires sticky sessions or shared store",
                      "Any server can validate"
                    ],
                    [
                      "CSRF",
                      "Vulnerable, needs tokens",
                      "Immune (stateless)"
                    ],
                    [
                      "Logout",
                      "Invalidate session",
                      "Wait for expiration or blacklist"
                    ],
                    [
                      "Size",
                      "Small cookie",
                      "Larger header payload"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "sec-method-1",
            "title": "Method Security (@PreAuthorize)",
            "explanations": {
              "english": "Method security provides fine-grained authorization at the service layer using Spring Expression Language (SpEL). @PreAuthorize evaluates expressions before method execution, preventing invocation if conditions fail. @PostAuthorize checks after execution, useful for verifying return object ownership. @Secured is an older alternative supporting simple role lists but lacks SpEL flexibility. These annotations enable row-level security scenarios like 'user can only view their own orders' through expressions like 'returnObject.owner == authentication.name'. Method security requires @EnableMethodSecurity configuration."
            },
            "code": {
              "title": "Method-Level Authorization",
              "language": "java",
              "content": "@Configuration\n@EnableMethodSecurity(prePostEnabled = true, securedEnabled = true)\npublic class MethodSecurityConfig {\n}\n\n@Service\npublic class OrderService {\n    \n    @PreAuthorize(\"hasRole('ADMIN') or #userId == authentication.principal.id\")\n    public List<Order> getUserOrders(Long userId) {\n        return orderRepository.findByUserId(userId);\n    }\n    \n    @PreAuthorize(\"hasAuthority('ORDER_DELETE') and #order.status != 'SHIPPED'\")\n    public void cancelOrder(Order order) {\n        order.cancel();\n    }\n    \n    @PostAuthorize(\"returnObject.owner == authentication.name or hasRole('ADMIN')\")\n    public Document getDocument(Long id) {\n        return documentRepository.findById(id).orElseThrow();\n    }\n    \n    @PreAuthorize(\"hasRole('MANAGER')\")\n    @Transactional\n    public void bulkUpdateOrders(List<Long> orderIds, Status newStatus) {\n        // Only managers can execute bulk updates\n    }\n}\n\n// Using @Secured (simpler, no SpEL)\n@Secured({\"ROLE_ADMIN\", \"ROLE_MANAGER\"})\npublic void sensitiveOperation() {}"
            },
            "codeExplanations": {
              "english": "@PreAuthorize uses SpEL: hasRole checks for ROLE_ADMIN, #userId references method parameter, authentication.principal.id accesses current user ID. @PostAuthorize prevents method return if the document owner doesn't match current user (unless admin). This implements row-level security independent of web layer."
            },
            "keyPoints": [
              "@PreAuthorize: Validate before method execution using SpEL",
              "@PostAuthorize: Validate after execution, can inspect returnObject",
              "SpEL supports method parameters (#argName), roles (hasRole), and authentication object",
              "Use @EnableMethodSecurity to activate",
              "Method security uses AOP proxies; internal calls bypass security",
              "@Secured is simpler but less powerful than @PreAuthorize"
            ],
            "extras": {
              "flowDiagram": "Request -> Controller (authenticated) -> Service Method -> @PreAuthorize Check -> Proceed/Reject\n                                         -> Return Object -> @PostAuthorize Check -> Return to Caller",
              "comparisonTable": [
                {
                  "headers": [
                    "Annotation",
                    "Timing",
                    "SpEL Support",
                    "Use Case"
                  ],
                  "rows": [
                    [
                      "@PreAuthorize",
                      "Before execution",
                      "Yes",
                      "Input validation, role checks"
                    ],
                    [
                      "@PostAuthorize",
                      "After execution",
                      "Yes",
                      "Result filtering, ownership verification"
                    ],
                    [
                      "@Secured",
                      "Before execution",
                      "No (roles only)",
                      "Simple role-based access"
                    ],
                    [
                      "@PreFilter",
                      "Before execution",
                      "Yes",
                      "Filter collection arguments"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "sec-oauth-1",
            "title": "OAuth2 & Social Login",
            "explanations": {
              "english": "OAuth2 is an authorization framework enabling delegated access. Spring Boot supports three roles: Client (Login with Google/GitHub), Resource Server (protecting APIs with JWT validation), and Authorization Server (issuing tokens - moved to separate Spring Authorization Server project). As a Client, Spring Security redirects users to the provider (Google), handles the callback, exchanges the code for tokens, and creates a local user session. This eliminates password storage while leveraging established identity providers. Resource Server configuration validates incoming JWTs from authorization servers."
            },
            "code": {
              "title": "OAuth2 Client and Resource Server",
              "language": "java",
              "content": "// OAuth2 Client (Login with Google)\n@Configuration\npublic class OAuth2ClientConfig {\n    @Bean\n    public SecurityFilterChain filterChain(HttpSecurity http) throws Exception {\n        http\n            .oauth2Login(oauth2 -> oauth2\n                .loginPage(\"/login\")\n                .defaultSuccessUrl(\"/dashboard\", true)\n                .userInfoEndpoint(userInfo -> userInfo\n                    .oidcUserService(customOidcUserService())\n                )\n            )\n            .authorizeHttpRequests(auth -> auth\n                .anyRequest().authenticated()\n            );\n        return http.build();\n    }\n}\n\n// application.yml for OAuth2 Client:\n// spring:\n//   security:\n//     oauth2:\n//       client:\n//         registration:\n//           google:\n//             client-id: ${GOOGLE_CLIENT_ID}\n//             client-secret: ${GOOGLE_CLIENT_SECRET}\n//             scope: openid,profile,email\n\n// OAuth2 Resource Server (API JWT validation)\n@Bean\npublic SecurityFilterChain resourceServerChain(HttpSecurity http) throws Exception {\n    http\n        .csrf(csrf -> csrf.disable())\n        .oauth2ResourceServer(oauth2 -> oauth2\n            .jwt(jwt -> jwt\n                .jwtDecoder(jwtDecoder())\n                .jwtAuthenticationConverter(jwtAuthenticationConverter())\n            )\n        )\n        .authorizeHttpRequests(auth -> auth\n            .requestMatchers(\"/api/public\").permitAll()\n            .requestMatchers(\"/api/admin\").hasAuthority(\"SCOPE_admin\")\n            .anyRequest().authenticated()\n        );\n    return http.build();\n}\n\n@Bean\npublic JwtDecoder jwtDecoder() {\n    return NimbusJwtDecoder.withJwkSetUri(\"https://auth-server/.well-known/jwks.json\").build();\n}"
            },
            "codeExplanations": {
              "english": "OAuth2 Client configuration enables 'Login with Google' using OIDC (OpenID Connect). The userInfoEndpoint customizes how user details are loaded. Resource Server configuration validates JWTs from an authorization server using JWKS (JSON Web Key Set) URI for signature verification. SCOPE_admin checks for specific OAuth2 scopes in the token."
            },
            "keyPoints": [
              "OAuth2 Client: Delegate authentication to Google/GitHub/Auth0",
              "OAuth2 Resource Server: Protect APIs by validating JWT access tokens",
              "Authorization Server: Now in separate Spring Authorization Server project",
              "OIDC (OpenID Connect) built on OAuth2 for identity verification",
              "Resource Server extracts scopes/roles from JWT for authorization",
              "Social login eliminates local password storage and management"
            ],
            "extras": {
              "flowDiagram": "User -> App -> Redirect to Google -> Google Auth -> Callback with Code -> Exchange Code for Tokens -> Create Session\nAPI Client -> Request with Access Token -> Resource Server -> Validate JWT Signature -> Extract Claims -> Check Scopes -> Allow/Deny",
              "comparisonTable": [
                {
                  "headers": [
                    "Role",
                    "Purpose",
                    "Spring Module"
                  ],
                  "rows": [
                    [
                      "Client",
                      "Login via external providers",
                      "spring-boot-starter-oauth2-client"
                    ],
                    [
                      "Resource Server",
                      "Validate tokens, protect APIs",
                      "spring-boot-starter-oauth2-resource-server"
                    ],
                    [
                      "Authorization Server",
                      "Issue tokens",
                      "Spring Authorization Server"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          }
        ]
      },
      {
        "id": "actuator-monitoring-testing",
        "title": "Actuator, Monitoring & Testing",
        "description": "Comprehensive coverage of production-ready features including health checks, metrics collection, structured logging, and testing strategies from unit tests to full integration scenarios with containerized dependencies.",
        "topics": [
          {
            "id": "act-mon-1",
            "title": "Health Endpoints",
            "explanations": {
              "english": "Spring Boot Actuator provides the /actuator/health endpoint which exposes application health status to monitoring systems and orchestration platforms. The endpoint aggregates information from HealthIndicator beans that check database connectivity, disk space, message broker availability, and custom system states. By default, it returns a simple UP or DOWN status, but can be configured to show detailed health information for authorized users. This endpoint is crucial for load balancers to determine traffic routing and for Kubernetes to make restart decisions."
            },
            "code": {
              "title": "Custom Health Indicator",
              "language": "java",
              "content": "@Component\npublic class ExternalApiHealthIndicator implements HealthIndicator {\n    \n    private final RestTemplate restTemplate;\n    \n    public ExternalApiHealthIndicator(RestTemplate restTemplate) {\n        this.restTemplate = restTemplate;\n    }\n    \n    @Override\n    public Health health() {\n        try {\n            ResponseEntity<String> response = restTemplate.getForEntity(\n                \"https://api.service.com/health\", String.class);\n            \n            if (response.getStatusCode().is2xxSuccessful()) {\n                return Health.up()\n                    .withDetail(\"api.status\", \"Available\")\n                    .withDetail(\"responseTimeMs\", response.getHeaders().getFirst(\"X-Response-Time\"))\n                    .build();\n            }\n            return Health.down()\n                .withDetail(\"api.status\", \"Unhealthy\")\n                .withDetail(\"statusCode\", response.getStatusCode())\n                .build();\n        } catch (Exception e) {\n            return Health.down()\n                .withException(e)\n                .build();\n        }\n    }\n}"
            },
            "codeExplanations": {
              "english": "This custom indicator checks an external API dependency. It implements HealthIndicator and returns Health.up() or Health.down() with contextual details. These details appear in the health JSON when authorized. Exceptions are captured and included in health details for debugging."
            },
            "keyPoints": [
              "/actuator/health aggregates all HealthIndicator beans",
              "Custom indicators implement HealthIndicator interface",
              "Return Health.up() or Health.down() with optional details",
              "Sensitive details hidden by default; configure management.endpoint.health.show-details for visibility",
              "Used by load balancers and Kubernetes probes to assess application state"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "act-mon-2",
            "title": "Metrics",
            "explanations": {
              "english": "Spring Boot uses Micrometer as the metrics facade to instrument code and export to monitoring systems like Prometheus, CloudWatch, or Datadog. Common metrics include JVM metrics (memory, GC, threads), system metrics (CPU, file descriptors), and application metrics (HTTP request counts/timers, datasource connection pool usage). Developers can create custom metrics using Counter, Timer, Gauge, and DistributionSummary meters. These metrics provide visibility into application performance and resource utilization for capacity planning and alerting."
            },
            "code": {
              "title": "Custom Metrics",
              "language": "java",
              "content": "@Service\npublic class OrderService {\n    private final MeterRegistry meterRegistry;\n    private final Counter orderCounter;\n    private final Timer orderProcessingTimer;\n    \n    public OrderService(MeterRegistry meterRegistry) {\n        this.meterRegistry = meterRegistry;\n        this.orderCounter = Counter.builder(\"orders.created\")\n            .description(\"Total orders created\")\n            .register(meterRegistry);\n        this.orderProcessingTimer = Timer.builder(\"order.processing.time\")\n            .description(\"Time taken to process orders\")\n            .publishPercentiles(0.5, 0.95, 0.99)\n            .register(meterRegistry);\n    }\n    \n    public void processOrder(Order order) {\n        orderProcessingTimer.record(() -> {\n            // Processing logic\n            saveToDatabase(order);\n            sendNotification(order);\n        });\n        orderCounter.increment();\n        \n        // Gauge for current queue size\n        meterRegistry.gauge(\"orders.queue.size\", \n            Tags.of(\"priority\", order.getPriority()), \n            orderQueue.size());\n    }\n}"
            },
            "codeExplanations": {
              "english": "Counter tracks monotonically increasing values like total orders. Timer measures duration and can publish percentiles for SLA monitoring. Gauges track current values like queue sizes. All metrics are automatically exported via configured registries (e.g., Prometheus). Tags allow dimensional metrics for filtering and aggregation."
            },
            "keyPoints": [
              "Micrometer provides vendor-neutral metrics abstraction",
              "Counter for incrementing counts, Timer for durations, Gauge for current values",
              "Tags enable multi-dimensional metrics (e.g., status=200, endpoint=/api/users)",
              "Percentile histograms track SLA compliance (p95, p99)",
              "Auto-configured metrics include JVM, system, and web request statistics"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "act-mon-3",
            "title": "Environment Endpoints",
            "explanations": {
              "english": "The Actuator provides several endpoints for inspecting application configuration without requiring server access. /actuator/env displays properties from all PropertySource instances including system properties, environment variables, and application properties with placeholder resolution. /actuator/configprops shows @ConfigurationProperties beans and their binding results. /actuator/conditions displays auto-configuration reports showing which configurations matched or failed. These endpoints are invaluable for debugging configuration issues in production environments where you cannot attach a debugger."
            },
            "code": {
              "title": "Configuration Inspection",
              "language": "java",
              "content": "// Access via: GET /actuator/env\n// Response snippet:\n{\n  \"activeProfiles\": [\"prod\"],\n  \"propertySources\": [\n    {\n      \"name\": \"systemEnvironment\",\n      \"properties\": {\n        \"DB_PASSWORD\": {\"value\": \"******\", \"origin\": \"System Environment\"}\n      }\n    },\n    {\n      \"name\": \"applicationConfig: [classpath:/application-prod.yml]\",\n      \"properties\": {\n        \"server.port\": {\"value\": 8080}\n      }\n    }\n  ]\n}\n\n// GET /actuator/configprops\n{\n  \"app.mail-org.springframework.boot.actuate.autoconfigure.context.properties.ConfigurationPropertiesReportEndpoint\": {\n    \"prefix\": \"app.mail\",\n    \"properties\": {\n      \"host\": \"smtp.gmail.com\",\n      \"port\": 587\n    }\n  }\n}"
            },
            "codeExplanations": {
              "english": "The env endpoint shows the final resolved values of all properties across all sources including their origins. Sensitive values like passwords are masked with asterisks for security. The configprops endpoint exposes bound @ConfigurationProperties beans, showing exactly how external configuration has been mapped to Java objects."
            },
            "keyPoints": [
              "/actuator/env shows all properties from all sources with resolution order",
              "/actuator/configprops displays bound @ConfigurationProperties beans",
              "/actuator/conditions shows auto-configuration match results",
              "Sensitive data automatically masked based on property name patterns",
              "Useful for verifying production configuration without shell access"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "act-mon-4",
            "title": "Kubernetes Readiness & Liveness",
            "explanations": {
              "english": "Spring Boot provides first-class support for Kubernetes health probes through specialized endpoints. Liveness probes (/actuator/health/liveness) indicate whether the application is running and should be restarted if failing, catching deadlocks or infinite loops. Readiness probes (/actuator/health/readiness) indicate whether the application is ready to accept traffic, remaining false during startup or when overloaded. These are separate from the general health endpoint to allow Kubernetes to make distinct decisions about restarts versus traffic routing. ApplicationAvailability interface allows programmatic state management."
            },
            "code": {
              "title": "Probe Configuration",
              "language": "java",
              "content": "@Component\npublic class DatabaseStartupValidator implements ApplicationListener<ApplicationReadyEvent> {\n    \n    private final ApplicationAvailability availability;\n    private final DataSource dataSource;\n    \n    public DatabaseStartupValidator(ApplicationAvailability availability, DataSource dataSource) {\n        this.availability = availability;\n        this.dataSource = dataSource;\n    }\n    \n    @Override\n    public void onApplicationEvent(ApplicationReadyEvent event) {\n        try (Connection conn = dataSource.getConnection()) {\n            if (conn.isValid(5)) {\n                // Signal readiness\n                availability.markAsReady();\n            } else {\n                availability.markAsNotReady();\n            }\n        } catch (SQLException e) {\n            availability.markAsNotReady();\n        }\n    }\n}\n\n// application.yml:\n// management:\n//   endpoint:\n//     health:\n//       probes:\n//         enabled: true\n//       group:\n//         readiness:\n//           include: readinessState,db\n//         liveness:\n//           include: livenessState"
            },
            "codeExplanations": {
              "english": "The ApplicationAvailability interface allows programmatic control of readiness state. The validator checks database connectivity on startup before marking the application ready. Kubernetes calls /actuator/health/readiness and /actuator/health/liveness separately to make pod lifecycle decisions. Probes must be explicitly enabled and configured to include relevant health indicators."
            },
            "keyPoints": [
              "Liveness probe: App is running (restart if false)",
              "Readiness probe: App is ready to accept traffic (remove from service if false)",
              "Endpoints: /actuator/health/liveness and /actuator/health/readiness",
              "ApplicationAvailability interface for programmatic state changes",
              "Enabled via management.endpoint.health.probes.enabled=true"
            ],
            "extras": {
              "flowDiagram": "Pod Start -> Liveness=UP (default) -> App initializes -> Readiness=UP -> Traffic allowed\nApp deadlock -> Liveness=DOWN -> Kubernetes restarts pod\nDB connection lost -> Readiness=DOWN -> Traffic routed to other pods",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "act-mon-5",
            "title": "Prometheus & Grafana Integration",
            "explanations": {
              "english": "Prometheus is a popular open-source monitoring solution that scrapes metrics from applications via HTTP endpoints. Spring Boot with Micrometer exposes metrics in Prometheus format at /actuator/prometheus by adding the micrometer-registry-prometheus dependency. Prometheus scrapes these metrics at intervals (typically 15-30 seconds), stores them in a time-series database, and evaluates alerting rules. Grafana connects to Prometheus to create dashboards visualizing metrics like request rates, error rates, and latency histograms. This stack provides comprehensive observability for Spring Boot applications in production environments."
            },
            "code": {
              "title": "Prometheus Configuration",
              "language": "yaml",
              "content": "# pom.xml dependency\n// <dependency>\n//     <groupId>io.micrometer</groupId>\n//     <artifactId>micrometer-registry-prometheus</artifactId>\n// </dependency>\n\n# application.yml\nmanagement:\n  endpoints:\n    web:\n      exposure:\n        include: health,info,prometheus,metrics\n  endpoint:\n    prometheus:\n      enabled: true\n  metrics:\n    tags:\n      application: ${spring.application.name}\n      environment: ${spring.profiles.active:default}\n    distribution:\n      percentiles-histogram:\n        http.server.requests: true\n      slo:\n        http.server.requests: 100ms,500ms,1s,5s\n\n# Scraped by Prometheus at: GET /actuator/prometheus\n# http_server_requests_seconds_count{application=\"order-service\",uri=\"/api/orders\",status=\"200\"} 1024"
            },
            "codeExplanations": {
              "english": "The micrometer-registry-prometheus dependency exposes the /actuator/prometheus endpoint in Prometheus exposition format. Tags add dimensions like application name for filtering. SLAs define buckets for histograms to track latency objectives. Prometheus server scrapes this endpoint periodically to collect time-series data for alerting and visualization in Grafana."
            },
            "keyPoints": [
              "Add micrometer-registry-prometheus to expose /actuator/prometheus",
              "Prometheus scrapes metrics in text format (Pull model)",
              "Grafana queries Prometheus for dashboards and alerts",
              "Configure tags for multi-dimensional filtering (app, instance, endpoint)",
              "Histogram percentiles track latency distribution (p50, p95, p99)"
            ],
            "extras": {
              "flowDiagram": "Spring Boot App (/actuator/prometheus) <- scrape <- Prometheus (TSDB) <- query <- Grafana (Dashboards/Alerts)",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "log-1",
            "title": "SLF4J",
            "explanations": {
              "english": "SLF4J (Simple Logging Facade for Java) serves as an abstraction layer for various logging frameworks like Logback, Log4j2, and java.util.logging. It allows developers to write logging code using the SLF4J API while the actual implementation is determined at deployment time. This prevents vendor lock-in and allows easy switching between logging frameworks without code changes. Spring Boot uses SLF4J internally and automatically provides Logback as the default implementation. The LoggerFactory creates logger instances that support parameterized messages, avoiding string concatenation overhead when logging is disabled."
            },
            "code": {
              "title": "SLF4J Usage",
              "language": "java",
              "content": "import org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\n@Service\npublic class PaymentService {\n    private static final Logger logger = LoggerFactory.getLogger(PaymentService.class);\n    \n    public void processPayment(Payment payment) {\n        // Parameterized logging - no string concatenation if DEBUG disabled\n        logger.debug(\"Processing payment for order: {}, amount: {}\", \n                     payment.getOrderId(), payment.getAmount());\n        \n        try {\n            gateway.charge(payment);\n            logger.info(\"Payment successful for order: {}\", payment.getOrderId());\n        } catch (PaymentException e) {\n            // SLF4J accepts exception as last argument for stack traces\n            logger.error(\"Payment failed for order: {}\", payment.getOrderId(), e);\n        }\n        \n        // Guard for expensive computation\n        if (logger.isTraceEnabled()) {\n            logger.trace(\"Full payment payload: {}\", expensiveSerialization(payment));\n        }\n    }\n}"
            },
            "codeExplanations": {
              "english": "LoggerFactory.getLogger(Class) creates a logger instance for the class. Parameterized logging uses {} placeholders to defer string formatting until determining if the level is enabled. Exceptions passed as the last argument are logged with stack traces. isTraceEnabled guards expensive operations that should only run when trace logging is active."
            },
            "keyPoints": [
              "Facade pattern decouples logging API from implementation",
              "Parameterized messages avoid performance cost of disabled log levels",
              "LoggerFactory creates logger instances specific to the class",
              "Pass exception as last argument to include stack trace",
              "Spring Boot auto-configures SLF4J with Logback"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "log-2",
            "title": "Logback Configuration",
            "explanations": {
              "english": "Logback is the default logging implementation in Spring Boot, configured via logback-spring.xml in the classpath or through application properties. It supports console and file appenders with rolling policies to manage disk space. Pattern layouts customize log format including timestamps, log levels, class names, and messages. Spring Boot provides sane defaults but allows complete customization for different profiles. The configuration supports filters to control which log levels go to which appenders, separating INFO logs to console and ERROR logs to specific files for alerting."
            },
            "code": {
              "title": "Logback Configuration",
              "language": "xml",
              "content": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<configuration>\n    <springProfile name=\"dev\">\n        <appender name=\"CONSOLE\" class=\"ch.qos.logback.core.ConsoleAppender\">\n            <encoder>\n                <pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>\n            </encoder>\n        </appender>\n        <root level=\"DEBUG\">\n            <appender-ref ref=\"CONSOLE\" />\n        </root>\n    </springProfile>\n    \n    <springProfile name=\"prod\">\n        <appender name=\"FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\">\n            <file>/var/log/myapp/application.log</file>\n            <rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\">\n                <fileNamePattern>/var/log/myapp/application.%d{yyyy-MM-dd}.%i.log</fileNamePattern>\n                <maxHistory>30</maxHistory>\n                <maxFileSize>100MB</maxFileSize>\n            </rollingPolicy>\n            <encoder>\n                <pattern>%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n</pattern>\n            </encoder>\n        </appender>\n        <root level=\"INFO\">\n            <appender-ref ref=\"FILE\" />\n        </root>\n    </springProfile>\n</configuration>"
            },
            "codeExplanations": {
              "english": "logback-spring.xml supports Spring profiles to apply different configurations per environment. The dev profile logs DEBUG to console with compact format. The prod profile logs INFO to rolling files with time and size based policies, keeping 30 days of history with max 100MB files. The pattern syntax controls timestamp format, thread names, padding, and logger abbreviation."
            },
            "keyPoints": [
              "logback-spring.xml supports Spring profiles (<springProfile>)",
              "RollingFileAppender manages log rotation by time or size",
              "Pattern layout controls visual format of log lines",
              "Root logger level filters which messages are logged",
              "Appenders determine output destination (console, file, remote)"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "log-3",
            "title": "Structured JSON Logging",
            "explanations": {
              "english": "Structured JSON logging formats log entries as JSON objects rather than plain text lines, making them easily parseable by log aggregation systems like ELK (Elasticsearch, Logstash, Kibana), Splunk, or Fluentd. Each log entry contains fields like timestamp, level, logger, message, and MDC context as JSON properties. This eliminates the need for complex regex parsing to extract structured data. The logstash-logback-encoder or Jackson-based encoders can be configured to include application metadata, trace IDs, and custom fields, enabling efficient filtering and correlation in centralized logging platforms."
            },
            "code": {
              "title": "JSON Logging Setup",
              "language": "xml",
              "content": "<configuration>\n    <appender name=\"JSON\" class=\"ch.qos.logback.core.ConsoleAppender\">\n        <encoder class=\"net.logstash.logback.encoder.LogstashEncoder\">\n            <includeContext>true</includeContext>\n            <includeMdc>true</includeMdc>\n            <customFields>{\"service\":\"order-service\",\"version\":\"1.2.3\"}</customFields>\n        </encoder>\n    </appender>\n    \n    <!-- Alternative: Pattern based JSON -->\n    <appender name=\"JSON_PATTERN\" class=\"ch.qos.logback.core.ConsoleAppender\">\n        <encoder class=\"ch.qos.logback.core.encoder.LayoutWrappingEncoder\">\n            <layout class=\"ch.qos.logback.contrib.json.classic.JsonLayout\">\n                <jsonFormatter class=\"ch.qos.logback.contrib.jackson.JacksonJsonFormatter\">\n                    <prettyPrint>false</prettyPrint>\n                </jsonFormatter>\n                <timestampFormat>yyyy-MM-dd' 'HH:mm:ss.SSS</timestampFormat>\n            </layout>\n        </encoder>\n    </appender>\n    \n    <root level=\"INFO\">\n        <appender-ref ref=\"JSON\" />\n    </root>\n</configuration>"
            },
            "codeExplanations": {
              "english": "LogstashEncoder produces JSON formatted logs compatible with Logstash. includeMdc adds Mapped Diagnostic Context fields to the JSON structure. customFields injects static metadata like service name and version for identification in multi-service environments. Alternative Jackson-based layout provides more control over JSON structure and formatting."
            },
            "keyPoints": [
              "JSON format enables easy parsing by log aggregators (ELK, Splunk)",
              "LogstashEncoder or JacksonJsonFormatter convert logs to JSON",
              "Static customFields identify service, version, environment",
              "MDC fields automatically included as JSON properties",
              "Eliminates fragile regex parsing of plain text logs"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [
                {
                  "headers": [
                    "Format",
                    "Human Readable",
                    "Machine Parseable",
                    "Query Complexity"
                  ],
                  "rows": [
                    [
                      "Plain Text",
                      "Yes",
                      "Requires regex",
                      "High"
                    ],
                    [
                      "JSON",
                      "Readable with formatting",
                      "Native\", \"Low (field-based)"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "log-4",
            "title": "MDC for Request Tracing",
            "explanations": {
              "english": "MDC (Mapped Diagnostic Context) is a thread-local map that stores contextual data accessible to logging frameworks. It is essential for correlating log messages belonging to the same request across multiple classes and methods. Common use cases include storing request IDs, user IDs, or session IDs that appear in every log line of that request. MDC requires cleanup after request processing to prevent memory leaks in thread pools. In async or reactive programming, MDC context must be explicitly propagated between threads using MDC.getCopyOfContextMap() and MDC.setContextMap()."
            },
            "code": {
              "title": "MDC Implementation",
              "language": "java",
              "content": "@Component\npublic class RequestIdFilter extends OncePerRequestFilter {\n    private static final String REQUEST_ID_HEADER = \"X-Request-ID\";\n    \n    @Override\n    protected void doFilterInternal(HttpServletRequest request, \n                                    HttpServletResponse response, \n                                    FilterChain chain) throws ServletException, IOException {\n        try {\n            String requestId = request.getHeader(REQUEST_ID_HEADER);\n            if (requestId == null) {\n                requestId = UUID.randomUUID().toString();\n            }\n            \n            MDC.put(\"requestId\", requestId);\n            MDC.put(\"userId\", SecurityContextHolder.getContext().getAuthentication().getName());\n            \n            response.setHeader(REQUEST_ID_HEADER, requestId);\n            chain.doFilter(request, response);\n        } finally {\n            MDC.clear(); // Critical to prevent leaks\n        }\n    }\n}\n\n// Log pattern: %X{requestId} %X{userId} %msg\n// Output: 2024-01-15 10:23:45 [abc-123] [john.doe] Processing order 456"
            },
            "codeExplanations": {
              "english": "The filter extracts or generates a request ID, stores it in MDC for the request duration, and ensures cleanup in the finally block to prevent thread pollution in the container's thread pool. %X{key} in logback patterns outputs MDC values. This allows tracing a specific request across all log lines even in complex service calls."
            },
            "keyPoints": [
              "MDC is thread-local storage for logging context",
              "Stores requestId, userId, traceId for correlation",
              "Must call MDC.clear() in finally block to prevent leaks",
              "Access in log patterns via %X{key} or included in JSON logs",
              "Requires manual propagation in async/reactive contexts"
            ],
            "extras": {
              "flowDiagram": "Request -> Filter (MDC.put requestId)) -> Controller (log includes requestId) -> Service (log includes requestId) -> Filter (MDC.clear())",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "test-1",
            "title": "@WebMvcTest",
            "explanations": {
              "english": "@WebMvcTest is a test slice annotation that auto-configures the Spring MVC infrastructure for controller layer testing without starting the full ApplicationContext. It configures MockMvc for performing HTTP requests and validating responses without an actual web server. Only @Controller, @ControllerAdvice, @JsonComponent, Filter, and WebMvcConfigurer beans are loaded. Dependencies are typically mocked using @MockBean. This approach is significantly faster than @SpringBootTest for verifying request mappings, input validation, exception handling, and response serialization in the web layer."
            },
            "code": {
              "title": "Controller Testing",
              "language": "java",
              "content": "@WebMvcTest(OrderController.class)\n@AutoConfigureMockMvc(addFilters = false) // Skip security filters for unit test\npublic class OrderControllerTest {\n    \n    @Autowired\n    private MockMvc mockMvc;\n    \n    @MockBean\n    private OrderService orderService;\n    \n    @Test\n    void shouldCreateOrder() throws Exception {\n        Order order = new Order(1L, \"PRODUCT-123\", 2);\n        when(orderService.create(any())).thenReturn(order);\n        \n        mockMvc.perform(post(\"/api/orders\")\n                .contentType(MediaType.APPLICATION_JSON)\n                .content(\"{\\\"productId\\\":\\\"PRODUCT-123\\\",\\\"quantity\\\":2}\"))\n            .andExpect(status().isCreated())\n            .andExpect(jsonPath(\"$.id\", is(1)))\n            .andExpect(jsonPath(\"$.productId\", is(\"PRODUCT-123\")))\n            .andExpect(header().string(\"Location\", containsString(\"/api/orders/1\")));\n    }\n    \n    @Test\n    void shouldReturnValidationError() throws Exception {\n        mockMvc.perform(post(\"/api/orders\")\n                .contentType(MediaType.APPLICATION_JSON)\n                .content(\"{\\\"productId\\\":\\\"\\\",\\\"quantity\\\":-1}\"))\n            .andExpect(status().isBadRequest())\n            .andExpect(jsonPath(\"$.errors\").isArray());\n    }\n}"
            },
            "codeExplanations": {
              "english": "@WebMvcTest loads only web layer components. MockMvc simulates HTTP requests without running a server. @MockBean creates Mockito mocks for service dependencies. The test verifies HTTP status, JSON response structure using jsonPath, and response headers. The addFilters=false parameter disables security filters to test controller logic in isolation."
            },
            "keyPoints": [
              "Test slice for MVC layer only (controllers, advices, filters)",
              "Configures MockMvc for simulated HTTP requests",
              "Does not start embedded server (faster than @SpringBootTest)",
              "Use @MockBean for service layer dependencies",
              "Validates request mapping, serialization, validation, and exception handling"
            ],
            "extras": {
              "flowDiagram": "Test -> @WebMvcTest -> Load Controller + MockMvc -> Mock Service -> Execute Request -> Assert Response",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "test-2",
            "title": "@DataJpaTest",
            "explanations": {
              "english": "@DataJpaTest is a test slice for JPA repository testing that auto-configures an embedded (in-memory) database by default, configures Spring Data JPA repositories, and sets up the EntityManager. It excludes web components, component scanning, and other infrastructure, focusing solely on the data layer. Tests are @Transactional by default and rollback after each test method to maintain test isolation. While it defaults to H2, @AutoConfigureTestDatabase can replace it with real databases. This slice is ideal for verifying custom queries, derived methods, and entity mappings without loading the full application context."
            },
            "code": {
              "title": "Repository Testing",
              "language": "java",
              "content": "@DataJpaTest\n@AutoConfigureTestDatabase(replace = AutoConfigureTestDatabase.Replace.NONE) // Use real DB defined in properties\npublic class OrderRepositoryTest {\n    \n    @Autowired\n    private OrderRepository repository;\n    \n    @Autowired\n    private TestEntityManager entityManager;\n    \n    @Test\n    void shouldFindOrdersByStatus() {\n        Order pending = new Order(Status.PENDING);\n        Order completed = new Order(Status.COMPLETED);\n        entityManager.persist(pending);\n        entityManager.persist(completed);\n        entityManager.flush();\n        \n        List<Order> results = repository.findByStatus(Status.PENDING);\n        \n        assertThat(results).hasSize(1);\n        assertThat(results.get(0).getStatus()).isEqualTo(Status.PENDING);\n    }\n    \n    @Test\n    void shouldExecuteCustomQuery() {\n        repository.save(new Order(\"ITEM-1\", LocalDateTime.now()));\n        repository.save(new Order(\"ITEM-2\", LocalDateTime.now().minusDays(1)));\n        \n        List<Order> recent = repository.findOrdersFromLast24Hours();\n        \n        assertThat(recent).hasSize(1);\n    }\n}"
            },
            "codeExplanations": {
              "english": "@DataJpaTest configures JPA components and in-memory database. TestEntityManager provides JPA operations directly for test setup. The default @Transactional rolls back after each test to keep tests isolated. Replace.NONE uses the configured datasource instead of replacing with embedded database, useful for testing against real database behavior."
            },
            "keyPoints": [
              "Test slice for repositories and JPA components",
              "Auto-configures in-memory database (H2) by default",
              "Automatic entity scanning and repository configuration",
              "Tests run in transactions rolled back automatically",
              "TestEntityManager provides utility methods for setup and verification"
            ],
            "extras": {
              "flowDiagram": "Test -> @DataJpaTest -> Configure JPA + Embedded DB -> Test Method (Transaction) -> Auto Rollback",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "test-3",
            "title": "@JsonTest",
            "explanations": {
              "english": "@JsonTest is a test slice for JSON serialization and deserialization testing. It auto-configures Jackson ObjectMapper (or Gson if preferred), @JsonComponent beans, and various Jackson modules. This slice is useful for verifying that domain objects serialize correctly to JSON with appropriate field names, date formats, and custom serializers, or deserialize correctly from JSON including handling unknown properties or validations. It does not load the web layer or data layer, making these tests extremely fast while ensuring API contract compliance."
            },
            "code": {
              "title": "JSON Serialization Testing",
              "language": "java",
              "content": "@JsonTest\npublic class OrderJsonTest {\n    \n    @Autowired\n    private JacksonTester<Order> json;\n    \n    @Test\n    void shouldSerializeOrder() throws IOException {\n        Order order = new Order(1L, \"PRODUCT-ABC\", \n                               LocalDateTime.of(2024, 1, 15, 10, 0));\n        \n        assertThat(json.write(order)).isStrictlyEqualToJson(\"expected.json\");\n        assertThat(json.write(order)).hasJsonPathStringValue(\"@.productId\", \"PRODUCT-ABC\");\n        assertThat(json.write(order)).extractingJsonPathNumberValue(\"@.id\").isEqualTo(1);\n    }\n    \n    @Test\n    void shouldDeserializeOrder() throws IOException {\n        String content = \"{\\\"id\\\":2,\\\"productId\\\":\\\"PRODUCT-XYZ\\\",\\\"createdAt\\\":\\\"2024-01-15T10:00:00\\\"}\";\n        \n        assertThat(json.parse(content))\n            .usingRecursiveComparison()\n            .isEqualTo(new Order(2L, \"PRODUCT-XYZ\", \n                                LocalDateTime.of(2024, 1, 15, 10, 0)));\n    }\n    \n    @Test\n    void shouldIgnoreUnknownProperties() throws IOException {\n        String content = \"{\\\"id\\\":3,\\\"productId\\\":\\\"P\\\",\\\"unknownField\\\":\\\"value\\\"}\";\n        assertThat(json.parse(content).getObject().getId()).isEqualTo(3);\n    }\n}"
            },
            "codeExplanations": {
              "english": "JacksonTester provides fluent assertions for JSON content. isStrictlyEqualToJson compares against a file in test resources. hasJsonPathStringValue verifies specific JSON path values. The test confirms proper serialization of Java 8 date/time, handling of unknown properties (via @JsonIgnoreProperties(ignoreUnknown=true)), and deserialization integrity without loading web or database contexts."
            },
            "keyPoints": [
              "Test slice for ObjectMapper and JSON mapping",
              "Auto-configures Jackson and custom serializers",
              "Does not load web or data layers (very fast)",
              "JacksonTester provides JSON-specific assertions",
              "Verifies API contract compliance for payloads"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "test-4",
            "title": "@SpringBootTest",
            "explanations": {
              "english": "@SpringBootTest loads the complete ApplicationContext for full integration testing, allowing tests to exercise the entire stack from controllers through services to repositories. It can start an embedded servlet container with random or defined ports using webEnvironment options. It resolves @Value properties, loads configuration files, and executes auto-configuration as in production. While comprehensive, these tests are slower due to full context initialization, so they should be used sparingly for critical end-to-end flows while favoring test slices for isolated component testing."
            },
            "code": {
              "title": "Integration Testing",
              "language": "java",
              "content": "@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)\n@Testcontainers\npublic class OrderIntegrationTest {\n    \n    @LocalServerPort\n    private int port;\n    \n    @Container\n    static PostgreSQLContainer<?> postgres = new PostgreSQLContainer<>(\"postgres:15\")\n        .withDatabaseName(\"testdb\")\n        .withUsername(\"test\")\n        .withPassword(\"test\");\n    \n    @DynamicPropertySource\n    static void configureProperties(DynamicPropertyRegistry registry) {\n        registry.add(\"spring.datasource.url\", postgres::getJdbcUrl);\n        registry.add(\"spring.datasource.username\", postgres::getUsername);\n        registry.add(\"spring.datasource.password\", postgres::getPassword);\n    }\n    \n    @Autowired\n    private TestRestTemplate restTemplate;\n    \n    @Autowired\n    private OrderRepository repository;\n    \n    @Test\n    void fullOrderLifecycle() {\n        OrderRequest request = new OrderRequest(\"ITEM-001\", 5);\n        \n        ResponseEntity<Order> response = restTemplate.postForEntity(\n            \"http://localhost:\" + port + \"/api/orders\", \n            request, Order.class);\n        \n        assertThat(response.getStatusCode()).isEqualTo(HttpStatus.CREATED);\n        assertThat(repository.findById(response.getBody().getId())).isPresent();\n    }\n}"
            },
            "codeExplanations": {
              "english": "@SpringBootTest with RANDOM_PORT starts the full application context with embedded Tomcat on a random port. @Testcontainers provides PostgreSQL via Docker. DynamicPropertySource overrides datasource properties to point to the container. TestRestTemplate makes actual HTTP calls to the running server, testing the complete stack including serialization, validation, persistence, and HTTP status handling."
            },
            "keyPoints": [
              "Loads complete ApplicationContext including all beans",
              "Starts embedded server with webEnvironment options (MOCK, RANDOM_PORT, DEFINED_PORT)",
              "@LocalServerPort injects the actual port used",
              "Slowest test type due to full context startup; use sparingly",
              "Ideal for end-to-end smoke tests and critical path validation"
            ],
            "extras": {
              "flowDiagram": "Test -> @SpringBootTest -> Start Full Context + Embedded Server -> HTTP Request -> Full Stack Processing -> Assert",
              "comparisonTable": [
                {
                  "headers": [
                    "Annotation",
                    "Scope",
                    "Speed",
                    "Server"
                  ],
                  "rows": [
                    [
                      "@WebMvcTest",
                      "Controller layer only\", \"Fast\", \"MockMvc (no server)"
                    ],
                    [
                      "@DataJpaTest",
                      "Repository layer only\", \"Fast\", \"None"
                    ],
                    [
                      "@SpringBootTest",
                      "Full context\", \"Slow\", \"Embedded Tomcat"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "test-5",
            "title": "@MockBean",
            "explanations": {
              "english": "@MockBean replaces an existing bean in the Spring ApplicationContext with a Mockito mock. It is primarily used in @SpringBootTest and test slices when you need to isolate the class under test from its dependencies. The mock is injected into the context and can be configured using standard Mockito methods like when() and verify(). After each test, the mock is automatically reset. This is essential for testing service layers without actually calling external APIs or databases, or for simulating error conditions that are hard to reproduce with real implementations."
            },
            "code": {
              "title": "Mocking Dependencies",
              "language": "java",
              "content": "@SpringBootTest\npublic class OrderServiceIntegrationTest {\n    \n    @Autowired\n    private OrderService orderService;\n    \n    @MockBean\n    private PaymentGatewayClient paymentGateway;\n    \n    @MockBean\n    private NotificationService notificationService;\n    \n    @Test\n    void shouldProcessOrderWhenPaymentSucceeds() {\n        when(paymentGateway.charge(any(), any()))\n            .thenReturn(new PaymentResult(true, \"TX-123\"));\n        \n        Order order = orderService.processOrder(new OrderRequest(\"ITEM\", 100.0));\n        \n        assertThat(order.getStatus()).isEqualTo(OrderStatus.COMPLETED);\n        verify(paymentGateway).charge(eq(\"ITEM\"), eq(BigDecimal.valueOf(100.0)));\n        verify(notificationService).sendOrderConfirmation(order);\n    }\n    \n    @Test\n    void shouldRollbackWhenPaymentFails() {\n        when(paymentGateway.charge(any(), any()))\n            .thenThrow(new PaymentException(\"Insufficient funds\"));\n        \n        assertThatThrownBy(() -> orderService.processOrder(new OrderRequest(\"ITEM\", 100.0)))\n            .isInstanceOf(OrderProcessingException.class);\n        \n        verify(notificationService, never()).sendOrderConfirmation(any());\n    }\n}"
            },
            "codeExplanations": {
              "english": "@MockBean creates Mockito mocks that replace real beans in the Spring context. The test configures mock behavior for happy path and error scenarios. verify() ensures expected interactions occurred or didn't occur. This isolates the service logic from external payment systems and notification services while verifying the integration points are called correctly."
            },
            "keyPoints": [
              "Replaces bean in ApplicationContext with Mockito mock",
              "Used in @SpringBootTest and test slices",
              "Automatically reset after each test method",
              "Configure with when().thenReturn() or when().thenThrow()",
              "Verify interactions with verify() to test collaboration"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "test-6",
            "title": "Mockito",
            "explanations": {
              "english": "Mockito is the standard mocking framework for Java unit tests. It creates proxy objects that simulate the behavior of real collaborators without requiring the actual implementation. Annotations include @Mock to create mock instances, @InjectMocks to instantiate the class under test and inject mocks into it, and @Spy for partial mocking of real objects. Stubbing defines behavior with when().thenReturn(), while verification checks method invocation counts with verify(). ArgumentMatchers like any(), eq(), and argThat() provide flexible argument matching. Strict stubbing mode helps identify unnecessary stubs."
            },
            "code": {
              "title": "Mockito Fundamentals",
              "language": "java",
              "content": "@ExtendWith(MockitoExtension.class)\npublic class InventoryServiceTest {\n    \n    @Mock\n    private InventoryRepository repository;\n    \n    @Mock\n    private EventPublisher eventPublisher;\n    \n    @InjectMocks\n    private InventoryService inventoryService;\n    \n    @Captor\n    private ArgumentCaptor<StockUpdateEvent> eventCaptor;\n    \n    @Test\n    void shouldUpdateStockAndPublishEvent() {\n        // Stubbing\n        when(repository.findByProductId(\"PROD-1\"))\n            .thenReturn(Optional.of(new Inventory(\"PROD-1\", 100)));\n        when(repository.save(any(Inventory.class)))\n            .thenAnswer(inv -> inv.getArgument(0));\n        \n        // Execute\n        Inventory result = inventoryService.decrementStock(\"PROD-1\", 5);\n        \n        // Verification\n        assertThat(result.getQuantity()).isEqualTo(95);\n        verify(repository).save(argThat(inv -> inv.getQuantity() == 95));\n        verify(eventPublisher).publish(eventCaptor.capture());\n        assertThat(eventCaptor.getValue().getProductId()).isEqualTo(\"PROD-1\");\n        \n        verifyNoMoreInteractions(repository);\n    }\n    \n    @Test\n    void shouldThrowWhenInsufficientStock() {\n        when(repository.findByProductId(anyString()))\n            .thenReturn(Optional.of(new Inventory(\"PROD-1\", 3)));\n        \n        assertThrows(InsufficientStockException.class, () -> {\n            inventoryService.decrementStock(\"PROD-1\", 5);\n        });\n    }\n}"
            },
            "codeExplanations": {
              "english": "@ExtendWith(MockitoExtension.class) enables Mockito without Spring. @InjectMocks creates the service and injects @Mock fields. when().thenReturn() stubs repository behavior. argThat() verifies arguments match custom predicates. ArgumentCaptor captures arguments passed to mocks for detailed assertion. verifyNoMoreInteractions ensures no unexpected calls were made to the mock."
            },
            "keyPoints": [
              "@Mock creates mock instances of dependencies",
              "@InjectMocks creates the subject under test with mocks injected",
              "when().thenReturn() stubs method behavior",
              "verify() checks method was called with specific arguments",
              "ArgumentCaptor captures arguments for verification"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [
                {
                  "headers": [
                    "Feature",
                    "Purpose"
                  ],
                  "rows": [
                    [
                      "@Mock",
                      "Create mock object"
                    ],
                    [
                      "@Spy",
                      "Partial mock of real object"
                    ],
                    [
                      "@InjectMocks",
                      "Auto-inject mocks into subject"
                    ],
                    [
                      "when().thenReturn()",
                      "Define stub behavior"
                    ],
                    [
                      "verify().never()",
                      "Verify interaction did not happen"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "test-7",
            "title": "Testcontainers",
            "explanations": {
              "english": "Testcontainers is a Java library that provides lightweight, throwaway instances of databases, message brokers, web browsers, and other dependencies running in Docker containers. It enables integration testing against real infrastructure rather than mocks or in-memory databases, catching issues like SQL dialect differences and networking problems. Containers are defined with @Container annotation and started before tests. @DynamicPropertySource injects connection details (like dynamic ports) into Spring properties. This ensures test environments match production closely while remaining isolated and reproducible across different development machines and CI/CD pipelines."
            },
            "code": {
              "title": "Containerized Integration Tests",
              "language": "java",
              "content": "@SpringBootTest\n@Testcontainers\npublic class MessagingIntegrationTest {\n    \n    @Container\n    static KafkaContainer kafka = new KafkaContainer(\n        DockerImageName.parse(\"confluentinc/cp-kafka:7.5.0\"));\n    \n    @Container\n    static GenericContainer<?> redis = new GenericContainer<>(\"redis:7-alpine\")\n        .withExposedPorts(6379);\n    \n    @DynamicPropertySource\n    static void properties(DynamicPropertyRegistry registry) {\n        registry.add(\"spring.kafka.bootstrap-servers\", kafka::getBootstrapServers);\n        registry.add(\"spring.data.redis.host\", redis::getHost);\n        registry.add(\"spring.data.redis.port\", redis::getFirstMappedPort);\n    }\n    \n    @Autowired\n    private KafkaTemplate<String, OrderEvent> kafkaTemplate;\n    \n    @Autowired\n    private OrderRepository repository;\n    \n    @Test\n    void shouldProcessOrderEventAndCacheResult() throws Exception {\n        OrderEvent event = new OrderEvent(\"ORDER-1\", \"PRODUCT-A\", 5);\n        \n        kafkaTemplate.send(\"orders\", event).get();\n        \n        // Wait for async processing\n        await().atMost(Duration.ofSeconds(5)).untilAsserted(() -> {\n            assertThat(repository.findById(\"ORDER-1\")).isPresent();\n        });\n    }\n}"
            },
            "codeExplanations": {
              "english": "@Testcontainers enables the Testcontainers extension. @Container defines Docker containers that start before tests and stop after. KafkaContainer provides convenient methods for bootstrap servers. GenericContainer allows any Docker image. DynamicPropertySource dynamically overrides Spring properties with container-specific connection details (random ports mapped). This tests the actual integration with Kafka and Redis without mocks."
            },
            "keyPoints": [
              "Provides real dependencies in Docker containers for tests",
              "Matches production environment (same versions, real network)",
              "@Container manages container lifecycle (start before, stop after)",
              "@DynamicPropertySource injects connection strings into Spring Environment",
              "Supports databases (PostgreSQL, MySQL), brokers (Kafka, RabbitMQ), and cloud services"
            ],
            "extras": {
              "flowDiagram": "Test Start -> Start Docker Containers (Kafka, Redis) -> Run DynamicPropertySource -> Start Spring Context (with real connections) -> Execute Tests -> Stop Containers",
              "comparisonTable": [
                {
                  "headers": [
                    "Approach",
                    "Fidelity",
                    "Speed",
                    "Portability"
                  ],
                  "rows": [
                    [
                      "H2 Database\", \"Low (different SQL)\", \"Very Fast\", \"High"
                    ],
                    [
                      "Testcontainers\"",
                      "High (same as prod)",
                      "Slow (Docker pull)",
                      "Requires Docker"
                    ],
                    [
                      "@MockBean\", \"Medium (logic only)\", \"Fast\", \"High"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          }
        ]
      },
      {
        "id": "microservices-architecture",
        "title": "Microservices Architecture",
        "description": "Comprehensive guide to building cloud-native distributed systems using Spring Boot, covering service decomposition, inter-service communication patterns, service discovery, API gateways, containerization, and resilient microservices patterns.",
        "topics": [
          {
            "id": "micro-1",
            "title": "Monolith vs Microservices",
            "explanations": {
              "english": "Monolithic architectures deploy all functionality as a single unit, offering simplicity in development and debugging but limiting scalability and technology diversity. Microservices decompose applications into independently deployable services aligned with business capabilities, enabling autonomous scaling, polyglot persistence, and team independence. However, microservices introduce complexity in distributed transactions, service coordination, network latency, and operational overhead. The decision depends on team size, scaling requirements, and organizational maturity. Many organizations start with monoliths and extract services incrementally as boundaries clarify."
            },
            "code": {
              "title": "Architectural Evolution",
              "language": "java",
              "content": "// Monolithic: All code deployed together\n@Entity\npublic class Order {\n    @OneToMany\n    private List<OrderItem> items;\n    @ManyToOne \n    private Customer customer;  // Same database, same codebase\n}\n\n// Microservices: Separate services, separate databases\n// Order Service\n@Service\npublic class OrderService {\n    private final OrderRepository orderRepo;\n    private final CustomerClient customerClient;  // HTTP/RPC call to Customer Service\n    private final InventoryClient inventoryClient;  // HTTP/RPC call to Inventory Service\n}"
            },
            "codeExplanations": {
              "english": "The monolithic example shows tight coupling within a single database. The microservices example demonstrates how OrderService coordinates with Customer and Inventory services via network calls rather than direct database joins, enforcing service boundaries and database-per-service pattern."
            },
            "keyPoints": [
              "Monolith: Single codebase, single database, simple deployment",
              "Microservices: Independent deployment, decentralized data management, bounded contexts",
              "Microservices trade code complexity for operational complexity",
              "Database-per-service pattern prevents tight coupling",
              "Start with monolith, extract microservices when scaling demands"
            ],
            "extras": {
              "flowDiagram": "Monolith: Web+Business+Data Logic -> Single Database\nMicroservices: API Gateway -> [Order Service -> Order DB] + [Customer Service -> Customer DB] + [Inventory Service -> Inventory DB]",
              "comparisonTable": [
                {
                  "headers": [
                    "Characteristic",
                    "Monolith",
                    "Microservices"
                  ],
                  "rows": [
                    [
                      "Deployment",
                      "Single artifact",
                      "Multiple independent pipelines"
                    ],
                    [
                      "Scalability",
                      "Scale entire app",
                      "Scale individual services"
                    ],
                    [
                      "Fault Isolation",
                      "Total failure possible",
                      "Partial degradation"
                    ],
                    [
                      "Data Consistency",
                      "ACID transactions",
                      "Eventual consistency, sagas"
                    ],
                    [
                      "Technology",
                      "Single stack",
                      "Polyglot programming"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "micro-2",
            "title": "Bounded Contexts",
            "explanations": {
              "english": "Bounded Contexts are central to Domain-Driven Design, defining explicit boundaries within which a domain model is consistent and applicable. Each microservice typically aligns with a bounded context, owning its data and business rules. Contexts have explicit integration contracts (anti-corruption layers) preventing leakage of internal models. Ubiquitous Language within a context ensures terms have precise meaning (e.g., 'Customer' means different things in Billing vs Shipping contexts). Clear boundaries reduce coupling and enable teams to evolve models independently without breaking other services."
            },
            "code": {
              "title": "Context Boundary Implementation",
              "language": "java",
              "content": "// Billing Context: Customer has payment methods\npackage com.billing.domain;\npublic class Customer {\n    private CustomerId id;\n    private List<PaymentMethod> paymentMethods;\n    private BillingAddress address;\n    public void charge(Money amount) { ... }\n}\n\n// Shipping Context: Customer has delivery preferences  \npackage com.shipping.domain;\npublic class Customer {\n    private CustomerId id;\n    private List<ShippingAddress> addresses;\n    private DeliveryPreferences preferences;\n    public void updatePreferences(DeliveryPreferences prefs) { ... }\n}\n\n// Anti-Corruption Layer: Order Service translation\n@Service\npublic class OrderCustomerAdapter {\n    public OrderCustomerDTO fetchCustomerForOrder(CustomerId id) {\n        BillingCustomer billing = billingClient.getCustomer(id);\n        ShippingCustomer shipping = shippingClient.getCustomer(id);\n        \n        // Translate to Order Context's view of Customer\n        return new OrderCustomerDTO(\n            id, \n            billing.getDefaultPaymentMethod(),\n            shipping.getDefaultShippingAddress()\n        );\n    }\n}"
            },
            "codeExplanations": {
              "english": "Different contexts define Customer differently based on their responsibilities. The Anti-Corruption Layer (Adapter) translates external domain models into the local Order context's model, protecting the Order service from external model changes and maintaining conceptual integrity within the Order bounded context."
            },
            "keyPoints": [
              "Each microservice owns a bounded context with its ubiquitous language",
              "Same entity name (Customer) can represent different concepts in different contexts",
              "Anti-corruption layers translate between contexts preventing model leakage",
              "Database schemas are internal implementation details of the context",
              "Context maps define integration relationships between services"
            ],
            "extras": {
              "flowDiagram": "Billing Context (Customer+Payment) <- ACL -> Order Context (CustomerRef+Order) <- ACL -> Shipping Context (Customer+Address)",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "micro-3",
            "title": "Team Autonomy",
            "explanations": {
              "english": "Microservices enable Conway's Law in reverse: architecture drives organizational structure. Two-pizza teams (5-9 people) own complete services from development through production, eliminating cross-team dependencies for deployments. Autonomous teams choose their technology stacks, release schedules, and scaling policies independently. This requires platform engineering support for self-service infrastructure, CI/CD pipelines, and observability tools. Team autonomy increases velocity but requires strong API contracts, clear SLOs (Service Level Objectives), and robust inter-team communication to prevent integration failures."
            },
            "code": {
              "title": "Contract-Driven Development",
              "language": "java",
              "content": "// Consumer-Driven Contract: Order Service defines expectations\npublic interface CustomerClientContract {\n    @GetMapping(\"/customers/{id}\")\n    CustomerDTO getCustomer(@PathVariable String id);\n}\n\n// Team A (Order) writes contract tests\n@SpringBootTest\n@AutoConfigureStubRunner(ids = \"com.company:customer-service:+:stubs:8081\")\npublic class CustomerContractTest {\n    @Test\n    public void shouldReturnCustomerDetails() {\n        CustomerDTO customer = customerClient.getCustomer(\"123\");\n        assertThat(customer.getId()).isNotNull();\n        assertThat(customer.getPaymentMethod()).isNotNull();\n    }\n}\n\n// Team B (Customer) implements to satisfy contracts\n@RestController\npublic class CustomerController implements CustomerClientContract {\n    @Override\n    public CustomerDTO getCustomer(String id) {\n        return customerService.findById(id);\n    }\n}"
            },
            "codeExplanations": {
              "english": "Consumer-Driven Contracts (CDC) using Spring Cloud Contract enable autonomous teams. The Order team defines expectations in contracts. StubRunner verifies Order service against Customer stubs. The Customer team implements to satisfy these contracts, ensuring API compatibility without tight coordination."
            },
            "keyPoints": [
              "Two-pizza teams own services end-to-end (you build it, you run it)",
              "Autonomy requires self-service platforms for deployment and monitoring",
              "API contracts (OpenAPI, gRPC proto) enable independent evolution",
              "Consumer-Driven Contracts prevent breaking changes",
              "SLOs define acceptable performance and availability between teams"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "micro-4",
            "title": "REST (Feign)",
            "explanations": {
              "english": "Synchronous REST communication uses HTTP request-response patterns for real-time service interaction. OpenFeign is a declarative HTTP client that simplifies inter-service calls by creating dynamic implementations of interfaces annotated with @FeignClient. It integrates with Ribbon for client-side load balancing and Hystrix/Resilience4j for circuit breaking. Feign reduces boilerplate compared to RestTemplate or WebClient but introduces temporal coupling; if the target service is down, the caller fails. Synchronous calls should be short, cached where possible, and wrapped in resilience patterns to prevent cascade failures."
            },
            "code": {
              "title": "Feign Client Implementation",
              "language": "java",
              "content": "@FeignClient(\n    name = \"inventory-service\",\n    configuration = InventoryFeignConfig.class,\n    fallbackFactory = InventoryClientFallbackFactory.class\n)\npublic interface InventoryClient {\n    \n    @GetMapping(\"/api/inventory/{productId}\")\n    InventoryStatus checkStock(@PathVariable String productId);\n    \n    @PostMapping(\"/api/inventory/reserve\")\n    ReservationResult reserveStock(@RequestBody ReservationRequest request);\n}\n\n@Component\npublic class InventoryClientFallbackFactory implements FallbackFactory<InventoryClient> {\n    @Override\n    public InventoryClient create(Throwable cause) {\n        return new InventoryClient() {\n            @Override\n            public InventoryStatus checkStock(String productId) {\n                return InventoryStatus.unknown(); // Graceful degradation\n            }\n            \n            @Override\n            public ReservationResult reserveStock(ReservationRequest request) {\n                throw new InventoryServiceUnavailableException(cause);\n            }\n        };\n    }\n}\n\n// Usage\n@Service\npublic class OrderService {\n    private final InventoryClient inventoryClient;\n    \n    public void processOrder(Order order) {\n        InventoryStatus status = inventoryClient.checkStock(order.getProductId());\n        if (status.isAvailable()) {\n            // Proceed\n        }\n    }\n}"
            },
            "codeExplanations": {
              "english": "@FeignClient declares an HTTP client interface. Spring creates the implementation dynamically. FallbackFactory provides fallback behavior when the service is unavailable, preventing cascade failures. The fallback returns default values for queries and throws exceptions for commands, following the fail-fast principle for writes."
            },
            "keyPoints": [
              "Feign provides declarative REST clients reducing boilerplate code",
              "Integrates with service discovery (Eureka) for dynamic URL resolution",
              "FallbackFactory enables graceful degradation during service outages",
              "Synchronous calls create temporal coupling; use for queries, avoid long chains",
              "Combine with circuit breakers to prevent cascade failures"
            ],
            "extras": {
              "flowDiagram": "Order Service -> Feign Client -> Load Balancer -> Inventory Service Instance 1\n                                         -> Inventory Service Instance 2",
              "comparisonTable": [
                {
                  "headers": [
                    "Client",
                    "Style",
                    "Async Support",
                    "Verbose"
                  ],
                  "rows": [
                    [
                      "RestTemplate",
                      "Imperative\", \"No\", \"High"
                    ],
                    [
                      "WebClient",
                      "Reactive\", \"Yes\", \"Medium"
                    ],
                    [
                      "OpenFeign\", \"Declarative\", \"No\", \"Low"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "micro-5",
            "title": "gRPC",
            "explanations": {
              "english": "gRPC is a high-performance RPC framework using Protocol Buffers for efficient binary serialization and HTTP/2 for transport. It generates client and server stubs from .proto definitions, ensuring contract compliance. Unlike REST, gRPC uses strict service contracts with strongly typed messages, reducing integration errors. It supports bi-directional streaming for real-time communication and multiplexes multiple calls over a single connection. However, gRPC requires HTTP/2 support throughout the infrastructure (load balancers, proxies) and is less browser-friendly than REST, making it ideal for internal service-to-service communication."
            },
            "code": {
              "title": "gRPC Service Definition",
              "language": "protobuf",
              "content": "// inventory.proto\nsyntax = \"proto3\";\n\nservice InventoryService {\n  rpc CheckStock (StockRequest) returns (StockResponse);\n  rpc StreamStockUpdates (stream StockRequest) returns (stream StockUpdate);\n}\n\nmessage StockRequest {\n  string product_id = 1;\n  int32 quantity = 2;\n}\n\nmessage StockResponse {\n  string product_id = 1;\n  bool available = 2;\n  int32 current_stock = 3;\n}"
            },
            "codeExplanations": {
              "english": "The proto file defines the service contract using Protocol Buffers. CheckStock is a unary RPC. StreamStockUpdates demonstrates bi-directional streaming. Field numbers (1, 2, 3) ensure backward compatibility when adding new fields. This generates Java classes and stubs for type-safe communication."
            },
            "keyPoints": [
              "Protocol Buffers provide efficient binary serialization (smaller than JSON)",
              "HTTP/2 enables multiplexing, header compression, and bi-directional streaming",
              "Strong typing via generated stubs prevents contract violations",
              "Requires HTTP/2 support in network infrastructure",
              "Ideal for high-performance internal service communication"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [
                {
                  "headers": [
                    "Aspect",
                    "REST/HTTP",
                    "gRPC"
                  ],
                  "rows": [
                    [
                      "Protocol",
                      "HTTP/1.1 or HTTP/2",
                      "HTTP/2"
                    ],
                    [
                      "Serialization",
                      "JSON/XML (text)\", \"Protocol Buffers (binary)"
                    ],
                    [
                      "Streaming",
                      "Server-Sent Events\", \"Native bi-directional"
                    ],
                    [
                      "Strong Typing",
                      "Weak (OpenAPI)\", \"Strong (generated stubs)"
                    ],
                    [
                      "Browser Support",
                      "Excellent\", \"Requires gRPC-Web proxy"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "micro-6",
            "title": "RabbitMQ",
            "explanations": {
              "english": "RabbitMQ is a message broker implementing AMQP (Advanced Message Queuing Protocol) for reliable asynchronous messaging. It supports various exchange types: direct (point-to-point), topic (publish-subscribe with patterns), fanout (broadcast), and headers. Messages are routed through exchanges to queues, decoupling producers from consumers. RabbitMQ provides message durability (persisting to disk), acknowledgments (ensuring delivery), and TTL (time-to-live) for expiration. It excels in complex routing scenarios and request-reply patterns but has lower throughput compared to Kafka for high-volume streaming."
            },
            "code": {
              "title": "RabbitMQ Implementation",
              "language": "java",
              "content": "@Configuration\npublic class RabbitConfig {\n    @Bean\n    public TopicExchange orderExchange() {\n        return new TopicExchange(\"orders.exchange\");\n    }\n    \n    @Bean\n    public Queue orderCreatedQueue() {\n        return QueueBuilder.durable(\"orders.created\")\n            .withArgument(\"x-message-ttl\", 60000)\n            .build();\n    }\n    \n    @Bean\n    public Binding binding(Queue orderCreatedQueue, TopicExchange orderExchange) {\n        return BindingBuilder.bind(orderCreatedQueue)\n            .to(orderExchange).with(\"order.created.*\");\n    }\n}\n\n@Service\npublic class OrderEventPublisher {\n    private final RabbitTemplate rabbitTemplate;\n    \n    public void publishOrderCreated(Order order) {\n        OrderCreatedEvent event = new OrderCreatedEvent(order.getId(), order.getAmount());\n        rabbitTemplate.convertAndSend(\"orders.exchange\", \n                                     \"order.created.\" + order.getRegion(), \n                                     event);\n    }\n}\n\n@Component\npublic class InventoryListener {\n    @RabbitListener(queues = \"orders.created\")\n    public void handleOrderCreated(OrderCreatedEvent event) {\n        inventoryService.reserveStock(event.getOrderId(), event.getItems());\n    }\n}"
            },
            "codeExplanations": {
              "english": "TopicExchange routes messages based on routing key patterns. The durable queue survives broker restarts with a 60-second TTL for messages. The binding connects the queue to the exchange with a wildcard pattern (order.created.*). RabbitTemplate sends messages, while @RabbitListener creates a container to consume messages asynchronously, enabling the Inventory service to react to order events without direct HTTP calls."
            },
            "keyPoints": [
              "AMQP protocol with flexible routing (direct, topic, fanout exchanges)",
              "Decouples producers from consumers via queues",
              "Supports message durability, acknowledgments, and TTL",
              "Complex routing logic with exchange-to-exchange bindings",
              "Lower throughput than Kafka but richer messaging semantics"
            ],
            "extras": {
              "flowDiagram": "Order Service -> Exchange (topic) -> Queue (orders.created) -> Inventory Service\n                                    -> Queue (orders.created) -> Shipping Service",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "micro-7",
            "title": "Kafka",
            "explanations": {
              "english": "Apache Kafka is a distributed event streaming platform designed for high-throughput, fault-tolerant message processing. Unlike traditional message brokers, Kafka persists messages to disk with configurable retention, allowing consumers to replay events. It uses a partitioned log structure where topics are split across multiple brokers for horizontal scalability. Producers write to topic partitions; consumers read from partitions within consumer groups, enabling parallel processing. Kafka excels in event sourcing, log aggregation, and stream processing but requires careful partition strategy design to ensure ordering and avoid hotspots."
            },
            "code": {
              "title": "Kafka Configuration",
              "language": "java",
              "content": "@Configuration\npublic class KafkaConfig {\n    @Bean\n    public ProducerFactory<String, OrderEvent> producerFactory() {\n        Map<String, Object> config = new HashMap<>();\n        config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"kafka:9092\");\n        config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);\n        config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);\n        config.put(ProducerConfig.ACKS_CONFIG, \"all\"); // Wait for all replicas\n        config.put(ProducerConfig.RETRIES_CONFIG, 3);\n        return new DefaultKafkaProducerFactory<>(config);\n    }\n    \n    @Bean\n    public KafkaTemplate<String, OrderEvent> kafkaTemplate() {\n        return new KafkaTemplate<>(producerFactory());\n    }\n}\n\n@Service\npublic class OrderEventProducer {\n    private final KafkaTemplate<String, OrderEvent> kafkaTemplate;\n    \n    public void sendOrderEvent(OrderEvent event) {\n        // Key ensures same orderId goes to same partition (ordering guarantee)\n        kafkaTemplate.send(\"orders\", event.getOrderId(), event)\n            .whenComplete((result, ex) -> {\n                if (ex != null) {\n                    log.error(\"Failed to send event\", ex);\n                }\n            });\n    }\n}\n\n@Component\npublic class OrderConsumer {\n    @KafkaListener(topics = \"orders\", groupId = \"inventory-service\")\n    public void handleOrder(@Payload OrderEvent event, \n                           @Header(KafkaHeaders.RECEIVED_PARTITION) int partition) {\n        log.info(\"Processing order {} from partition {}\", event.getOrderId(), partition);\n        processEvent(event);\n    }\n}"
            },
            "codeExplanations": {
              "english": "The ProducerFactory configures serializers and durability (acks=all). Using the orderId as the message key ensures all events for the same order go to the same partition, maintaining event order. The @KafkaListener uses a consumer group for load balancing; multiple instances share partitions. Consumer groups allow horizontal scaling while ensuring each message is processed by one consumer in the group."
            },
            "keyPoints": [
              "Distributed commit log with high throughput and durability",
              "Partitions enable parallelism; keys ensure ordering within partitions",
              "Consumer groups provide load balancing and fault tolerance",
              "Messages retained based on time/size policy (not deleted after consumption)",
              "Ideal for event sourcing, metrics, and log aggregation"
            ],
            "extras": {
              "flowDiagram": "Producer -> Topic (orders: Partition 0, Partition 1, Partition 2) -> Consumer Group [Instance A (Partition 0,1), Instance B (Partition 2)]",
              "comparisonTable": [
                {
                  "headers": [
                    "Feature",
                    "RabbitMQ",
                    "Kafka"
                  ],
                  "rows": [
                    [
                      "Model",
                      "Traditional message queue",
                      "Distributed log"
                    ],
                    [
                      "Ordering",
                      "Per queue",
                      "Per partition (with key)"
                    ],
                    [
                      "Retention",
                      "Delete after ack",
                      "Configurable retention"
                    ],
                    [
                      "Throughput",
                      "Moderate",
                      "Very high"
                    ],
                    [
                      "Replay",
                      "No",
                      "Yes (seek to offset)"
                    ],
                    [
                      "Routing",
                      "Complex (exchanges)\", \"Simple (topics)"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "micro-8",
            "title": "Spring Cloud Gateway Routing",
            "explanations": {
              "english": "Spring Cloud Gateway provides an API Gateway built on Spring 5, WebFlux, and Project Reactor, handling cross-cutting concerns like routing, security, and rate limiting. It routes requests to downstream services using predicates (path, header, query parameters) and filters (modifying requests/responses). Routes can be configured via Java DSL or YAML. It integrates with service discovery (Eureka) for dynamic routing using lb://service-id syntax. As a reactive gateway, it handles high concurrency efficiently but requires careful handling of blocking operations in filters."
            },
            "code": {
              "title": "Gateway Configuration",
              "language": "java",
              "content": "@Configuration\npublic class GatewayConfig {\n    \n    @Bean\n    public RouteLocator customRouteLocator(RouteLocatorBuilder builder) {\n        return builder.routes()\n            .route(\"order-service\", r -> r\n                .path(\"/api/orders/**\")\n                .and().method(\"GET\", \"POST\")\n                .filters(f -> f\n                    .stripPrefix(2)\n                    .addRequestHeader(\"X-Gateway-Source\", \"api-gateway\")\n                    .circuitBreaker(config -> config\n                        .setName(\"orderServiceCircuitBreaker\")\n                        .setFallbackUri(\"forward:/fallback/orders\"))\n                )\n                .uri(\"lb://order-service\"))\n            .route(\"static\", r -> r\n                .path(\"/ui/**\")\n                .uri(\"https://static-content.example.com\"))\n            .build();\n    }\n}\n\n// application.yml alternative:\n// spring:\n//   cloud:\n//     gateway:\n//       routes:\n//       - id: order-service\n//         uri: lb://order-service\n//         predicates:\n//         - Path=/api/orders/**\n//         - Method=GET,POST\n//         filters:\n//         - StripPrefix=2"
            },
            "codeExplanations": {
              "english": "RouteLocator defines routes programmatically. The order-service route matches /api/orders/**, strips the first 2 path segments (/api), adds a header, and uses load balancing (lb://) to distribute requests across order-service instances. CircuitBreaker filter provides fallback during outages. The static route forwards to external URLs for frontend assets."
            },
            "keyPoints": [
              "Entry point for microservices handling cross-cutting concerns",
              "Routes based on predicates (path, method, header) to downstream services",
              "Load balancing integration with Eureka (lb://service-id)",
              "Filters modify requests (StripPrefix, AddHeader) and responses",
              "Built on WebFlux for reactive, non-blocking I/O"
            ],
            "extras": {
              "flowDiagram": "Client -> Gateway:8080 -> [Predicate Match] -> Filter Chain -> lb://order-service\n                                    -> [Predicate Match] -> Filter Chain -> lb://inventory-service",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "micro-9",
            "title": "Rate Limiting",
            "explanations": {
              "english": "Rate limiting in API Gateways controls traffic volume to prevent backend services from being overwhelmed by excessive requests. Algorithms include token bucket (smooth rate limiting), leaky bucket (smooth output), fixed window, and sliding window. Spring Cloud Gateway Redis RateLimiter stores burst capacity in Redis for distributed rate limiting across multiple gateway instances. Limits can be defined per user (based on JWT claims), per IP, or globally. When limits are exceeded, the gateway returns HTTP 429 (Too Many Requests) with optional Retry-After headers to inform clients of backoff periods."
            },
            "code": {
              "title": "Rate Limiting Configuration",
              "language": "java",
              "content": "@Bean\npublic RateLimiterGatewayFilterFactory filterFactory(RateLimiter rateLimiter) {\n    return new RateLimiterGatewayFilterFactory(rateLimiter);\n}\n\n// application.yml configuration:\n// spring:\n//   cloud:\n//     gateway:\n//       routes:\n//       - id: order-service\n//         uri: lb://order-service\n//         predicates:\n//         - Path=/api/orders/**\n//         filters:\n//         - name: RequestRateLimiter\n//           args:\n//             redis-rate-limiter.replenishRate: 10   # requests per second\n//             redis-rate-limiter.burstCapacity: 20   # max burst\n//             key-resolver: \"#{@userKeyResolver}\"\n\n@Bean\npublic KeyResolver userKeyResolver() {\n    // Rate limit by user (extracted from JWT or Principal)\n    return exchange -> Mono.just(\n        exchange.getPrincipal()\n            .cast(Authentication.class)\n            .map(auth -> auth.getName())\n            .defaultIfEmpty(\"anonymous\")\n    );\n}\n\n@Bean\npublic KeyResolver ipKeyResolver() {\n    // Rate limit by IP address\n    return exchange -> Mono.just(\n        exchange.getRequest().getRemoteAddress().getAddress().getHostAddress()\n    );\n}"
            },
            "codeExplanations": {
              "english": "The RequestRateLimiter filter uses Redis to track request rates. replenishRate sets steady-state throughput (10/sec), burstCapacity allows short spikes up to 20. KeyResolver determines the rate limit bucket; userKeyResolver extracts the username from security context for per-user quotas, while ipKeyResolver limits by client IP. Exceeding limits returns 429 Too Many Requests."
            },
            "keyPoints": [
              "Prevents cascade failures by throttling excessive requests",
              "Token bucket algorithm allows bursts while limiting sustained rate",
              "Redis backend enables distributed rate limiting across gateway replicas",
              "KeyResolver strategies: per user, per IP, or global",
              "Returns HTTP 429 with optional Retry-After header for client backoff"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [
                {
                  "headers": [
                    "Algorithm",
                    "Behavior",
                    "Burst Handling"
                  ],
                  "rows": [
                    [
                      "Token Bucket",
                      "Smooth with bursts\", \"Allows bursts up to bucket size"
                    ],
                    [
                      "Leaky Bucket",
                      "Smooth output\", \"Queues or drops excess"
                    ],
                    [
                      "Fixed Window",
                      "Resets at interval\", \"Allows 2x burst at window edges"
                    ],
                    [
                      "Sliding Window",
                      "Precise\", \"Smooth, no burst at edges"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "micro-10",
            "title": "Gateway Authentication",
            "explanations": {
              "english": "Centralizing authentication in the API Gateway eliminates the need for individual services to handle JWT validation, certificate management, and OAuth2 flows. The gateway validates tokens from incoming requests and passes user context (user ID, roles) to downstream services via headers (X-User-Id, X-Roles). Services trust headers from the gateway (mTLS or network policies prevent spoofing). This pattern simplifies service code and provides single-point security policy enforcement. The gateway can also handle cookie-to-token translation for browser clients and refresh token rotation."
            },
            "code": {
              "title": "Gateway Security Filter",
              "language": "java",
              "content": "@Component\npublic class AuthenticationFilter extends AbstractGatewayFilterFactory<Config> {\n    \n    @Override\n    public GatewayFilter apply(Config config) {\n        return (exchange, chain) -> {\n            String token = extractToken(exchange.getRequest());\n            \n            return validateToken(token)\n                .flatMap(jwt -> {\n                    // Add user context to headers for downstream services\n                    ServerHttpRequest mutatedRequest = exchange.getRequest()\n                        .mutate()\n                        .header(\"X-User-Id\", jwt.getSubject())\n                        .header(\"X-User-Roles\", String.join(\",\", jwt.getRoles()))\n                        .header(\"X-Trace-Id\", UUID.randomUUID().toString())\n                        .build();\n                    \n                    return chain.filter(exchange.mutate()\n                        .request(mutatedRequest)\n                        .build());\n                })\n                .switchIfEmpty(Mono.error(new ResponseStatusException(HttpStatus.UNAUTHORIZED)));\n        };\n    }\n    \n    private Mono<Jwt> validateToken(String token) {\n        // JWT validation logic\n        return Mono.justOrEmpty(token)\n            .map(this::parseAndValidate);\n    }\n}"
            },
            "codeExplanations": {
              "english": "The global filter intercepts all requests. It extracts JWT from the Authorization header, validates signature and expiration, then injects user context as new headers into the request before forwarding to downstream services. Downstream services read these trusted headers instead of parsing JWT themselves. If validation fails, it returns 401 immediately without burdening backend services."
            },
            "keyPoints": [
              "Centralize JWT/OAuth2 validation in the gateway",
              "Pass user context via headers to downstream services (X-User-Id)",
              "Services trust headers from gateway (secured by mTLS or VPC)",
              "Eliminates duplicate security code in microservices",
              "Simplifies token refresh and cookie handling for browsers"
            ],
            "extras": {
              "flowDiagram": "Client -> [JWT] -> Gateway (Validate) -> [X-User-Id:123, X-Roles:USER] -> Order Service (Trust Headers)",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "micro-11",
            "title": "Eureka Server",
            "explanations": {
              "english": "Eureka Server is a service registry providing a REST API for service discovery in Netflix OSS architecture. Services register themselves at startup with their host, port, and health status. The server maintains a registry of available instances and provides lookup capabilities to clients. It handles service deregistration on graceful shutdown and expiration of instances that fail to send heartbeats. Eureka Server replicates registry data with peer nodes for high availability in cluster mode. It is the foundation of client-side service discovery where clients query Eureka to locate service instances before making requests."
            },
            "code": {
              "title": "Eureka Server Setup",
              "language": "java",
              "content": "@SpringBootApplication\n@EnableEurekaServer\npublic class DiscoveryServerApplication {\n    public static void main(String[] args) {\n        SpringApplication.run(DiscoveryServerApplication.class, args);\n    }\n}\n\n// application.yml:\n// server:\n//   port: 8761\n// eureka:\n//   instance:\n//     hostname: localhost\n//   client:\n//     registerWithEureka: false  # Self-preservation: don't register itself\n//     fetchRegistry: false       # Don't fetch registry as client\n//   server:\n//     enableSelfPreservation: false  # For dev; disabled auto-protection in prod\n\n// Cluster configuration (peer awareness):\n// ---\n// spring:\n//   profiles: peer1\n// eureka:\n//   instance:\n//     hostname: peer1\n//   client:\n//     serviceUrl:\n//       defaultZone: http://peer2:8762/eureka/,http://peer3:8763/eureka/"
            },
            "codeExplanations": {
              "english": "@EnableEurekaServer activates the registry. In standalone mode, it disables self-registration. The dashboard is available at http://localhost:8761 showing registered services and their health. For production, multiple Eureka instances form a cluster with peer-to-peer replication; each peer registers with others in defaultZone to ensure registry consistency and availability."
            },
            "keyPoints": [
              "Service registry for client-side discovery pattern",
              "Services register on startup and send heartbeats every 30 seconds",
              "Self-preservation mode prevents mass deregistration during network partitions",
              "Peer-to-peer replication for high availability clusters",
              "REST API allows querying instances by service ID"
            ],
            "extras": {
              "flowDiagram": "Order Service -> Register -> Eureka Server <- Register <- Inventory Service\n      \\                            /\n       \\                          /\n        Query -> Available Instances",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "micro-12",
            "title": "Eureka Client",
            "explanations": {
              "english": "Eureka Client enables applications to register with Eureka Server and discover other services. On startup, the client registers its metadata (instance ID, host, port, health check URL) and sends periodic heartbeats to renew its lease. It caches the registry locally for resilience, refreshing periodically from the server. When calling another service, the client queries Eureka for available instances and uses Ribbon or Spring Cloud LoadBalancer to select one. Registration includes metadata like zone information for affinity-based routing and virtualization awareness."
            },
            "code": {
              "title": "Eureka Client Configuration",
              "language": "java",
              "content": "@SpringBootApplication\n@EnableDiscoveryClient\npublic class OrderServiceApplication {\n    public static void main(String[] args) {\n        SpringApplication.run(OrderServiceApplication.class, args);\n    }\n}\n\n// application.yml:\n// spring:\n//   application:\n//     name: order-service  # Service ID used for discovery\n// eureka:\n//   client:\n//     serviceUrl:\n//       defaultZone: http://eureka1:8761/eureka/,http://eureka2:8762/eureka/\n//     healthcheck:\n//       enabled: true  # Use Spring Boot health endpoint\n//   instance:\n//     preferIpAddress: true  # Register IP instead of hostname\n//     metadataMap:\n//       zone: zone1\n//       profile: production\n\n// Discovering services programmatically:\n@Autowired\nprivate DiscoveryClient discoveryClient;\n\npublic void callInventoryService() {\n    List<ServiceInstance> instances = discoveryClient\n        .getInstances(\"inventory-service\");\n    \n    if (!instances.isEmpty()) {\n        ServiceInstance instance = instances.get(0);\n        String url = instance.getUri() + \"/api/inventory\";\n        // Make request using RestTemplate/WebClient\n    }\n}"
            },
            "codeExplanations": {
              "english": "@EnableDiscoveryClient activates Eureka registration. The application registers with the service name 'order-service'. Multiple Eureka servers in defaultZone provide failover. preferIpAddress ensures registration uses IP addresses (sensible in containerized environments). DiscoveryClient provides programmatic lookup of instances, though typically Ribbon/Feign handle this automatically via load-balanced RestTemplates."
            },
            "keyPoints": [
              "Registers service metadata and health endpoints with Eureka",
              "Sends heartbeats every 30s (lease renewal)",
              "Caches registry locally, refreshing every 30s",
              "Uses service ID (spring.application.name) for lookups",
              "Supports zone-aware registration for latency-based routing"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "micro-13",
            "title": "Client-side Load Balancing",
            "explanations": {
              "english": "Client-side load balancing places the selection logic within the consumer rather than external load balancers. Spring Cloud LoadBalancer (replacing deprecated Ribbon) queries Eureka for available service instances and selects one using an algorithm (RoundRobin, Random, or custom). This eliminates the network hop to a central load balancer, reducing latency and single points of failure. The load balancer is integrated with RestTemplate, WebClient, and Feign via @LoadBalanced annotations. It respects health status and can implement zone affinity to prefer instances in the same availability zone."
            },
            "code": {
              "title": "Load Balancer Configuration",
              "language": "java",
              "content": "@Configuration\npublic class LoadBalancerConfig {\n    \n    @Bean\n    @LoadBalanced  // Enables client-side load balancing\n    public RestTemplate restTemplate() {\n        return new RestTemplate();\n    }\n    \n    @Bean\n    @LoadBalanced\n    public WebClient.Builder loadBalancedWebClientBuilder() {\n        return WebClient.builder();\n    }\n}\n\n@Service\npublic class OrderService {\n    @Autowired\n    private RestTemplate restTemplate;\n    \n    public InventoryStatus checkInventory(String productId) {\n        // URL uses service ID instead of hostname\n        // Load balancer selects instance from Eureka\n        return restTemplate.getForObject(\n            \"http://inventory-service/api/inventory/{id}\",\n            InventoryStatus.class,\n            productId\n        );\n    }\n}\n\n// Custom load balancing rule (e.g., zone affinity)\npublic class ZoneAffinityRule implements ReactorServiceInstanceLoadBalancer {\n    @Override\n    public Mono<Response<ServiceInstance>> choose(Request request) {\n        // Prefer instances in same zone, fallback to others\n        String myZone = getCurrentZone();\n        return serviceInstanceSupplier.get()\n            .map(instances -> instances.stream()\n                .filter(i -> myZone.equals(i.getMetadata().get(\"zone\")))\n                .findFirst()\n                .orElse(instances.get(ThreadLocalRandom.current().nextInt(instances.size()))));\n    }\n}"
            },
            "codeExplanations": {
              "english": "@LoadBalanced interceptor replaces 'http://inventory-service' with an actual host:port from Eureka using the load balancing algorithm. RestTemplate remains simple using logical service names. ZoneAffinityRule demonstrates custom selection logic prioritizing same-zone instances for lower latency, falling back to random selection if local zone instances are unavailable."
            },
            "keyPoints": [
              "Client chooses instance from Eureka registry instead of central LB",
              "Eliminates network hop and single point of failure",
              "@LoadBalanced annotation enables for RestTemplate/WebClient",
              "Default RoundRobin, supports custom selection algorithms",
              "Zone affinity reduces cross-AZ latency costs"
            ],
            "extras": {
              "flowDiagram": "Order Service -> Eureka (Get instances [A, B, C]) -> Load Balancer (Select B) -> HTTP to Instance B",
              "comparisonTable": [
                {
                  "headers": [
                    "Aspect",
                    "Server-side LB",
                    "Client-side LB"
                  ],
                  "rows": [
                    [
                      "Latency",
                      "Extra hop\", \"Direct connection"
                    ],
                    [
                      "Failure Mode",
                      "LB is SPOF\", \"Resilient (local cache)"
                    ],
                    [
                      "Routing Logic",
                      "Centralized\", \"Distributed per client"
                    ],
                    [
                      "Cost",
                      "Hardware/ALB expense\", \"Library overhead"
                    ],
                    [
                      "SSL",
                      "Terminate at LB\", \"End-to-end TLS"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "micro-14",
            "title": "Docker Multi-stage Builds",
            "explanations": {
              "english": "Multi-stage Docker builds optimize container images by separating the build environment from the runtime environment. The first stage uses a full JDK and build tools (Maven/Gradle) to compile and package the application. The final stage copies only the built artifact (JAR) into a minimal JRE or distroless base image, excluding build tools and source code. This significantly reduces image size, attack surface, and startup time. Spring Boot 2.3+ supports layered JARs that separate dependencies and application code for better Docker layer caching during rebuilds."
            },
            "code": {
              "title": "Multi-stage Dockerfile",
              "language": "dockerfile",
              "content": "# Stage 1: Build\nFROM maven:3.9-eclipse-temurin-17 AS builder\nWORKDIR /build\nCOPY pom.xml .\nCOPY src ./src\nRUN mvn clean package -DskipTests\n\n# Stage 2: Extract layers for caching\nFROM eclipse-temurin:17-jre-alpine AS extractor\nWORKDIR /extracted\nCOPY --from=builder /build/target/*.jar app.jar\nRUN java -Djarmode=layertools -jar app.jar extract\n\n# Stage 3: Runtime\nFROM eclipse-temurin:17-jre-alpine\nWORKDIR /app\n\n# Create non-root user\nRUN addgroup -S spring && adduser -S spring -G spring\nUSER spring:spring\n\n# Copy layers (dependencies change less frequently than code)\nCOPY --from=extracter /extracted/dependencies/ ./\nCOPY --from=extracter /extracted/spring-boot-loader/ ./\nCOPY --from=extracter /extracted/snapshot-dependencies/ ./\nCOPY --from=extracter /extracted/application/ ./\n\nEXPOSE 8080\nENTRYPOINT [\"java\", \"org.springframework.boot.loader.launch.JarLauncher\"]"
            },
            "codeExplanations": {
              "english": "Stage 1 builds the application using Maven. Stage 2 extracts the Spring Boot layered JAR to separate dependencies from application code. Stage 3 creates the runtime image using Alpine Linux (minimal size) with a non-root user for security. Layer ordering ensures dependency changes don't invalidate the application layer cache, speeding up rebuilds."
            },
            "keyPoints": [
              "Build in full JDK image, run in minimal JRE image",
              "Reduces final image size from 500MB+ to ~100MB",
              "Removes build tools and source code from production image",
              "Layered JARs optimize Docker cache (dependencies rarely change)",
              "Run as non-root user for security hardening"
            ],
            "extras": {
              "flowDiagram": "Stage 1 (Build): JDK + Maven -> Compile -> JAR\nStage 2 (Extract): JRE -> Explode JAR -> Layers\nStage 3 (Runtime): Minimal JRE + Layers -> Run",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "micro-15",
            "title": "Kubernetes Deployments",
            "explanations": {
              "english": "Kubernetes Deployments manage stateless application updates declaratively, ensuring the desired number of replicas are running and healthy. The Deployment resource defines the container image, resource limits (CPU/memory), environment variables, and health probes. Rolling updates ensure zero downtime by gradually replacing old pods with new ones, honoring maxSurge and maxUnavailable constraints. Rollbacks revert to previous replica sets if new versions fail readiness checks. Spring Boot apps integrate via liveness and readiness probes exposed through Actuator endpoints, allowing Kubernetes to restart unhealthy instances and remove unready instances from service rotation."
            },
            "code": {
              "title": "Deployment Configuration",
              "language": "yaml",
              "content": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: order-service\n  labels:\n    app: order-service\nspec:\n  replicas: 3\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1          # Allow 1 extra pod during update\n      maxUnavailable: 0    # Ensure no downtime\n  selector:\n    matchLabels:\n      app: order-service\n  template:\n    metadata:\n      labels:\n        app: order-service\n    spec:\n      containers:\n      - name: app\n        image: registry/order-service:1.2.3\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            memory: \"512Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"1024Mi\"\n            cpu: \"1000m\"\n        env:\n        - name: SPRING_PROFILES_ACTIVE\n          value: \"kubernetes,production\"\n        - name: DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: db-secret\n              key: password\n        livenessProbe:\n          httpGet:\n            path: /actuator/health/liveness\n            port: 8080\n          initialDelaySeconds: 60\n          periodSeconds: 30\n        readinessProbe:\n          httpGet:\n            path: /actuator/health/readiness\n            port: 8080\n          initialDelaySeconds: 20\n          periodSeconds: 5"
            },
            "codeExplanations": {
              "english": "The Deployment specifies 3 replicas with a RollingUpdate strategy ensuring zero maxUnavailable pods. Resource requests and limits prevent noisy neighbor issues. Secrets mount database passwords securely. Liveness probe (60s initial delay) detects deadlocks and restarts pods. Readiness probe (20s delay) determines when the pod can receive traffic, waiting for database connections to be ready."
            },
            "keyPoints": [
              "Declarative updates with rollout and rollback capabilities",
              "Rolling updates ensure zero-downtime deployments",
              "Resource requests/limits control scheduling and prevent OOM",
              "Liveness probes restart stuck containers",
              "Readiness probes control traffic flow during startup"
            ],
            "extras": {
              "flowDiagram": "Deployment Controller -> ReplicaSet (v1) -> Pods [Pod1, Pod2, Pod3]\nUpdate triggered -> Create ReplicaSet (v2) -> Scale up v2 pods -> Scale down v1 pods",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "micro-16",
            "title": "Kubernetes Services",
            "explanations": {
              "english": "Kubernetes Services provide stable networking endpoints for pods, abstracting away the ephemeral nature of individual containers. ClusterIP (default) exposes the service on an internal IP, accessible only within the cluster for inter-service communication. NodePort exposes a port on each node's IP for external access. LoadBalancer provisions an external load balancer (cloud-provider specific) and assigns a public IP. Headless services (ClusterIP: None) return pod IPs directly for client-side service discovery. Services use label selectors to route traffic to matching pods and support session affinity if needed."
            },
            "code": {
              "title": "Service Definitions",
              "language": "yaml",
              "content": "# Internal service (ClusterIP)\napiVersion: v1\nkind: Service\nmetadata:\n  name: order-service\nspec:\n  type: ClusterIP\n  selector:\n    app: order-service\n  ports:\n  - port: 80\n    targetPort: 8080\n    protocol: TCP\n\n# External access via cloud load balancer\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: api-gateway-lb\nspec:\n  type: LoadBalancer\n  selector:\n    app: api-gateway\n  ports:\n  - port: 443\n    targetPort: 8080\n  sessionAffinity: None\n\n# Headless service for StatefulSets/client-side discovery\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: kafka-headless\nspec:\n  type: ClusterIP\n  clusterIP: None  # Headless\n  selector:\n    app: kafka\n  ports:\n  - port: 9092"
            },
            "codeExplanations": {
              "english": "The order-service ClusterIP exposes port 80 internally, routing to container port 8080. Pods are selected by label app=order-service. The LoadBalancer service creates a cloud provider load balancer with public IP for the API Gateway. The headless Kafka service returns individual pod IPs for direct communication required by Kafka brokers, allowing clients to connect to specific instances."
            },
            "keyPoints": [
              "ClusterIP: Internal cluster access only (default)",
              "NodePort: Exposes port on each node's IP",
              "LoadBalancer: External load balancer with public IP (cloud)",
              "Headless (clusterIP: None): Returns pod IPs for direct access",
              "Label selectors determine which pods receive traffic"
            ],
            "extras": {
              "flowDiagram": "User -> LoadBalancer -> [Gateway Pod1, Gateway Pod2]\nInternal: Order Pod -> ClusterIP -> [Inventory Pod1, Inventory Pod2]",
              "comparisonTable": [
                {
                  "headers": [
                    "Type",
                    "Scope",
                    "Use Case"
                  ],
                  "rows": [
                    [
                      "ClusterIP",
                      "Internal cluster only\", \"Microservice-to-microservice"
                    ],
                    [
                      "NodePort",
                      "External via <NodeIP>:Port\", \"Dev/testing access"
                    ],
                    [
                      "LoadBalancer\", \"External via cloud LB\", \"Production public APIs"
                    ],
                    [
                      "ExternalName\", \"DNS alias\", \"External service reference"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "micro-17",
            "title": "Kubernetes Ingress",
            "explanations": {
              "english": "Ingress manages external HTTP/HTTPS access to services within the cluster, providing Layer 7 routing capabilities. It offers features like SSL termination, name-based virtual hosting, path-based routing (/api -> service-a, /ui -> service-b), and rate limiting. Ingress Controllers (NGINX, Traefik, HAProxy) implement the Ingress resource specifications. TLS certificates are managed via Secrets. Ingress eliminates the need for multiple LoadBalancer services (expensive in cloud providers) by multiplexing traffic through a single entry point. Advanced configurations include rewrite rules, CORS handling, and connection timeouts."
            },
            "code": {
              "title": "Ingress Configuration",
              "language": "yaml",
              "content": "apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: api-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/rate-limit: \"100\"\n    nginx.ingress.kubernetes.io/rewrite-target: /\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - api.example.com\n    secretName: api-tls-secret\n  rules:\n  - host: api.example.com\n    http:\n      paths:\n      - path: /orders\n        pathType: Prefix\n        backend:\n          service:\n            name: order-service\n            port:\n              number: 80\n      - path: /inventory\n        pathType: Prefix\n        backend:\n          service:\n            name: inventory-service\n            port:\n              number: 80\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: gateway-service\n            port:\n              number: 80"
            },
            "codeExplanations": {
              "english": "The Ingress routes traffic based on URL paths to different backend services. Annotations configure NGINX-specific features: SSL redirect, rate limiting, and URL rewriting. cert-manager annotation automates TLS certificate issuance from Let's Encrypt. The TLS section references a secret containing the certificate and key. PathType: Prefix matches any path starting with the specified string."
            },
            "keyPoints": [
              "Layer 7 HTTP routing (path-based, host-based)",
              "Single entry point for multiple services (saves LoadBalancer costs)",
              "SSL termination at ingress controller",
              "Annotations configure controller-specific features (rate limits, rewrites)",
              "Requires Ingress Controller deployment (NGINX, Traefik)"
            ],
            "extras": {
              "flowDiagram": "Internet -> Ingress Controller -> [api.example.com/orders -> Order Service]\n                                  -> [api.example.com/inventory -> Inventory Service]",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "micro-18",
            "title": "Kubernetes ConfigMaps",
            "explanations": {
              "english": "ConfigMaps decouple configuration artifacts from image content to enable environment-specific settings without rebuilding containers. They store non-sensitive configuration as key-value pairs or entire files (application.yml). ConfigMaps can be injected into pods as environment variables, command-line arguments, or mounted volumes. For sensitive data (passwords, tokens), use Secrets (base64 encoded, encrypted at rest in etcd). Spring Boot can mount ConfigMaps as application.properties or use the Spring Cloud Kubernetes library to watch for configuration changes and refresh the application context without restarting pods."
            },
            "code": {
              "title": "ConfigMap Usage",
              "language": "yaml",
              "content": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: order-service-config\ndata:\n  application-k8s.yml: |\n    server:\n      port: 8080\n    spring:\n      datasource:\n        url: jdbc:postgresql://postgres:5432/orders\n      kafka:\n        bootstrap-servers: kafka:9092\n    management:\n      endpoints:\n        web:\n          exposure:\n            include: health,info,metrics\n  LOG_LEVEL: INFO\n  FEATURE_FLAG_NEW_UI: \"true\"\n\n---\napiVersion: apps/v1\nkind: Deployment\nspec:\n  template:\n    spec:\n      containers:\n      - name: order-service\n        image: order-service:1.0\n        env:\n        - name: SPRING_PROFILES_ACTIVE\n          value: \"kubernetes\"\n        - name: LOG_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: order-service-config\n              key: LOG_LEVEL\n        volumeMounts:\n        - name: config-volume\n          mountPath: /config\n      volumes:\n      - name: config-volume\n        configMap:\n          name: order-service-config\n          items:\n          - key: application-k8s.yml\n            path: application-k8s.yml"
            },
            "codeExplanations": {
              "english": "The ConfigMap contains a complete YAML configuration file and simple key-value pairs. The Deployment consumes it in two ways: LOG_LEVEL is injected as an environment variable using configMapKeyRef, and the application-k8s.yml is mounted as a volume at /config. Spring Boot reads the mounted file as part of its configuration. This allows updating configuration by changing the ConfigMap and restarting pods, without rebuilding the image."
            },
            "keyPoints": [
              "Decouple configuration from container images",
              "Store non-sensitive data (use Secrets for passwords)",
              "Mount as files or inject as environment variables",
              "Update ConfigMap to change configuration across pods",
              "Spring Cloud Kubernetes enables hot reloading of ConfigMap changes"
            ],
            "extras": {
              "flowDiagram": "ConfigMap -> Mounted Volume -> /config/application.yml -> Spring Boot reads\n         -> Env Var -> JVM System Property",
              "comparisonTable": [
                {
                  "headers": [
                    "Aspect",
                    "ConfigMap",
                    "Secret"
                  ],
                  "rows": [
                    [
                      "Content",
                      "Plain text\", \"Base64 encoded"
                    ],
                    [
                      "Use Case",
                      "Configuration\", \"Passwords, tokens, keys"
                    ],
                    [
                      "Size Limit",
                      "1 MB\", \"1 MB"
                    ],
                    [
                      "Encryption",
                      "No (plain in etcd)\", \"Yes (at rest in etcd)"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "micro-19",
            "title": "Spring Boot in Microservices",
            "explanations": {
              "english": "Spring Boot serves as the foundational framework for microservices, providing embedded servers for containerized deployment, actuator endpoints for health checks and metrics, and auto-configuration for rapid service creation. It integrates seamlessly with Spring Cloud components for service discovery, configuration management, and circuit breakers. The fat JAR packaging simplifies containerization, while Spring Boot DevTools enhances local development efficiency. Its opinionated defaults reduce boilerplate, allowing teams to focus on business logic while maintaining consistency across dozens of services in a microservices ecosystem."
            },
            "code": {
              "title": "Microservice Bootstrap",
              "language": "java",
              "content": "@SpringBootApplication\n@EnableDiscoveryClient\npublic class OrderServiceApplication {\n    public static void main(String[] args) {\n        SpringApplication.run(OrderServiceApplication.class, args);\n    }\n}\n\n// Bootstrap configuration for cloud environments\n@SpringBootApplication\n@EnableDiscoveryClient\n@EnableCircuitBreaker\n@EnableFeignClients\npublic class Application {\n    public static void main(String[] args) {\n        new SpringApplicationBuilder(Application.class)\n            .properties(\n                \"spring.application.name=order-service\",\n                \"server.port=0\",  // Random port for multiple instances\n                \"management.endpoints.web.exposure.include=*\"\n            )\n            .run(args);\n    }\n}"
            },
            "codeExplanations": {
              "english": "The OrderServiceApplication shows a minimal microservice with service discovery enabled. The second example demonstrates programmatic configuration suitable for cloud environments: server.port=0 uses random ports (essential for local development with multiple instances), and full actuator exposure enables comprehensive monitoring. @EnableCircuitBreaker and @EnableFeignClients activate resilience and declarative HTTP clients."
            },
            "keyPoints": [
              "Embedded servers (Tomcat/Netty) eliminate external server dependencies",
              "Fat JARs simplify Docker containerization",
              "Actuator provides production-ready health and metrics endpoints",
              "Random port assignment (server.port=0) supports local scaling",
              "Spring Cloud integration enables distributed patterns"
            ],
            "extras": {
              "flowDiagram": "",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "micro-20",
            "title": "Spring Cloud Integration",
            "explanations": {
              "english": "Spring Cloud provides tools for building common patterns in distributed systems. Config Server centralizes external configuration across environments and services. Gateway handles API routing, load balancing, and cross-cutting concerns. Circuit Breaker (Resilience4j) prevents cascade failures. Sleuth and Zipkin enable distributed tracing. OpenFeign simplifies HTTP client creation. These components integrate with Spring Boot via auto-configuration and annotations, providing a cohesive platform for cloud-native microservices without vendor lock-in to specific cloud providers."
            },
            "code": {
              "title": "Cloud Dependencies",
              "language": "xml",
              "content": "<dependencies>\n    <!-- Service Discovery -->\n    <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>\n    </dependency>\n    \n    <!-- API Gateway -->\n    <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-starter-gateway</artifactId>\n    </dependency>\n    \n    <!-- Resilience -->\n    <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-starter-circuitbreaker-resilience4j</artifactId>\n    </dependency>\n    \n    <!-- Distributed Tracing -->\n    <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-starter-sleuth</artifactId>\n    </dependency>\n    <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-sleuth-zipkin</artifactId>\n    </dependency>\n</dependencies>"
            },
            "codeExplanations": {
              "english": "These Spring Cloud starters provide the microservices toolkit: Eureka Client for service registration, Gateway for API management, Resilience4j for circuit breaking and bulkheading, and Sleuth with Zipkin for distributed tracing. They leverage Spring Boot auto-configuration to minimize explicit configuration while enabling production-grade distributed patterns."
            },
            "keyPoints": [
              "Config Server: Centralized external configuration",
              "Gateway: Routing, filtering, and cross-cutting concerns",
              "Circuit Breaker: Resilience against service failures",
              "Sleuth: Distributed tracing and correlation IDs",
              "OpenFeign: Declarative HTTP clients with load balancing"
            ],
            "extras": {
              "flowDiagram": "Config Server -> Git Repo\nServices -> Eureka Registry\nGateway -> Services\nTraces -> Zipkin",
              "comparisonTable": [],
              "examples": []
            }
          },
          {
            "id": "micro-21",
            "title": "Observability",
            "explanations": {
              "english": "Observability in microsystems encompasses metrics, logging, and distributed tracing to understand system behavior. Micrometer instruments code and exports metrics to Prometheus, Datadog, or CloudWatch. Distributed tracing (with Sleuth/Zipkin or OpenTelemetry) follows requests across service boundaries using correlation IDs (traceId, spanId) injected into MDC and HTTP headers. Centralized logging aggregates logs from all services into ELK or Splunk. Health indicators report service-specific status. Together, these provide the telemetry necessary to diagnose failures, analyze performance bottlenecks, and alert on anomalies in distributed architectures."
            },
            "code": {
              "title": "Distributed Tracing",
              "language": "java",
              "content": "@Configuration\npublic class TracingConfig {\n    \n    @Bean\n    public WebClient.Builder tracedWebClientBuilder(Tracer tracer) {\n        return WebClient.builder()\n            .filter((request, next) -> {\n                // Propagate trace IDs to downstream services\n                Span span = tracer.nextSpan().name(\"http.client\").start();\n                try (Tracer.SpanInScope ws = tracer.withSpanInScope(span)) {\n                    return next.exchange(\n                        ClientRequest.from(request)\n                            .header(\"X-B3-TraceId\", span.context().traceId())\n                            .header(\"X-B3-SpanId\", span.context().spanId())\n                            .build()\n                    ).doFinally(sig -> span.end());\n                }\n            });\n    }\n}\n\n// Log format includes trace/span IDs\n// %d{yyyy-MM-dd HH:mm:ss} [%thread] [%X{traceId},%X{spanId}] %-5level %logger - %msg%n\n// Output: 2024-01-15 10:00:00 [http-nio-8080-exec-1] [abc123,def456] INFO c.e.OrderService - Processing order"
            },
            "codeExplanations": {
              "english": "The WebClient filter propagates tracing context (TraceId, SpanId) via HTTP headers (B3 propagation format) to downstream services. This creates a trace tree spanning multiple services. Logs include these IDs via MDC (%X{traceId}), allowing correlation of log entries across distributed services. Zipkin aggregates these spans to visualize request flows and latency."
            },
            "keyPoints": [
              "Micrometer for metrics (counters, timers, gauges)",
              "Distributed tracing follows requests across service boundaries",
              "TraceId and SpanId propagation via HTTP headers (B3 or W3C)",
              "Centralized logging (ELK/Splunk) aggregates logs from all pods",
              "Health endpoints (liveness/readiness) enable orchestration awareness"
            ],
            "extras": {
              "flowDiagram": "Request -> Gateway [Trace: abc, Span: 1] -> Order Service [Trace: abc, Span: 2] -> Inventory Service [Trace: abc, Span: 3]\nAll report to Zipkin -> Visualize trace tree",
              "comparisonTable": [
                {
                  "headers": [
                    "Signal",
                    "Tooling",
                    "Purpose"
                  ],
                  "rows": [
                    [
                      "Metrics",
                      "Micrometer/Prometheus",
                      "Performance, capacity"
                    ],
                    [
                      "Logging",
                      "ELK/Splunk\", \"Debugging, audit trails"
                    ],
                    [
                      "Tracing",
                      "Zipkin/Jaeger\", \"Request flow, latency"
                    ],
                    [
                      "Profiling",
                      "Async Profiler\", \"CPU/Memory analysis"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "micro-22",
            "title": "Resilience",
            "explanations": {
              "english": "Resilience patterns prevent cascade failures in distributed systems where services depend on other services. Circuit Breakers (Resilience4j) stop requests to failing services, returning fallback responses or errors immediately after a threshold of failures, allowing recovery time. Bulkheads isolate failures by limiting concurrent calls to specific services, preventing one slow dependency from exhausting all threads. Retries with exponential backoff handle transient failures. Timeouts prevent indefinite blocking. Rate limiters control throughput. These patterns combined ensure partial system functionality degradation rather than total system failure when dependencies are stressed or unavailable."
            },
            "code": {
              "title": "Resilience4j Implementation",
              "language": "java",
              "content": "@Service\npublic class InventoryServiceClient {\n    private final InventoryFeignClient client;\n    \n    @CircuitBreaker(name = \"inventory\", fallbackMethod = \"getDefaultStock\")\n    @Retry(name = \"inventory\")\n    @Bulkhead(name = \"inventory\", type = Type.THREADPOOL)\n    @TimeLimiter(name = \"inventory\")\n    public CompletableFuture<StockStatus> checkStock(String productId) {\n        return CompletableFuture.supplyAsync(() -> client.checkAvailability(productId));\n    }\n    \n    public CompletableFuture<StockStatus> getDefaultStock(String productId, Exception ex) {\n        log.warn(\"Inventory service down, returning default for {}\", productId, ex);\n        return CompletableFuture.completedFuture(\n            StockStatus.builder().available(false).source(\"CACHE\").build()\n        );\n    }\n}\n\n// application.yml:\n// resilience4j:\n//   circuitbreaker:\n//     instances:\n//       inventory:\n//         slidingWindowSize: 10\n//         permittedNumberOfCallsInHalfOpenState: 3\n//         waitDurationInOpenState: 10s\n//         failureRateThreshold: 50\n//   timelimiter:\n//     instances:\n//       inventory:\n//         timeoutDuration: 2s"
            },
            "codeExplanations": {
              "english": "@CircuitBreaker opens after 50% failure rate within 10 calls, bypassing the inventory service for 10 seconds before half-open retries. @Retry attempts transient failures. @Bulkhead (threadpool) limits concurrent inventory calls to prevent thread starvation. @TimeLimiter enforces 2-second timeouts. The fallback method returns cached/default data when the circuit is open, ensuring order processing continues even if inventory checking fails."
            },
            "keyPoints": [
              "Circuit Breaker: Fail fast when dependency is unhealthy",
              "Bulkhead: Limit resources per dependency (thread isolation)",
              "Retry: Handle transient failures with backoff",
              "Timeout: Prevent indefinite blocking",
              "Fallback: Provide degraded functionality during outages"
            ],
            "extras": {
              "flowDiagram": "Request -> Circuit Breaker (Closed) -> Inventory Service\n                    |\n                    -> Open -> Fallback (Cache/Default)",
              "comparisonTable": [
                {
                  "headers": [
                    "Pattern",
                    "Problem Solved",
                    "Action"
                  ],
                  "rows": [
                    [
                      "Circuit Breaker\", \"Cascade failure\", \"Stop calling failing service"
                    ],
                    [
                      "Bulkhead\", \"Resource exhaustion\", \"Isolate thread pools per service"
                    ],
                    [
                      "Retry\", \"Transient failures\", \"Retry with backoff"
                    ],
                    [
                      "Timeout\", \"Latency accumulation\", \"Fail if too slow"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          },
          {
            "id": "micro-23",
            "title": "Cloud-Native Patterns",
            "explanations": {
              "english": "Cloud-native patterns leverage platform capabilities for scalability and resilience. Externalized configuration (ConfigMaps/Secrets) separates code from environment. Stateless processes enable horizontal scaling; session data is stored in Redis or databases. Health probes enable orchestration decisions. Graceful shutdown handles SIGTERM by completing in-flight requests before terminating. Event sourcing and CQRS decouple read/write models. Sidecar pattern deploys auxiliary containers (proxies, log shippers) alongside app containers. These 12-Factor App principles ensure applications thrive in dynamic, containerized environments with ephemeral infrastructure."
            },
            "code": {
              "title": "Cloud-Native Implementation",
              "language": "java",
              "content": "@Component\npublic class GracefulShutdown implements ApplicationListener<ContextClosedEvent> {\n    private final ExecutorService executorService;\n    \n    @Override\n    public void onApplicationEvent(ContextClosedEvent event) {\n        log.info(\"Received shutdown signal, draining connections...\");\n        executorService.shutdown();\n        try {\n            if (!executorService.awaitTermination(30, TimeUnit.SECONDS)) {\n                executorService.shutdownNow();\n            }\n        } catch (InterruptedException e) {\n            executorService.shutdownNow();\n        }\n    }\n}\n\n// Externalized Session with Redis\n@Configuration\n@EnableRedisHttpSession(maxInactiveIntervalInSeconds = 3600)\npublic class SessionConfig {\n    @Bean\n    public LettuceConnectionFactory connectionFactory() {\n        return new LettuceConnectionFactory();\n    }\n}\n\n// Stateless service - no local state\n@Service\npublic class OrderService {\n    // All state externalized: Database for persistence, Redis for sessions/cache\n    // Service can be killed/restarted without data loss\n}"
            },
            "codeExplanations": {
              "english": "GracefulShutdown implements the graceful degradation pattern, handling Kubernetes SIGTERM by draining in-flight requests within 30 seconds before forcing shutdown. @EnableRedisHttpSession externalizes HTTP sessions to Redis, making the application stateless and allowing horizontal scaling without sticky sessions. The OrderService contains no instance-specific state, adhering to 12-Factor App principles for cloud-native deployments."
            },
            "keyPoints": [
              "Stateless processes: Share-nothing architecture enables horizontal scaling",
              "Externalized configuration: Environment variables and ConfigMaps",
              "Graceful shutdown: Handle SIGTERM to complete requests before exit",
              "Port binding: Export services via ports, not domain sockets",
              "Concurrency: Scale via process model (container replicas)",
              "Disposability: Fast startup and graceful shutdown for rapid scaling"
            ],
            "extras": {
              "flowDiagram": "Kubelet -> SIGTERM -> Graceful Shutdown (30s) -> Drain Requests -> Exit 0\n            -> SIGKILL (if stuck) -> Force Kill",
              "comparisonTable": [
                {
                  "headers": [
                    "Traditional",
                    "Cloud-Native"
                  ],
                  "rows": [
                    [
                      "Stateful sessions\", \"Externalized to Redis"
                    ],
                    [
                      "File system storage\", \"Object storage (S3)"
                    ],
                    [
                      "Static scaling\", \"Dynamic horizontal scaling"
                    ],
                    [
                      "Deployment scripts\", \"Container orchestration"
                    ],
                    [
                      "Fixed infrastructure\", \"Ephemeral, replaceable instances"
                    ]
                  ]
                }
              ],
              "examples": []
            }
          }
        ]
      }
    ]
  }
]